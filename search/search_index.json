{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Blog","text":""},{"location":"hello-world/","title":"Hello world!","text":"<p>Welcome to WordPress. This is your first post. Edit or delete it, then start blogging!</p> <p>\u2014 I intentionally left this automatic WordPress post untouched to mark the beginning of this blog.</p>"},{"location":"windows-phone-7-great-platform-sad-user-experience/","title":"Windows Phone 7 \u2013 great platform, sad user experience","text":"<p>If you have been a Windows developer and at the same time Apple iPhone/iPad or Google Android user then you probably know what I am talking about here.</p> <p>Windows Phone 7 is running on top of Silverlight and XNA, and then you can use Visual Studio and/or XNA Game Studio for WP7 development. So in terms of development WP7 is a dream platform.</p> <p>That being said, I am looking at the WP7 phone that I got for research, and the user interface is just plain ugly. I am talking about the square boxes, or info tiles (or however you want to call them) on the home screen; the black and white lists and dialog boxes; the square black and white buttons and the half-hidden page titles.</p> <p>I keep wondering why, given the capabilities of Silverlight and XNA, why has Microsoft created such an unexciting user interface?</p> <p>The phone I have is SAMSUNG SGH-i917 with AT&amp;T</p>"},{"location":"the-year-of-the-tablet/","title":"The year of the tablet","text":"<p>At CES this year, I saw more than a dozen vendors who are preparing to launch tab, slate or pad device in 2011. Most of the devices are going to be Android based. Except for a few big exhibitors like Samsung and RIM, most companies were showing just prototypes.</p> <p>So this year will be the year of the tablets. We will see a lot of devices and ultimately the competition will drive the prices down. As the devices become more affordable, soon there will be at least one and likely a few tab devices per household. The demand for tablet apps is going to be huge. Same is true forother products like movies, newspapers, magazines and books.</p>"},{"location":"mono-will-be-the-cross-platform-tool-for-android-and-ios-development/","title":"Mono will be the cross-platform tool for Android and iOS development","text":"<p>The nice folks on the Novell\u2019s Mono team are almost ready with MonoDroid \u2013 a C# version of the Android API, and MonoTouch \u2013 the C# version of the iOS frameworks has been around for a while now. So, if you are about to start a new iPhone/iPad application and you already know C#, you should definitely check MonoTouch. If later you decide to support Android, it will be easier to port your app from MonoTouchto MonoDroid than to rewrite it from Objective-C to Java.</p>"},{"location":"a-few-thoughts-about-nokia-microsoft-deal-and-windows-phone-7/","title":"A few thoughts about Nokia-Microsoft deal and Windows Phone 7","text":"<p>A few days ago Nokia announced that it would start using Windows Phone 7 as the main mobile operating system on all its future smartphones. I think this is probably a good deal for Microsoft. I do not see how this is good for Nokia though. This deal basically reduces Nokia to just a hardware manufacturer. </p> <p>The worst part is that Nokia becomes completely dependent on Windows Phone 7 which as a platform is way behind Android. Nokia should have chosen Android, kept their investment in MeeGo, and provided Android and MeeGo migration tools to Symbian developers.</p>"},{"location":"can-intel-become-the-next-apple/","title":"Can Intel become the next Apple","text":"<p>Now that Nokia has abandoned Intel\u2019s MeeGo,the most logical way forward for Intel is to start designing its own phone and tablet device. That way Intel will control both the hardware and the software and will be able to make them work together well.So what do you think? Can Intel become the next Apple?</p>"},{"location":"can-hp-become-the-next-apple/","title":"Can HP become the next Apple","text":"<p>As you may know HP acquired WebOS when it bought phone maker Palm for $1.2 billion last year, and this week Leo Apotheker, the new CEO of HP, said in a Bloomberg interview, that starting next year, every PC shipped by HP will come with WebOS in addition to Microsoft Windows.</p> <p>I think it is a move in the right direction for HP. Clearly, if done right, a model where both hardware and software are developed in-house works (as shown by Apple). If HP is able to play the software part well, then we might see some users switching to WebOS at least for home use.</p> <p>If HP is successful with WebOS, other big PC vendors might follow the same model. So, where all this leaves Microsoft? One way for Microsoft to continue forward is to start making and selling its own brand of computer, tablet and possibly phone device (just like it did with Zune and Xbox).</p>"},{"location":"xna-game-framework-for-ios-and-android/","title":"XNA Game Framework for iOS and Android","text":"<p>I recently came across MonoGame / (formerly XNATouch) \u2013 a cool open source project that implements XNA on top of OpenGL. MonoGame currently runs on MonoTouch, Mac OS X and Windows, and MonoDroid will be supported as well. So now we have a portable .NET game platform for all major mobile platforms.</p>"},{"location":"android-honeycomb-emulator-is-completely-useless/","title":"Android Honeycomb emulator is completely useless","text":"<p>I decided to test drive the new Android 3.0 and tools today.</p> <p>I updated my Eclipse environment to the latest Helios revision and then downloaded and installed the latest Android SDK and tools.</p> <p>I created a basic photo slideshow application to test with. However, the Android 3.0 Honeycomb emulator is so slow, it is actually useless for any kind of development or testing. It takes forever for the application to load and start and then it runs extremely slow. The machine I test on is Intel Core i7, 2.67 GHz, quad-core with 12GB RAM, so that is a pretty good machine. I cannot imagine what else the Android emulator might need to run faster.</p>"},{"location":"zune-will-be-no-more/","title":"Zune will be no more","text":"<p>According to a report by Bloomberg, Microsoft will stop making any new Zune models and shift its focus to developing software for mobile phones and video-game consoles. </p> <p>That\u2019s unfortunate as Zune seemed to be the only device on the market that offered any alternative to iPod. Particularly the latest Zune HD is not a bad device at all. It has been rated second after iPod Touch by sites like CNet. I think Zune HD might have had a chance in the long run. Let\u2019s hope the Bloomberg\u2019s report turns out just a rumor.</p>"},{"location":"why-is-it-faster-and-cheaper-to-develop-for-mac/","title":"Why is it faster and cheaper to develop for Mac?","text":"<p>At Swift Software Group, which is our consulting business, we are seeing now more and more projects that have the requirement to run on Mac and Windows. What we found out is that making a Mac version of a software product almost always takes less effort than making the corresponding Windows version. That is a surprise for everybody, as we have been what some people call \u201cPCs\u201d for a long time. So naturally I started thinking why the Mac development turns out to be more efficient. It is definitely not the tools \u2013 Visual Studio is still a better IDE than XCode \u2013 it is not the OS either, Mac OS and Windows 7 are both nice and modern operating systems and both are centered around better usability and increased productivity.</p> <p>So why is it faster and cheaper to develop for Mac?</p> <p>The first thing about Mac is the stability of the underlying platform. By that I mean that you rarely worry about things like drivers, other software messing up with your software, devices not working as expected and so on problems that are common on Windows . Once something works on the developers\u2019 Macs it works flawlesslyon any Mac worldwide. It just works. With Windows the OS/Hardware combo is never guaranteed to work in a consistent way. It is important to say here that the problem is not Windows by itself, but Windows in combination with the infinite number of hardware, devices and drivers out there.</p> <p>The second thing that makes your Mac developer life easier is the fact that Mac owners upgrade the system software often. As a result most of your customers run the latest version of Mac OS shortly after Apple releases it. With Windows you have Windows XP, Windows Vista, Windows 7, server versions, 32Bit and 64Bit, so at the end you must spend a lot of time (and money) to make sure your product works on every kind of Windows.</p>"},{"location":"android-fragmentation-is-bad-for-everybody/","title":"Android fragmentation is bad for everybody","text":"<p>Android fragmentation will kill Android eventually. Some call this fragmentation a \u201cwider consumer choice\u201d, \u201cdifferentiation\u201d and other names. In reality it only creates headaches for software developers, hinders software upgrades and slows down innovation. </p> <p>It has become increasingly hard and expensive to develop quality apps for Android. The problem is not the device choice but that the same code does not work consistently across devices. Single developers and small development shops do not have the resources to buy multiple Android devices. For bigger companies Android apps cost more and take longer to develop. </p> <p>All that leads to low quality apps or apps that work on just a few device models. Something has to be done.Google should do what Amazon did with Kindle Fire. Google should take complete control over the software platform and maybe they should start making their own hardware too.</p>"},{"location":"app-stores-the-future-of-desktop-software-distribution/","title":"App Stores \u2013 the future of desktop software distribution","text":"<p>After the success of the iOS App Store, an app store for Mac was a logical step for Apple. Many people have had doubts about a desktop software app store, but it is now official \u2013 the way to distribute apps for Mac going forward is the Mac App Store.</p> <p>What about Microsoft and Windows?</p> <p>The Windows story is even more exciting. With the release of Windows 8 later this year the most widely used desktop platform will get an app store. Given the Windows user base, the potential reach of a its app store will be huge.</p> <p>What should we do?</p> <p>If you are a software developer or publisher you should start working on Windows 8 versions of your products now, because the Windows app market will be bigger than iOS, Mac and Android markets combined.</p>"},{"location":"urls-or-the-last-ugly-thing-in-web-apps/","title":"URLs OR The last ugly thing in web apps","text":"<p>Just look at this URL:</p> <p>http://movies.netflix.com/WiPlayer?movieid=70198352&amp;trkid=4213507&amp;t=The+Event%3A+Ssn+1%3A+Us+or+Them#MovieId=70197638&amp;EpisodeMovieId=70198352</p> <p>Ouch! That is what I see in the Google Chrome address bar, while watching The Event \u2013 Us or Them on Netflix.</p> <p>How about this URL to a page for buying a book from Amazon:</p> <p>http://www.amazon.com/gp/product/1847195148?ie=UTF8&amp;tag=viny07-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1847195148</p> <p>What I want to see is Chrome and every other browser hide the URL garbage after the host name. For example it will be nice to see only netflix.com in the address bar or even better will be just \u201cNetflix\u201d. Everything else should be hidden because it is in fact an implementation detail which few people understand, and even fewer care about.</p> <p>So here is a feature request for browser developers:Hide the part of the URL after the domain name by default. Then add a switch for showing/hiding full URL on demand.</p>"},{"location":"android-5-if-you-make-it-they-wont-push-the-update/","title":"Android 5: If you make it, they won\u2019t push the update","text":"<p>Android 4 was released in October 2011. Three months later we have just few devices running it. Today Android 5 is rumored to be launching in Q2 2012. We all know how this will end up: wireless carriers and device manufacturers will be late or will simply refuse to push the software update to existing hardware. It seems they do not care about sold inventory, but sure enough they will offer you new devices with the new Android OS. </p> <p>The first problem is your Android device is destined to become an unsupported brick 6 months after you buy it, and to be fair I have to say that a lot of people are actually fine with that. </p> <p>The second problem, the bigger problem is that software developers cannot keep up with this mess of hardware vendor customization, carrier customization, multiple versions, and just about everybody doing what they want and when the want it with Android. Android used to be a decent and promising iOS alternative. Recently it has become the nightmare of mobile development.</p> <p>\u2026 but \u2026</p> <p>There is a light in the tunnel. Google is buying Motorola. Hopefully they are doing it, so they can make better hardware + software integrated devices, just like Apple does. However, it will take time to swallow Motorola, so in the meantime Google should take a page from Microsoft\u2019s book and implement a more controlled Android licensing. Google should start demanding minimum hardware specs and swift software updates from device manufacturers and wireless carriers. That is what Microsoft has done with Windows Phone 7 and is doing with Windows 8.</p>"},{"location":"super-agile-a-note-about-software-requirements/","title":"Super Agile: A note about software requirements","text":"<p>Write your requirements as user stories, following this simple template:</p> <pre><code>As a , I want  so that .\n</code></pre> <p>In other words:</p> <pre><code>As a product owner, I want to describe features as user stories, so that I encourage myself to think about the added value for my customers.\n</code></pre>"},{"location":"convert-an-existing-google-apps-account-to-a-google-apps-reseller-account/","title":"Convert an existing Google Apps account to a Google Apps Reseller account","text":"<p>This one was giving me a headache.</p> <p>I was trying to enroll Swift Software Group in the Google Apps Reseller program, but the standard application form did not want to accept our domain name \u201cswiftsoftwaregroup.com\u201d. It kept coming back saying \u201cThis domain has already been registered with Google Apps.\u201d</p> <p>I just found a way around this:</p> <p>Basically, you first have to sign in to your existing Google Apps account and then navigate (in the same browser window) to http://new.googlepartnerconnect.com/Home/enrollment.You should to complete the reseller enrollment from there.</p>"},{"location":"super-agile-replace-email-with-a-shared-blog/","title":"Super Agile: Replace email with a shared blog","text":"<p>At Primo Software, we have switched from email to using shared internal blogs. That has improved communication in several ways:</p> <ul> <li>Instead of emailing multiple people, you now write a post on the blog and all people who are subscribed to it are notified</li> <li>Discussions are visible to everybody including future employees</li> <li>As a side effect, posts have become more substantial. You post when you really have something valuable to share</li> <li>People who prefer email can still choose to receive email notifications, daily digest, weekly digest and so on\u2026</li> <li>Posts are searchable</li> </ul>"},{"location":"the-specified-password-for-user-account-root-is-not-valid-or-failed-to-connect-to-the-database-server/","title":"The specified password for user account \u2018root\u2019 is not valid, or failed to connect to the database server.","text":"<p>While installing WordPress 3.4 via Web Platform Installer 4.0 on IIS 7, at some point the Web Platform Installer asks for MySQL \u2018root\u2019 user password. There you might get this error: \u201cThe specified password for user account \u2018root\u2019 is not valid, or failed to connect to the database server\u201d. That happens even if you enter the correct password.</p> <p>Here is how to fix it:</p> <ul> <li>In the Windows registry, delete the mysql_pwd reg key under HKCU\\Software\\Microsoft\\WebPlatformInstaller</li> <li>Download and install the latest MySql .NET Connector (32 bit). At the time of writing, the latest version of MySql .NET Connector was 6.6.4.</li> </ul>"},{"location":"super-agile-unknown-good-team/","title":"Super Agile: Unknown is good for your team","text":"<p>Encourage developers to work on things or with technologies they do not know. Watch them becoming the fearless masters of technology, who can solve any problem you throw at them.</p>"},{"location":"import-a-sql-dump-from-one-schema-into-another-with-mysql-workbench/","title":"Import a SQL dump from one schema into another with MySQL Workbench","text":"<p>When restoring a MySQL dump from MySQL Workbench, currently it is not possible to specify a different schema than the schema used during the export. The workaround for that is to edit the dump file (which is just a text file) in a text editor and change the name of the schema manually.</p> <p>For example to change the schema name from \u2018old_schema\u2019 to \u2018new_schema\u2019, open the dump file in a text editor and change these two lines:</p> <pre><code>CREATE DATABASE  IF NOT EXISTS 'old_schema' /*!40100 DEFAULT CHARACTER SET utf8 */;\nUSE 'old_schema';\n</code></pre> <p>to this:</p> <pre><code>CREATE DATABASE  IF NOT EXISTS 'new_schema' /*!40100 DEFAULT CHARACTER SET utf8 */;\nUSE 'new_schema';\n</code></pre> <p>After that, import the dump file using MySQL Workbench as usual. Please note that if you exported the old schema with qualified identifiers you would also have to search and replace the schema name everywhere in the dump file, otherwise each object would have the old schema name as prefix.</p>"},{"location":"how-to-configure-tortoisehg-to-remember-your-username-and-password/","title":"How to configure TortoiseHg to remember your username and password","text":"<p>I have been playing with Hg (Mercurial) lately to see if it would be feasible to move our projects at Primo Software from SVN (Subversion) to Mercurial. The things I am looking at are not just the version control capabilities, but also the tools that are available on Windows, Mac and Ubuntu. As part of the tools evaluation I have been playing with TortoiseHg, which seems to be the recommended Hg visual tool for Windows.</p> <p>This post here is about configuring TortoiseHg to remember the username and password and not ask you for those when you do Pull/Push to a remote repository. In the example below I use a Hg repository hosted on bitbucket.org, but the same configuration should be valid for any other remote repository.</p> <p>After you first clone your repository with TortoiseHg you end up with this in your Hg configuration file (i.e. your .hg/hgrc file):</p> <p>``` ini  [ui] username = Valentin Kantchev myemail@primosoftware.com</p> <p>[paths] default = https://myusername@bitbucket.org/primosoftware/projectmap <pre><code>If you do Push and Pull from TortoiseHg it will take your username from the repo URL under the [paths] config, but it will keep asking for your password every time you do this.\n\n![workbench_1](../assets/images/how-to-configure-tortoisehg-to-remember-your-username-and-password/workbench_1.png)\n\n One of the solutions to this is to set your username and password in the TortoiseHg synchronization view:\n\n![workbench_2](../assets/images/how-to-configure-tortoisehg-to-remember-your-username-and-password/workbench_2.png)\n\n Now it\u2019s all good, but to make this work TortoiseHg creates a file called mercurial.ini under your Windows home directory, whichs is normally C:\\\\Users\\\\yourwindowsusername\\\\. In my case the file had this inside:\n\n\n``` ini \n# Generated by TortoiseHg settings dialog\n[ui]\nusername = Valentin Kantchev &lt;myemail@primosoftware.com&gt;\n\n[auth]\nbitbucket.org.prefix = bitbucket.org\nbitbucket.org.username = myusername\nbitbucket.org.password = mypassword\n</code></pre></p> <p>The problem with this file is that the password is stored in it as clear text.</p> <p>Fortunately there is an easy workaround for that: TortoiseHg comes bundled with a Keyring extension, designed for storing authentication passwords securely. However, the Keyring extension is not active by default. To activate it you have to add the following lines in your mercurial.ini file:</p> <pre><code>[extensions]\nmercurial_keyring=\n</code></pre> <p>You can delete the password line under the [auth] section completely as it is not needed at this point. Your final mercurial.ini file should look like this:</p> <pre><code># Generated by TortoiseHg settings dialog\n[ui]\nusername = Valentin Kantchev &lt;myemail@primosoftware.com&gt;\n\n[auth]\nbitbucket.org.prefix = bitbucket.org\nbitbucket.org.username = myusername\n\n[extensions]\nmercurial_keyring=\n</code></pre> <p>Now you can also remove your username from the repository URL. In the .hg/hgrc file in your local repository folder, change this: https://myusername@nullbitbucket.org/primosoftware/projectmap to this: https://bitbucket.org/primosoftware/projectmap</p> <p>Your final .hg/hgrc file should look like this:</p> <pre><code>[ui]\nusername = Valentin Kantchev &lt;myemail@primosoftware.com&gt;\n\n[paths]\ndefault = https://bitbucket.org/primosoftware/projectmap\n</code></pre> <p>This completely removes all authentication info from your local repository folders. Your password is now stored in the Keyring and your user name is stored in <code>C:\\Users\\yourwindowsusername\\mercurial.ini</code>. This way, for example, if you zip your local folder to send it to somebody you cannot accidentally send your source control authentication information with it.</p> <p>Please note that after all changes TortoiseHg might ask you one more time for password. After that it will store and use the password from the Keyring.</p> <p>Here is the last TortoiseHg screenshot. Notice that there is no authentication information visible anywhere:</p> <p></p>"},{"location":"hg-subrepositories-a-how-to-guide-for-the-svnexternals-junkie-toc/","title":"Hg subrepositories: a how-to guide for the \u201csvn:externals\u201d junkie (TOC)","text":""},{"location":"hg-subrepositories-a-how-to-guide-for-the-svnexternals-junkie-toc/#table-of-content","title":"Table of Content","text":"<ol> <li>Repository Setup</li> <li>The Commit/Push, and Pull/Update cycles</li> <li>Summary</li> </ol>"},{"location":"hg-subrepositories-a-how-to-guide-for-the-svnexternals-junkie-part-1/","title":"Hg subrepositories: a how-to guide for the \u201csvn:externals\u201d junkie (Part 1)","text":"<p>This is the first post from a multi-part article about using Mercurial subrepositories when you are switching from Subversion to Mercurial and you heavily used Subversion subrepositories configured via the svn:externals property.</p> <p>Often a common scenario in software development is to have a main project that depends on other projects. Here is an example of how the Subversion \u201ctrunk\u201d for such projects might look like:</p> <p>``` text svn://svnserver/SandboxSvn     trunk         SandboxSvn (main source code)         SanboxDep1Svn (svn:externals link from svn://svnserver/SandboxDep1Svn/trunk)         SanboxDep2Svn (svn:externals link from svn://svnserver/SandboxDep2Svn/trunk) <pre><code>Basically we have a repository at *svn://svnserver/SandboxSvn* that includes the main project called *SandboxSvn* and two projects* SandboxDep1Svn* and *SandboxDep2Svn* on which *SandboxSvn* depends. The dependency projects are linked from two separate Subversion repositories, hosted at *svn://svnserver/SandboxDep1Svn/trunk* and *svn://svnserver/SandboxDep2Svn/trunk* respectively.\n\nYou can create a similar structure in Mercurial by using the Mercurial subrepositories. In the example below, I use BitBucket, so I can test my setup later, but the same steps should be valid for any other shared Mercurial setup. For more information on how to use BitBucket, see the [BitBucket 101](https://confluence.atlassian.com/display/BITBUCKET/Bitbucket+101 \"BitBucket 101\") wiki.\n\nSteps to setup a main project with two dependencies in Mercurial:\n\n1) Create a repository called SandboxRootHg. This will be a containerrepository for both the main project and the dependencies. I set that up at https://bitbucket.org/your-team-name/SandboxRootHg.\n\n2) Create a repository for your main project, e.g. SandboxHg at *https://bitbucket.org/your-team-name/SandboxHg*.\n\n3) Create a repository for each of the dependencies:\n\n- SandboxDep1Hg at *https://bitbucket.org/your-team-name/SandboxDep1Hg*\n- SandboxDep2Hg at *https://bitbucket.org/your-team-name/sandboxDep1Hg*\n\n4) Setup the three dependencies in the container project.\n\nYou first have to clone the container repository locally to your machine. In our case the containeris *SandboxRootHg*, so I cloned that in a new*SandboxRootHg* folder. In the *SandboxRootHg* folder create a *.hgsub* file(note the dot in the*.hgsub*name), and add the *SandboxHg*, *SandboxDep1Hg* and *SandboxDep2Hg* projects to in the *.hgsub* file. Your final *.hgsub* will have three lines in it and will look similar to this:\n\n``` text \nSandboxHg = https://bitbucket.org/your-team-name/SandboxHg\nSandboxDep1Hg = https://bitbucket.org/your-team-name/SandboxDep1Hg\nSandboxDep2Hg = https://bitbucket.org/your-team-name/SandboxDep2Hg\n</code></pre></p> <p>5) In the SandboxRootHg folder, do a Hg/Add to add the .hgsub file to Mercurial, then Hg/Commit. And last, do not forget to do a Hg/Push to update the remote shared repository with your changes.</p> <p>Continue to Hg subrepositories: a how-to guide for the \u201csvn:externals\u201d junkie (Part 2).</p>"},{"location":"hg-subrepositories-a-how-to-guide-for-the-svnexternals-junkie-part-2/","title":"Hg subrepositories: a how-to guide for the \u201csvn:externals\u201d junkie (Part 2)","text":"<p>This is the second post of a multi-part article about Mercurial subrepositories. Please make sure you read Part 1 before reading this post.</p> <p>In Part 1 of this series we created a Mercurial container SandboxRootHgrepository and Mercurial repositories for the main project -SandboxHg,and its two depencies \u2013 SandboxDep1Hg andSandboxDep2Hg. Then we added the main project and dependency projects as subrepositories to SandboxRootHg.</p> <p>In this post we will go through a Change / Push and Pull / Update cycle for the subrepositories. If you followed the steps in Part 1 you will end up with a SandboxRootHgstructure similar to the one shown on this screenshot:</p> <p> </p> <p>Notice the .hgsubstate file. Mercurial added this file to track the subrepository revisions. We will get back to examine this file when we make changes to the projects and we synchronize those changes with the remote shared repository.</p> <p>To simulate a two machine setup I simply cloned the SandboxRootHgshared remote repository to two separate folders named Work and Home respectively. After that I created two groups in TortoiseHg Workbench registry and rearranged the groups and the repositories to reflect my new directory structure. Here is another screenshot:</p> <p></p> <p>We are now ready do do some testing.</p> <p>Go to the Home folder and add a new file TestFile-1.txt to the SandboxRootHg/SandboxHg folder, right click on the new file and select TortoiseHg/Add Files from the menu, then do Hg Commit. So far the changes have been committed to your local repository clone. You still have to Push the changes to remote shared repository. You can do that in the Synchronize view ofthe TortoiseHg Workbench.</p> <p></p> <p>Now go to the Work folder,right click onthe SandboxRootHg folder and select Hg Workbench from the menu. Switch to Synchronize view and pull the changes from the remote repository. Hmm.. Nothing came in the Work/SandboxRootHg/SandboxHg folder. We should have received a change set with the TestFile-1.txt. What happened? We added TestFile-1.txt  in Home/SandboxRootHg/SandboxHg, committed and pushed the change to the remote server. However we forgot to commit and push the change in the container repository: Home/SandboxRootHg. Right click on Home/SandboxRootHg and select Hg Commit from the menu.</p> <p></p> <p>If you open the .hgsubstate file under the Home/SandboxRootHg folder you will see that after the commit the Mercurial updated the revision id of the SandBoxHg project. The .hgsubstate contents changed from this:</p> <pre><code>0000000000000000000000000000000000000000 SandboxDep1Hg\n0000000000000000000000000000000000000000 SandboxDep2Hg\n0000000000000000000000000000000000000000 SandboxHg\n</code></pre> <p>to this:</p> <pre><code>0000000000000000000000000000000000000000 SandboxDep1Hg\n0000000000000000000000000000000000000000 SandboxDep2Hg\n4090583f58e67f599b5141ed2551be3eb4fe5c8c SandboxHg\n</code></pre> <p>Now all we have to do is Push the Home/SandboxRootHg changes to the remote shared repository.</p> <p>Go again to the Work folder,right click on SandboxRootHg and select Hg Workbench from the menu. Switch to the Synchronize view and pull the changes from the remote repository. This is how my Hg Workbench looks like after the update:</p> <p></p> <p>Notice on the screenshot above that our working copy still does not have the latest code in it. TortoiseHg makes alerts us by displaying the \u201cNot a head revision!\u201d message in red. One of the differences between Mercurial and Subversion is that in Mercurial you have a two-step code update. Basically the Hg/Pull command only downloads the latest change sets from a remote shared repository. After you pull the changes you still have to apply them by issuing an Hg/Update command.</p> <p>Go to the Work folder, right click on the SandboxRootHg folder, and select TortoiseHg &gt; Update from the menu. This updates our working copy with the changes we downloaded when did Hg/Pull.</p> <p></p> <p>If you check the Work/SandboxRootHg/SandboxHg folder you will see that the TestFile-1.txt file is now there as it should be.</p> <p>Continue to Hg subrepositories: a how-to guide for the \u201csvn:externals\u201d junkie (Part 3)</p>"},{"location":"hg-subrepositories-a-how-to-guide-for-the-svnexternals-junkie-part-3/","title":"Hg subrepositories: a how-to guide for the \u201csvn:externals\u201d junkie (Part 3)","text":"<p>This post summarizes the Mercurial subrepository vs the Subversion externals experience. This is the third and last post of a multi-part article about Mercurial subrepositories. Please make sure you read Part 1 and Part 2 before reading this post.</p> <p>In a few words, Mercurial subrepositories are very similar to Subversion \u201csvn:externals\u201d and can be used pretty much the same way. However, there are some differences in the workflow, because of the distributed nature of Mercurial. Here are the main differences from Subversion:</p> <ul> <li>You always work in a copy / clone of a remote shared repository.</li> <li>You may commit changes multiple times, but those changes are not visible to others unless you push to the remote shared repository.</li> <li>A commit + push in a subrepository is treated as a local change in the top-level root repository. To make the root change permanent, you have to do a commit + push of the root repository as well.</li> <li>A pull from a remote repository just downloads the latest available changes. In order to apply/merge the changes, you have to manually update your working copy.</li> </ul> <p>On good thing about the pull+update workflow is that, it guards against accidentally losing local changes and allows you to do code merges at your convenience.You can also revert an update and continue in your local copy when an update breaks a lot of code and requires hard manual merge labor. You can update your working copy again later, when you are ready for the code merge.</p>"},{"location":"getting-started-with-git-and-bitbucket-on-windows/","title":"Getting started with Git and BitBucket on Windows","text":"<p>This post describes setting up Git on Windows and using a private remote Git repository hosted on BitBucket.org. Here it goes:</p> <p>1) Start by downloading Git fromthe msysgit site. At the time of writing the latest installer was Git-1.8.1.2-preview20130201.exe. For some unknown reason the installers are labeled \u201cpreview\u201d which normally suggests unfinished product, but the versions are actually fully functional.</p> <p>After downloading, run the installer and follow the steps. You may use the default options on each screen, but since we are going to try TortoiseGit later, on the first screen select \u201cSimple context menu (Registry based)\u201d and check only \u201cGit Bash Here\u201d. That will keep to your Windows Explorer context menu less cluttered.</p> <p>2) Install TortoiseGit. At the time of this writing the latest version was 1.8.1. There is nothing special about installing TortoiseGit.</p> <p>To verify the TortoiseGit installer integrated with your msysgit installation: right click anywhere in Windows Explorer and select TorstoiseGit &gt; Settings from the context menu, then make sure you have the correct paths for Git.exe under the General section and the ssh client under the Network section.</p> <p> </p> <p>3) Install the Credential Caching Git extension. We will be using Git via <code>https://</code> instead of <code>ssh</code> and that extension caches the username and password, so we do not have to type them all the time. Download git-credential-winstore and GitPad for Windows 8 (.NET 4.0 required), unzip,copy git-credential-winstore.exe to the Git bin directory and run it. By default Git is installed in <code>C:\\Program Files (x86)\\Git\\bin</code> on 64 Bit systems. Open your global .gitconfig file. The global .gitconfig file is in your home directory which on Windows Vista and above should be under <code>C:\\Users\\&lt;yourname&gt;</code>. Verify the you have this line in .gitconfig*:</p> <pre><code>[credential]\nhelper = !~/AppData/Roaming/GitCredStore/git-credential-winstore\n</code></pre> <p>4) Optionally you may want to change the default text editor that Git uses, e.g. you might need that for commit messages. The default editor in msysgit is Unix VIM. You can change that to Notepad with GitPad \u2013 a small utility found in the credential caching extension zip. Simply copy GitPad.exe inC:\\Program Files (x86)\\Git\\bin and run it.</p> <p>5) Create an empty Git repository onBitbucket.org \u2013 that will be your shared repository. If you are new to BitBucket you can check this shorttutorialon how to create a BitBucket account and a Git repo- the process is rather straightforward. For this demo create a repo and name it SandboxGit. Please note that BitBucket will create a bare repository. A bare repository is one without branches.</p> <p> </p> <p>6) We are now ready to start playing with the SandboxGit repo. If you are new to Git, it is better to start in Git Bash at the beginning just to get a feeling of Git. Knowing Git command line will help you understand what TortoiseGit or any other GUI tool does later, because in almost all cases, all the GUI tools generate and execute Git commands for you.</p> <ul> <li>Git Bash</li> <li>TortoiseGit</li> </ul>"},{"location":"getting-started-with-git-and-bitbucket-on-windows/#configure-default-name-and-email-for-commits","title":"Configure default name and email for commits","text":"<p>In Windows Explorer, go to a place where you want to put your working directory, right click and selectGit Bash Herefrom the menu.</p> <p>In Git Bash prompt enter:</p> <pre><code>git config --global user.name \"user\"\ngit config --global user.email \"user@domain.com\"\n</code></pre> <p>After the changes, <code>C:\\Users\\&lt;yourname&gt;\\.gitconfig</code> should have the user configuration in it:</p> <pre><code>[credential]\nhelper = !~/AppData/Roaming/GitCredStore/git-credential-winstore\n[user]\nname = user\nemail = user@domain.com\n</code></pre> <p>Also we can get the same result with the <code>git config</code> command:</p> <pre><code>git config --global -l \\\ncredential.helper=!~/AppData/Roaming/GitCredStore/git-credential-winstore \\\nuser.name=user \\\nuser.email=user@domain.com\n</code></pre>"},{"location":"getting-started-with-git-and-bitbucket-on-windows/#configure-disable-line-ending-conversion","title":"Configure / disable line ending conversion","text":"<pre><code>git config --global core.autocrlf false\n</code></pre> <p>Without that we will get CR/LF conversion warning on each commit, e.g. something like this will be shown for each new line in your source:</p> <pre><code>warning: LF will be replaced by CRLF in HelloWorld.cpp.\nThe file will have its original line endings in your working directory.\n</code></pre> <p>Modern development tools support both CR/LF and LF line endings, so we do not need Git to do line ending conversion.</p>"},{"location":"getting-started-with-git-and-bitbucket-on-windows/#clone-the-remote-repository","title":"Clone the remote repository","text":"<pre><code>git clone https://user@bitbucket.org/primosoftware/sandboxgit.git ./SandboxGit\nCloning into './SandboxGit'...\nwarning: You appear to have cloned an empty repository.\n</code></pre> <p>The first time you do this Git will ask for a BitBucket.org password. After that it will remember the password, because of the credentials caching extension thatwe installed in step 3.</p>"},{"location":"getting-started-with-git-and-bitbucket-on-windows/#check-the-remote-configuration","title":"Check the remote configuration","text":"<p>``` bash cd ./SandboxGit git remote show origin <pre><code>``` bash\ngit remote show origin\n* remote origin\nFetch URL: https://user@bitbucket.org/primosoftware/sandboxgit.git\nPush URL: https://user@bitbucket.org/primosoftware/sandboxgit.git\nHEAD branch: (unknown)\nLocal branch configured for 'git pull':\nmaster merges with remote master\n</code></pre></p> <p>Basically we have:</p> <ul> <li>An <code>origin</code> alias that points to a remote repo at https://user@nullbitbucket.org/primosoftware/sandboxgit.git</li> <li>A local branch <code>master</code> that will merge with the remote branch <code>master</code>. However, the remote <code>master</code> branch does not exist yet. It will be created when we do our first commit and push.</li> <li>A remote HEAD branch that is unknown.</li> </ul> <p>Think of HEAD as a symlink/shortcut to a branch. The HEADis unknown because there are no branches in the remote repository yet. Normally HEAD points to themasterbranch.</p>"},{"location":"getting-started-with-git-and-bitbucket-on-windows/#add-a-file-and-commit","title":"Add a file and commit","text":"<p>In the SandboxGit folder create a fileHelloWorld.cppwith some code in it. For example:</p> <pre><code>#include &lt;iostream&gt;\nusing namespace std;\nvoid main()\n{\n    cout &lt;&lt; \"Hello World!\" &lt;&lt; endl;   \n    cout &lt;&lt; \"Welcome to Git\" &lt;&lt; endl; \n}\n</code></pre> <p>In Git Bash do <code>git add HelloWorld.cpp</code>:</p> <p><pre><code>git add HelloWorld.cpp\n</code></pre> ... and <code>git commit</code> \u2013 enter \u201cInitial commit.\u201d when Git asks for a commit message.</p> <pre><code>git commit .\n[master (root-commit) 8ed71ed] Initial commit.\n1 file changed, 7 insertions(+)\ncreate mode 100644 HelloWorld.cpp\n</code></pre> <p>The commit is local. Up to this point we have done local changes only. The remote repository on BitBucket.org is still untouched.</p> <p> </p> <p>In order for others to see the changes we have to push the changes to the remote location. That is done with thegit push command.</p>"},{"location":"getting-started-with-git-and-bitbucket-on-windows/#configure-default-push-style","title":"Configure default \u201cpush\u201d style","text":"<p>Git pushcan work in one of two ways:</p> <ul> <li>matching: pushes all local branches to remote branches with the same name. This may lead to unwanted remote branches created by accident.</li> <li>simple: pushes only the current local branch to its remote brother which is usually a remote branch with the same name. This is a more intuitive behavior.</li> </ul> <p>We will use the simple push:</p> <pre><code>git config --global push.default simple\n</code></pre>"},{"location":"getting-started-with-git-and-bitbucket-on-windows/#push-to-the-remote-repository","title":"Push to the remote repository","text":"<pre><code>git push\nCounting objects: 3, done.\nDelta compression using up to 8 threads.\nCompressing objects: 100% (2/2), done.\nWriting objects: 100% (3/3), 322 bytes, done.\nTotal 3 (delta 0), reused 0 (delta 0)\nremote: bb/acl: user is allowed. accepted payload.\nTo https://user@bitbucket.org/primosoftware/sandboxgit.git\n    * [new branch]      master -&gt; master\n</code></pre> <p>Verify that now we have a remote branch called master:</p> <p>``` bash git remote show origin * remote origin     Fetch URL: https://user@bitbucket.org/primosoftware/sandboxgit.git     Push  URL: https://user@bitbucket.org/primosoftware/sandboxgit.git     HEAD branch: master     Remote branch:     master tracked     Local branch configured for 'git pull':     master merges with remote master     Local ref configured for 'git push':     master pushes to master (up to date) <pre><code>We are done.\n\n#### Configure default name and email for commits\n\nRight click anywhere in Windows Explorer and select **TorstoiseGit &gt; Settings** from the context menu, then enter your name and email on under the **Git** section.\n\n![tortoisegit-git-settings-config-name-email](../assets/images/getting-started-with-git-and-bitbucket-on-windows/tortoisegit-git-settings-config-name-email.png) \n\nClick *Edit global .gitconfig*. Verify that the *.gitconfig* file now contains the user configuration:\n\n ``` ini\n[credential]\nhelper = !~/AppData/Roaming/GitCredStore/git-credential-winstore\n\n[user]\nname = user\nemail = user@domain.com\n</code></pre></p>"},{"location":"getting-started-with-git-and-bitbucket-on-windows/#configure-disable-line-ending-conversion_1","title":"Configure / disable line ending conversion","text":"<p>Again in the TorstoiseGit &gt; Settings &gt; Git section, in the \"Auto CrLf convert\" group, uncheck the AutoCrlf box.</p> <p>Without that we will get CR/LF conversion warning on each commit, e.g. something like this will be shown for each new line in your source code:</p> <pre><code>warning: LF will be replaced by CRLF in HelloWorld.cpp.\nThe file will have its original line endings in your working directory.\n</code></pre> <p>Modern development tools support both CR/LF and LF line endings, so we do not need Git to do line ending conversion.</p>"},{"location":"getting-started-with-git-and-bitbucket-on-windows/#clone-the-remote-repository_1","title":"Clone the remote repository","text":"<p>In Windows Explorer, go to a place where you want to put your working directory, right click and select Git Clone from the menu.</p> <p> </p> <p> </p>"},{"location":"getting-started-with-git-and-bitbucket-on-windows/#check-the-remote-configuration_1","title":"Check the remote configuration","text":"<p>Right click on the <code>SandboxGit</code> folder in Windows Explorer and select TorstoiseGit &gt; Settings from the context menu, then go to the Git &gt; Remote section. Verify the remote url to which the origin alias points.</p> <p> </p>"},{"location":"getting-started-with-git-and-bitbucket-on-windows/#add-a-file-and-commit_1","title":"Add a file and commit","text":"<p>In the SandboxGit folder create a fileHelloWorld.cppwith some code in it. For example:</p> <pre><code>#include &lt;iostream&gt;\nusing namespace std;\nvoid main()\n{\n    cout &lt;&lt; \"Hello World!\" &lt;&lt; endl;   \n    cout &lt;&lt; \"Welcome to Git\" &lt;&lt; endl; \n}\n</code></pre> <p>Right click on the <code>HelloWorld.cpp</code> file and select TortoiseGit &gt; Add. Check the <code>HelloWorld.cpp</code> file and click OK.</p> <p> </p> <p>Right click on the <code>HelloWorld.cpp</code> file again and select Git Commit -&gt; Master. Enter \u201cInitial commit.\u201d for a message. Check the <code>HelloWorld.cpp</code> file and click OK.</p> <p> </p> <p> </p> <p>The commit is local. Up to this point we have done local changes only. The remote repository on BitBucket.org is still untouched.</p> <p> </p>"},{"location":"getting-started-with-git-and-bitbucket-on-windows/#push-to-the-remote-repository_1","title":"Push to the remote repository","text":"<p>Right click on theSandboxGitfolder in Windows Explorer and select TorstoiseGit &gt; Push from the context menu. Click OK.</p> <p> </p> <p> </p> <p>We are done.</p>"},{"location":"installing-mercurial-and-tortoisehg-on-ubuntu/","title":"Installing Mercurial and TortoiseHg on Ubuntu","text":"<p>This is a step-by-step guide on installing Mercurial and TortoiseHg on Ubuntu, and setting up a BitBucket account. This was tested on Ubuntu 12.04 LTS and Ubuntu 12.10.</p>"},{"location":"installing-mercurial-and-tortoisehg-on-ubuntu/#install-tortoisehg","title":"Install TortoiseHg","text":"<p>Add TortoiseHg PPA (<code>https://launchpad.net/~tortoisehg-ppa/+archive/releases</code>)</p> <pre><code>sudo add-apt-repository ppa:tortoisehg-ppa/releases\nsudo apt-get update\nsudo apt-get install tortoisehg tortoisehg-nautilus\n</code></pre> <p>That installs Mercurial 2.5.1 and TortoiseHg 2.7.</p>"},{"location":"installing-mercurial-and-tortoisehg-on-ubuntu/#restart-nautilus","title":"Restart Nautilus","text":"<pre><code>nautilus -q\n</code></pre>"},{"location":"installing-mercurial-and-tortoisehg-on-ubuntu/#check-installation","title":"Check installation","text":"<pre><code>thg &amp;\n</code></pre> <p>TorstoiseHg Workbench should open.</p>"},{"location":"installing-mercurial-and-tortoisehg-on-ubuntu/#configure-user-name-for-commits","title":"Configure user name for commits","text":"<pre><code>thg &amp;\n</code></pre> <p>Then select File | Settings from the top menu.</p> <p>In the Commit section enter the username that will be used with commits.  The common format is: Full Name (e.g. Valentin Kantchev )</p>"},{"location":"installing-mercurial-and-tortoisehg-on-ubuntu/#install-mercurial-keyring-extension","title":"Install Mercurial keyring extension","text":"<pre><code>sudo apt-get install python-setuptools\nsudo easy_install keyring\nsudo easy_install mercurial_keyring\n</code></pre> <p>Add these lines to the .hgrc (in your home directory):</p> <pre><code>[extensions]\nmercurial_keyring =\n</code></pre> <p>That allows Mercurial to store and use user credentials in the Ubuntu keychain.</p>"},{"location":"installing-mercurial-and-tortoisehg-on-ubuntu/#setup-bitbucket-user-optional","title":"Setup BitBucket user (optional)","text":"<p>Add these lines to your global .hgrc (i.e. /home/valentin/.hgrc), change the username to your own:</p> <pre><code>[auth]\nbitbucket.org.prefix = bitbucket.org/&lt;myteamname&gt;\nbitbucket.org.username = &lt;mybitbucketuser&gt;\n</code></pre> <p>My final <code>.hgrc</code> looks like this:</p> <pre><code># Generated by TortoiseHg settings dialog\n\n[ui]\nusername = Valentin Kantchev\n\n[auth]\nbitbucket.org.prefix = bitbucket.org/&lt;myteamname&gt;\nbitbucket.org.username =\u00a0&lt;mybitbucketuser&gt;\n\n[extensions]\nmercurial_keyring =\n</code></pre>"},{"location":"ubuntu-how-to-add-open-in-terminal-to-the-nautilus-context-menu/","title":"Ubuntu: how to add \u201cOpen in Terminal\u201d to the Nautilus context menu","text":"<p>This one is easy:</p> <ol> <li>Install nautilus-open-terminal package.</li> <li>Restart Nautilus.</li> </ol> <pre><code>sudo apt-get install nautilus-open-terminal\nnautilus -q\n</code></pre>"},{"location":"mercurial-sourcetree-and-bitbucket-on-mac/","title":"Starting with Mercurial, BitBucket and SourceTree on Mac","text":"<p>This is a quick step-by-step tutorial on starting with Mercurial and BitBucket on Mac. This tutorial was done on Mac OS 10.8.2.</p>"},{"location":"mercurial-sourcetree-and-bitbucket-on-mac/#install-mercurial","title":"Install Mercurial","text":"<p>The easiest way to do that is to download and install the Mercurial 2.5.4 for OS X 10.8 binary package from the official Mercurial site. After downloading the file unzip it and open <code>mercurial-2.5.4+20130405-py2.7-macosx10.8.mpkg</code>.</p>"},{"location":"mercurial-sourcetree-and-bitbucket-on-mac/#verify-mercurial-installation","title":"Verify Mercurial Installation","text":"<p>Open Terminal and type <code>hg \u2013version</code>.</p> <pre><code>hg --version\nMercurial Distributed SCM (version 2.5.4+20130405)\n(see http://mercurial.selenic.com for more information)\n\nCopyright (C) 2005-2012 Matt Mackall and others\nThis is free software; see the source for copying conditions. There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n</code></pre>"},{"location":"mercurial-sourcetree-and-bitbucket-on-mac/#install-mercurial-keyring-extension","title":"Install Mercurial Keyring Extension","text":"<p>In Terminal:</p> <pre><code>sudo easy_install keyring\nsudo easy_install mercurial_keyring\n</code></pre> <p>Next, add these lines to <code>.hgrc</code> (in your home directory):</p> <pre><code>[extensions]\nmercurial_keyring =\n</code></pre> <p>Now Mercurial will store and use user credentials to/from the Mac OS keychain.</p>"},{"location":"mercurial-sourcetree-and-bitbucket-on-mac/#configure-bitbucket-user","title":"Configure BitBucket User","text":"<p>There are a few ways to do this, but the best is via [ui] and [auth] sections in .hgrc (in your home directory). Your final .hgrc file should look like this:</p> <pre><code>[ui]\nusername = Valentin Kantchev &lt;youremail@&lt;span class=\"oe_displaynone\"&gt;null&lt;/span&gt;yourdomain.com&gt;\n\n[auth]\nbitbucket.org.prefix = bitbucket.org\nbitbucket.org.username = yourusername\n\n[extensions]\nmercurial_keyring=\n</code></pre>"},{"location":"mercurial-sourcetree-and-bitbucket-on-mac/#install-atlassian-sourcetree","title":"Install Atlassian SourceTree","text":"<p>Go to www.sourcetreeapp.com and download SourceTree for Mac. At the time of this writing the latest version of SourceTree was 1.5.8. SourceTree for Mac comes packaged as a dmg file \u2013 after you open the dmg file you install the app the normal Mac way \u2013 by dragging SourceTree.app into your Applications folder.</p>"},{"location":"mercurial-sourcetree-and-bitbucket-on-mac/#configure-sourcetree","title":"Configure SourceTree","text":"<p>I recommend configuring SourceTree to use the system Mercurial. That way you get consistent Hg experience when working in Terminal and in the SourceTree GUI. To do that, run SourceTree and press \u201cCommand + ,\u201d to open Preferences and then click Use System Mercurial.</p> <p> </p>"},{"location":"mercurial-sourcetree-and-bitbucket-on-mac/#clone-a-bitbucket-repository","title":"Clone a BitBucket Repository","text":"<p>In the SourceTree Bookmarks window:</p> <ol> <li>Click on the Add Repository button.</li> <li>Enter the remote repository url and the local repository folder.</li> <li>Click Clone</li> </ol> <p> </p>"},{"location":"powershell-prompt-here/","title":"PowerShell Prompt Here","text":"<p>I have been doing some scripting in PowerShell 3.0 lately and I found this post by Scott Hanselman. Just go to that post and download powershellhere.inf, right click on it and click Install. It will give you a nice \u201cPowerShell Prompt Here\u201d context menu in Windows Explorer.</p>"},{"location":"upgrading-a-web-app-from-asp-net-mvc-3-to-asp-net-mvc-4/","title":"Upgrading a web app from ASP.NET MVC 3 to ASP.NET MVC 4","text":"<p>I recently had to update a web application from ASP.NET MVC 3 to ASP.NET MVC 4. Here are the the steps I had to go through to do that:</p> <p>1) Update your project references. The easiest way to do that is to install ASP.NET MVC 4.0 from Package Manager Console:</p> <pre><code>Install-Package Microsoft.AspNet.Mvc\n</code></pre> <p>That will download and install all necessary components and will update your project references.</p> <p>2) In your root Web.config, in <code>&lt;system.web&gt; / &lt;assemblies&gt;</code>  section, update the assembly versions for <code>System.Web.Helpers</code>, <code>System.Web.Mvc</code> and <code>System.Web.WebPages</code>, i.e. replace this:</p> <pre><code>&lt;assemblies&gt;\n    &lt;add assembly=\"System.Web.Abstractions, Version=4.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\" /&gt;\n    &lt;add assembly=\"System.Web.Helpers, Version=1.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\" /&gt;\n    &lt;add assembly=\"System.Web.Routing, Version=4.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\" /&gt;\n    &lt;add assembly=\"System.Web.Mvc, Version=3.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\" /&gt;\n    &lt;add assembly=\"System.Web.WebPages, Version=1.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\" /&gt;\n&lt;/assemblies&gt;\n</code></pre> <p>with this:</p> <pre><code>&lt;assemblies&gt;\n    &lt;add assembly=\"System.Web.Abstractions, Version=4.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\" /&gt;\n    &lt;add assembly=\"System.Web.Helpers, Version=2.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\" /&gt;\n    &lt;add assembly=\"System.Web.Routing, Version=4.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\" /&gt;\n    &lt;add assembly=\"System.Web.Mvc, Version=4.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\" /&gt;\n    &lt;add assembly=\"System.Web.WebPages, Version=2.0.0.0, Culture=neutral, PublicKeyToken=31BF3856AD364E35\" /&gt;\n&lt;/assemblies&gt;\n</code></pre> <p>3) In <code>Views\\\\Web.config</code>, replace all instances of <code>System.Web.Mvc, Version=3.0.0.0</code> and <code>System.Web.WebPages.Razor, Version=1.0.0.0</code> with <code>System.Web.Mvc, Version=4.0.0.0</code> and <code>System.Web.WebPages.Razor, Version=2.0.0.0</code>.</p> <p>Those three basic changes were enough to get my web application running. Depending on your application you may have to do more changes. For a complete list of all changes that might be required, check out the upgrade section in the ASP.NET MVC 4 release notes.</p>"},{"location":"aps-net-mvc-4-could-not-load-file-or-assembly-dotnetopenauth-core-version-4-0-0-0/","title":"ASP.NET MVC 4: Could not load file or assembly DotNetOpenAuth.Core, Version=4.0.0.0","text":"<p>I got this error in an ASP.NET MVC 4 application after installing DotnetOpenAuth via the Package Manager Console:</p> <pre><code>Could not load file or assembly 'DotNetOpenAuth.Core, Version=4.0.0.0, Culture=neutral, PublicKeyToken=2780ccd10d57b246' or one of its dependencies. The located assembly's manifest definition does not match the assembly reference. (Exception from HRESULT: 0x80131040)\n</code></pre> <p>The application was actually upgraded earlier from ASP.NET MVC 3, i.e. it was not autogenerated by Visual Studio 2012. The pre-binding info in the exception was:</p> <pre><code>=== Pre-bind state information ===\nLOG: User = NT AUTHORITY\\NETWORK SERVICE\nLOG: DisplayName = DotNetOpenAuth.Core, Version=4.0.0.0, Culture=neutral, PublicKeyToken=2780ccd10d57b246\n    (Fully-specified)\nLOG: Appbase = file:///\nLOG: Initial PrivatePath = \\bin\nCalling assembly : Microsoft.Web.WebPages.OAuth, Version=2.0.0.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35.\n===\nLOG: This bind starts in default load context.\nLOG: Using application configuration file: \\web.config\nLOG: Using host configuration file: C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\aspnet.config\nLOG: Using machine configuration file from C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\config\\machine.config.\nLOG: Post-policy reference: DotNetOpenAuth.Core, Version=4.0.0.0, Culture=neutral, PublicKeyToken=2780ccd10d57b246\nLOG: Attempting download of new URL file:////DotNetOpenAuth.Core.DLL.\nLOG: Attempting download of new URL file:////DotNetOpenAuth.Core/DotNetOpenAuth.Core.DLL.\nLOG: Attempting download of new URL file:////DotNetOpenAuth.Core.DLL.\nWRN: Comparing the assembly name resulted in the mismatch: Minor Version\nERR: Failed to complete setup of assembly (hr = 0x80131040). Probing terminated.\n</code></pre> <p>The key pieces of information here are at lines 3 and 7. Basically, Microsoft.Web.WebPages.OAuth needs DotNetOpenAuth.Core 4.0.0.0, but the DotNetOpenAuth.Core I have is version4.3.0.0.</p> <p>The solution is to add these lines under the / section of the root Web.config: <pre><code>&lt;dependentAssembly&gt;\n    &lt;assemblyIdentity name=\"DotNetOpenAuth.AspNet\" publicKeyToken=\"2780ccd10d57b246\" culture=\"neutral\" /&gt;\n    &lt;bindingRedirect oldVersion=\"0.0.0.0-4.3.0.0\" newVersion=\"4.3.0.0\" /&gt;\n&lt;/dependentAssembly&gt;\n&lt;dependentAssembly&gt;\n    &lt;assemblyIdentity name=\"DotNetOpenAuth.Core\" publicKeyToken=\"2780ccd10d57b246\" culture=\"neutral\" /&gt;\n    &lt;bindingRedirect oldVersion=\"0.0.0.0-4.3.0.0\" newVersion=\"4.3.0.0\" /&gt;\n&lt;/dependentAssembly&gt;\n</code></pre> <p>The above solution works for other packages that ASP.NET MVC 4 depends on. For example, if you upgrade WebGrease from 1.0.0.0 to 1.3.0.0, you have to add this to the / section: <pre><code>&lt;dependentAssembly&gt;\n    &lt;assemblyIdentity name=\"WebGrease\" publicKeyToken=\"31bf3856ad364e35\" culture=\"neutral\" /&gt;\n    &lt;bindingRedirect oldVersion=\"0.0.0.0-1.3.0.0\" newVersion=\"1.3.0.0\" /&gt;\n&lt;/dependentAssembly&gt;\n</code></pre>"},{"location":"super-agile-accept-that-your-product-will-never-be-100-complete/","title":"Super Agile: Accept that your product will never be 100% complete","text":"<p>We now follow thesesimple rules for all our projects:</p> <ul> <li>Have a clear product vision / master plan / strategy. This is essential.</li> <li>A grand product vision can be realized only in small incremental steps.</li> <li>Version 1.0 should have the bare minimum of features, not more, not less.</li> <li>Each incremental release must add value for your customers.</li> <li>A high-quality and feature complete product is a natural result of all of the above.</li> </ul>"},{"location":"setup-google-analytics-for-a-bitbucket-repository/","title":"Setup Google Analytics for a Bitbucket repository","text":"<p>The idea is to create a new Google Analytics property for Bitbucket and then have a separate Google Analytics profiles for each repository. That way I end up with one profile per repository neatly grouped under the Bitbucket property. In the profiles, I also use filters to include only the traffic for the corresponding repository.</p> <p>This post is about myself setting up Google Analytics for our AVBlocks-Samples repository, so in the steps below I use the \u201cAVBlocks-Samples\u201d name and the corresponding URL. Needless to say, when going through the steps, you will use the name and URL of your own Bitbucket repo. OK, here it goes:</p>"},{"location":"setup-google-analytics-for-a-bitbucket-repository/#create-a-new-google-analytics-property-called-bitbucket","title":"Create a new Google Analytics property called Bitbucket","text":"<ol> <li>Go to Google Analytics and login into your account.</li> <li>Click on the Admin link at the top right corner.</li> <li>Click on the property drop-down list and then select the New Property at the bottom.</li> <li>Select \u201cClassic Analytics\u201d for tracking method.</li> <li>Under Website Name, type \u201cBitbucket\u201d.</li> <li>Under Web Site URL, select \u201chttps://\u201d and type \u201cbitbucket.org\u201d.</li> <li>Click [Get Tracking ID]</li> </ol>"},{"location":"setup-google-analytics-for-a-bitbucket-repository/#add-the-tracking-id-to-the-bitbucket-repository","title":"Add the Tracking ID to the Bitbucket repository","text":"<p>Google Analytics will generate a new tracking ID for you, something that looks like \u201cUA-123456-78\u2033.</p> <ol> <li>Copy the Tracking ID that Google generated</li> <li>Go to the repository admin page on Bitbucket</li> <li>Paste the Tracking ID into the \u201cGoogle Analytics key\u201d field.</li> </ol> <p> </p> <p>## Update the Google Analytics profile</p> <ol> <li>Go back to Google Analytics admin page</li> <li>Select \u201cBitbucket\u201d for property</li> <li>Select \u201cAll Web Site Data\u201d for profile</li> <li>Click \u201cView Settings\u201d</li> <li>Update the Website\u2019s URL with the full URL of your bitbucket repository.</li> <li>In my case I put \u201chttps://\u201d and \u201cbitbucket.org/primosoftware/avblocks-samples\u201d.</li> <li>If you plan to have multiple repo profiles under the Bitbucket property, I recommend changing the View name to something other than \u201cAll Web Site Data\u201d. I my case, I named my property \u201cAVBlocks-Samples\u201d.</li> <li>Click Apply.</li> </ol> <p> </p>"},{"location":"setup-google-analytics-for-a-bitbucket-repository/#setup-a-profile-filter","title":"Setup a profile filter","text":"<ol> <li>Go back to Google Analytics admin page</li> <li>Select \u201cBitbucket\u201d for property</li> <li>Select \u201cAVBlocks-Samples\u201d for profile</li> <li>Click \u201cView Settings\u201d</li> <li>Click \u201cFilters\u201d and then on the +New Filter button.</li> <li>Type \u201cAVBlocks-Samples\u201d for Filter Name</li> <li>Select \u201cPredefined filter\u201d for Filter Type</li> <li>Select \u201cinclude only\u201d, \u201ctraffic to subdirectories\u201d, \u201cthat begin with\u201d</li> <li>Type \u201c/primosoftware/avblocks-samples/\u201d for Subdirectory</li> <li>Select \u201cNo\u201d for Case Sensitive</li> <li>Click Save</li> </ol>"},{"location":"configuring-phpcurl-root-certificates-windows-server/","title":"Configuring PHP / CURL root certificates on Windows Server","text":"<p>This post is about configuring PHP/CURL root certificates for a WordPress installation running on Windows Server 2008 R2 / IIS 7.5.</p> <p>Yesterday I was trying to add an RSS feed to the AVBlocks Wiki Site and I got this error:</p> <p>``` text WP HTTP Error: SSL certificate problem, verify that the CA cert is OK. Details: error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed <pre><code>In my case the [feed](https://groups.google.com/forum/feed/avblocks-support/msgs/rss.xml?num=3) was coming from the [AVBlocks Group](https://groups.google.com/forum/#!forum/avblocks) on Google. However, the Google Groups feeds are served via secure https:// protocol and that requires SSL for server-to-server communication. The problem is that WordPress uses *php\\_curl*, and on a standard PHP installation of WordPress, *curl* does not come with the root certificate authorities installed.\n\nHere is how to fix it:\n\n1. You need to be running PHP 5.3.7 or later.\n2. Download [mk-ca-bundle.vbs](https://raw.github.com/bagder/curl/master/lib/mk-ca-bundle.vbs) from the [Curl](https://github.com/bagder/curl/tree/master/lib) repository on GitHub.\n3. Open a Command Prompt as Administrator and go to the directory in which you downloaded `mk-ca-bundle.vbs`.\n4. Run `mk-ca-bundle.vbs`. Accept the default filename and do not include the text information for each certificate.\n5. After running this you will end up with a file `ca-bundle.crt`.\n6. Copy that to a known location, e.g. `{path}/ca-bundle.crt`.\n7. Add `curl.cainfo={path}/ca-bundle.crt` to php.ini. See [PHP Runtime Configuration](http://php.net/manual/en/curl.configuration.php) for more details: \n\n``` ini\n[PHP]\n\n;;;;;;;;;;;;;;;;;;;\n; CURL Settings ;\n;;;;;;;;;;;;;;;;;;;\n\ncurl.cainfo={path}/ca-bundle.crt\n</code></pre> 8. Restart the IIS web site</p>"},{"location":"upgrade-gcc-4-7-ubuntu-12-04/","title":"How to upgrade GCC to 4.7+ on Ubuntu 12.04","text":"<p>Note: This is only needed on Ubuntu 12.04. Ubuntu 12.10 already comes with GNU C++ 4.7 and above.</p>"},{"location":"upgrade-gcc-4-7-ubuntu-12-04/#install","title":"Install","text":"<pre><code>sudo add-apt-repository ppa:ubuntu-toolchain-r/test\nsudo apt-get update\nsudo apt-get install gcc-4.7 g++-4.7\n</code></pre>"},{"location":"upgrade-gcc-4-7-ubuntu-12-04/#update-alternatives","title":"Update Alternatives","text":""},{"location":"upgrade-gcc-4-7-ubuntu-12-04/#add-gcc-47","title":"Add GCC 4.7","text":"<pre><code>sudo update-alternatives --remove gcc /usr/bin/gcc-4.6\nsudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.7 60 --slave /usr/bin/g++ g++ /usr/bin/g++-4.7\nsudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.6 40 --slave /usr/bin/g++ g++ /usr/bin/g++-4.6\n</code></pre>"},{"location":"upgrade-gcc-4-7-ubuntu-12-04/#make-sure-gcc-47-is-the-default-alternative","title":"Make sure GCC 4.7 is the default alternative","text":"<pre><code>sudo update-alternatives --config gcc\nThere are 2 choices for the alternative gcc (providing /usr/bin/gcc)\n\nSelection Path Priority Status\n------------------------------------------------------------\n* 0 /usr/bin/gcc-4.7 60 auto mode\n1 /usr/bin/gcc-4.6 40 manual mode\n2 /usr/bin/gcc-4.7 60 manual mode\n\nPress enter to keep the current choice[*], or type selection number: 0\n</code></pre>"},{"location":"upgrade-gcc-4-7-ubuntu-12-04/#verify","title":"Verify","text":"<pre><code>gcc --version\ngcc (Ubuntu/Linaro 4.7.3-2ubuntu1~12.04) 4.7.3\nCopyright (C) 2012 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions. There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n</code></pre>"},{"location":"install-configure-tortoisehg-mac/","title":"How to install and configure TortoiseHg on Mac","text":"<p>I finally got fed up with SourceTree and installed TortoiseHg on my Mac development machine. Read on:</p>"},{"location":"install-configure-tortoisehg-mac/#xcode-configuration","title":"Xcode Configuration","text":"<p>For best results make sure you have the latest XCode and Command Line Tools installed (XCode 5 and Command Line Tools September 2013 at the time of this writing). You can get them from the Apple Developer Downloads site.</p> <pre><code>sudo xcode-select -switch /Applications/Xcode.app/Contents/Developer\n</code></pre>"},{"location":"install-configure-tortoisehg-mac/#1-install-update-ruby","title":"1. Install / Update Ruby","text":"<p><pre><code>ruby -v\n</code></pre> should return something like:</p> <pre><code>ruby 2.0.0p247 (2013-06-27 revision 41674) [x86_64-darwin12.3.0]\n</code></pre> <p>You can skip the rest of this section if you have Ruby already installed.</p>"},{"location":"install-configure-tortoisehg-mac/#install-the-ruby-version-manager-and-ruby","title":"Install the Ruby Version Manager and Ruby","text":"<pre><code>curl -L https://get.rvm.io | bash -s stable --ruby\nsource /Users/yourname/.rvm/scripts/rvm\n</code></pre>"},{"location":"install-configure-tortoisehg-mac/#2-install-homebrew","title":"2. Install Homebrew","text":"<pre><code>ruby -e \"$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)\"\n</code></pre> <p>Follow the instructions in the script. The installation will take a few minutes.</p>"},{"location":"install-configure-tortoisehg-mac/#verify-your-brew-installation","title":"Verify your brew installation","text":"<pre><code>brew doctor\n</code></pre> <p>This returned a few problems for me, but the output will vary depending on the existing system configuration.</p> <pre><code>Warning: An outdated version of Git was detected in your PATH.\nGit 1.7.10 or newer is required to perform checkouts over HTTPS from GitHub.\nPlease upgrade: brew upgrade git\n\nWarning: /Library/Frameworks/Mono.framework detected\nThis can be picked up by CMake's build system and likely cause the build to\nfail. You may need to move this file out of the way to compile CMake.\n\nWarning: You have MacPorts or Fink installed:\n    /Users/yourname/.rvm/bin/port, /opt/local/bin/port\n\nThis can cause trouble. You don't have to uninstall them, but you may want to\ntemporarily move them out of the way, e.g.\n\n    sudo mv /opt/local ~/macports\n\nWarning: /usr/bin occurs before /usr/local/bin\nThis means that system-provided programs will be used instead of those\nprovided by Homebrew. \n\nConsider setting your PATH so that /usr/local/bin\noccurs before /usr/bin. Here is a one-liner:\n    echo export PATH=\"/usr/local/bin:$PATH\" &gt;&gt; ~/.bash_profile\n\nWarning: Your Xcode (x.y.z) is outdated\nPlease install Xcode a.b.c\n</code></pre> <p>The issues will depend on your specific installation. Use your best judgement about what to fix and what to ignore. Fixing one by one:</p>"},{"location":"install-configure-tortoisehg-mac/#warning-you-have-macports-or-fink-installed","title":"Warning: You have MacPorts or Fink installed","text":"<pre><code>sudo mv /opt/local ~/macports\n</code></pre>"},{"location":"install-configure-tortoisehg-mac/#warning-usrbin-occurs-before-usrlocalbin","title":"Warning: /usr/bin occurs before /usr/local/bin","text":"<pre><code>export PATH=/usr/local/bin:$PATH\necho export PATH=\"/usr/local/bin:$PATH\" &gt;&gt; ~/.bash_profile\n</code></pre>"},{"location":"install-configure-tortoisehg-mac/#warning-an-outdated-version-of-git-was-detected-in-your-path","title":"Warning: An outdated version of Git was detected in your PATH.","text":"<pre><code>brew upgrade git\n</code></pre> <p>or if you do not have Git at all:</p> <pre><code>brew install git\n</code></pre>"},{"location":"install-configure-tortoisehg-mac/#warning-your-xcode-xyz-is-outdated","title":"Warning: Your Xcode (x.y.z) is outdated","text":"<p>You can ignore this one.</p>"},{"location":"install-configure-tortoisehg-mac/#warning-libraryframeworksmonoframework-detected","title":"Warning: /Library/Frameworks/Mono.framework detected","text":"<p>You can ignore this one.</p>"},{"location":"install-configure-tortoisehg-mac/#3-install-python-packages","title":"3. Install Python packages","text":"<p>I had Python already installed before Homebrew, so I had to amend PYTHONPATH like so:</p> <pre><code>export PYTHONPATH=/usr/local/lib/python2.7/site-packages:$PYTHONPATH  \necho export PYTHONPATH=\"/usr/local/lib/python2.7/site-packages:$PYTHONPATH\" &gt;&gt; ~/.bash_profile\n</code></pre> <p>Then install PyQt (this also installs qt and sip):</p> <pre><code>brew install pyqt\n</code></pre> <p>Install QScintilla</p> <pre><code>brew install qscintilla2\n</code></pre> <p>Install Python Package Mananger (pip)</p> <pre><code>sudo easy_install pip\n</code></pre> <p>Install Pygments, iniparse and Mercurial Python packages. If you have Mercurial already, this will update it to the latest version.</p> <pre><code>sudo pip install -U Pygments iniparse Mercurial\n</code></pre>"},{"location":"install-configure-tortoisehg-mac/#4-install-tortoisehg","title":"4. Install TortoiseHg","text":"<p>Clone TortoiseHg repository using Mercurial:</p> <pre><code>hg clone http://bitbucket.org/tortoisehg/thg/ ~/Tools/TortoiseHg\ncd ~/Tools/TortoiseHg/\nhg update stable\n</code></pre> <p>Quick test. You should see TortoiseHg Workbench running:</p> <pre><code>./thg log\n</code></pre>"},{"location":"install-configure-tortoisehg-mac/#5-install-tortoisehg-mac-app","title":"5. Install TortoiseHg Mac App","text":""},{"location":"install-configure-tortoisehg-mac/#clone-thg-mac-app-repository","title":"Clone thg-mac-app repository","text":"<pre><code>hg clone https://bitbucket.org/skrysmanski/thg-mac-app ~/Tools/thg-mac-app\n</code></pre>"},{"location":"install-configure-tortoisehg-mac/#set-the-tortoisehg_path-variable","title":"Set the TORTOISEHG_PATH variable","text":"<pre><code>cp -p ~/Tools/thg-mac-app/tortoisehg-path.sh ~/\n</code></pre> <p>Edit <code>~/tortoisehg-path.sh</code> so it points to <code>~/Tools/TortoiseHg</code>. This is what <code>~/tortoisehg-path.sh</code> looks like after the change:</p> <p>``` bash</p>"},{"location":"install-configure-tortoisehg-mac/#binsh","title":"!/bin/sh","text":"<p>export TORTOISEHG_PATH=~/Tools/TortoiseHg ```</p>"},{"location":"install-configure-tortoisehg-mac/#install-tortoisehgapp","title":"Install TortoiseHg.app","text":"<p>Option + Drag the TortoiseHg.app from <code>~/Tools/thg-mac-app</code> to your Applications folder.</p>"},{"location":"save-xdocument-xml-use-single-quotes-attribute-values/","title":"How to save XDocument to xml and use single quotes for attribute values","text":"<p>I had to do this for AVBlocks xml licenses recently. It is not straightforward, but here is the C# code.</p> <pre><code>using System;\nusing System.Collections.Generic;\nusing System.IO;\nusing System.Linq;\nusing System.Text;\nusing System.Xml;\nusing System.Xml.Linq;\nusing System.Xml.XPath;\n\nnamespace Primo.LicenseBuilder.Xml\n{\n    public static class XmlExtensions\n    {\n        public static string ToSingleQuoteString(this XDocument xDocument, \n                                                    System.Xml.Formatting formatting = Formatting.Indented)\n        {\n            using (StringWriter sw = new StringWriter())\n            {\n                using (XmlTextWriter writer = new XmlTextWriter(sw))\n                {\n                    writer.Formatting = formatting;\n                    writer.QuoteChar = '\\'';\n                    writer.WriteNode(xDocument.CreateNavigator(), false);\n                    writer.Flush();\n                }\n\n                return sw.ToString();\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"debian-wheezy-guest-windows-8-1-host-using-virtualbox/","title":"Debian \"Wheezy\" guest on Windows 8.1 host using VirtualBox","text":"<p>This post is about using Oracle VirtualBox to install a Debian 7.2 x86_64 guest virtual machine on Windows 8.1 host.</p>"},{"location":"debian-wheezy-guest-windows-8-1-host-using-virtualbox/#install-virtualbox","title":"Install VirtualBox","text":"<ol> <li>Download the latest VirtualBox installer from https://www.virtualbox.org/wiki/Downloads. Make sure you get the 64-bit version. That was VirtualBox-4.3.2-90405-Win.exe at the time of writing.</li> <li>Run the installer and follow the instructions on the screen. Leave the default options as they are. The installation should complete without any issues.</li> <li>Download the Oracle VM VirtualBox Extension Pack from https://www.virtualbox.org/wiki/Downloads.</li> <li>Double click the downloaded .vbox-extpack file to install the extensions.</li> <li>Go to File &gt; Preferences &gt; Extensions. You should see the Oracle VM VirtualBox Extension Pack listed under Extension Packages.</li> </ol>"},{"location":"debian-wheezy-guest-windows-8-1-host-using-virtualbox/#create-virtual-machine","title":"Create virtual machine","text":"<ol> <li>Start VirtualBox</li> <li>Select Machine &gt; New from the menu - Name: Debian-7.2-x64</li> <li>Type: Linux</li> <li>Version: Debian (64 bit)</li> <li>Click Next </li> </ol> <p>NOTE: If the Debian (64 bit) choice is not available, make sure Intel Virtualization Technology is enabled in the host UEFI / BIOS. 3. Memory size - Memory size: 4096 MB - Click Next 4. Hard drive - Choose Create a virtual hard drive now - Click Create - Choose VDI (VirtualBox Disk Image) - Click Create - File allocation and size - Select a path for the virtual disk image - Select 100 GB for size - Click Create</p> <p>It takes a few minutes to create the virtual disk image, but eventually you will see the image in the VirtualBox Manager. We are ready to install Debian now.</p> <p> </p>"},{"location":"debian-wheezy-guest-windows-8-1-host-using-virtualbox/#configure-display","title":"Configure Display","text":"<p>In VirtualBox Manager:</p> <ol> <li>Select Debian-7.2-x64 &gt; Settings</li> <li>Select Display &gt; Video</li> <li>Bump up the video memory to 128 MB.</li> <li>Do not check Enable 3D Acceleration. We will enable 3D Acceleration later.  </li> </ol> <p>no images were found</p>"},{"location":"debian-wheezy-guest-windows-8-1-host-using-virtualbox/#mount-debian-boot-cd","title":"Mount Debian Boot CD","text":"<ol> <li>Download the Debian 7.2 x64 ISO image from the network install page on the Debian web site. Make sure you get the amd64 image.</li> <li>Open VirtualBox Manager</li> <li>Select Debian-7.2-x64 &gt; Settings</li> <li>Select Storage &gt; Controller IDE &gt; Empty</li> <li>Click on the little CD icon</li> <li>Find and select the Debian ISO (debian-7.2.0-amd64-netinst.iso) that you downloaded in step 1.</li> <li>Click OK  </li> </ol>"},{"location":"debian-wheezy-guest-windows-8-1-host-using-virtualbox/#start-the-virtual-machine","title":"Start the virtual machine","text":"<ol> <li>Open VirtualBox Manager</li> <li>Start the Debian-7.2-x64 machine</li> <li>Press right CTRL+R to reset the machine. You should see the Debian Installer boot menu.  </li> </ol>"},{"location":"debian-wheezy-guest-windows-8-1-host-using-virtualbox/#install-debian","title":"Install Debian","text":"<p>In the Debian Install boot menu:</p> <ol> <li>Select Graphical Install</li> <li>Follow the installer instructions and configure Debian just as you would do on a physical machine. You should be able to install without any problems.</li> </ol>"},{"location":"debian-wheezy-guest-windows-8-1-host-using-virtualbox/#enable-3d-acceleration","title":"Enable 3D Acceleration","text":""},{"location":"debian-wheezy-guest-windows-8-1-host-using-virtualbox/#install-guest-additions-for-virtualbox","title":"Install Guest Additions for VirtualBox","text":"<ol> <li>Start the Debian-7.2-x64 virtual machine</li> <li>Login into Debian</li> <li>Select Insert Guest Additions CD image\u2026 from the VirtualBox Devices menu. Do not run it!</li> <li>Open Root Terminal</li> </ol> <p>Install Module Assistant, so you can build kernel modules.</p> <pre><code>apt-get install module-assistant\n</code></pre> <p>Let Module Assistant prepare the system.</p> <pre><code>m-a prepare\n</code></pre> <p>Install Guest Additions</p> <pre><code>sh /media/cdrom/VBoxLinuxAdditions.run\n</code></pre>"},{"location":"debian-wheezy-guest-windows-8-1-host-using-virtualbox/#enable-3d-acceleration_1","title":"Enable 3D Acceleration","text":"<ol> <li>Shutdown the Debian-7.2-x64 virtual machine</li> <li>Open VirtualBox Manager - Select Debian-7.2-x64 &gt; Settings</li> <li>Select Display &gt; Video</li> <li>Check Enable 3D Acceleration</li> <li>Start the Debian-7.2-x64 virtual machine</li> </ol>"},{"location":"debian-wheezy-guest-windows-8-1-host-using-virtualbox/#troubleshooting","title":"Troubleshooting","text":"<p>If the installation does not start or hangs, try booting using Advanced Options &gt; Expert Install. That will give you more information about what is wrong with the installation.</p>"},{"location":"debian-wheezy-guest-windows-8-1-host-using-virtualbox/#errors","title":"Errors","text":""},{"location":"debian-wheezy-guest-windows-8-1-host-using-virtualbox/#this-kernel-requires-an-x86_64-cpu-but-only-detected-an-i686-cpu","title":"This kernel requires an x86_64 CPU, but only detected an i686 CPU \u2026","text":""},{"location":"debian-wheezy-guest-windows-8-1-host-using-virtualbox/#how-to-fix","title":"How to fix","text":"<ul> <li>Make sure Intel Virtualization Technology is ON in the host UEFI / BIOS.</li> <li>Make sure the VirtualBox machine version is Debian (64 bit).</li> <li>Make sure Windows Hyper-V services are not running.</li> </ul>"},{"location":"nvidia-driver-mismatch-upgrading-ubuntu-12-04-3-lts/","title":"Nvidia driver mismatch after upgrading to Ubuntu 12.04.3 LTS","text":"<p>After upgrading to Ubuntu 12.04.3 LTS, I could not boot in GUI / X anymore. I got this when trying to start X:</p> <pre><code>startx\n\nNVIDIA: API mismatch: the NVIDIA kernel module has version 304.88, but this NVIDIA driver component has version 304.108.\nPlease make sure that the kernel module and all NVIDIA driver components have the same version.\n</code></pre> <p>To fix that it seems you have to disable the <code>xorg:nvidia_304_updates</code> (304.108) driver and enable the <code>xorg:nvidia_304</code> (304.88) driver:</p> <pre><code>sudo jockey-text -e xorg:nvidia_304 \n</code></pre> <p>After that you should have <code>xorg:nvidia_304</code> listed as Proprietary, Enabled, In use:</p> <pre><code>sudo jockey-text --list\nxorg:nvidia_173 - NVIDIA accelerated graphics driver (Proprietary, Disabled, Not in use)\nxorg:nvidia_173_updates - NVIDIA accelerated graphics driver (post-release updates) (Proprietary, Disabled, Not in use)\nxorg:nvidia_304 - NVIDIA accelerated graphics driver (Proprietary, Enabled, In use)\nxorg:nvidia_304_updates - NVIDIA accelerated graphics driver (post-release updates) (Proprietary, Disabled, Not in use)\nxorg:nvidia_96 - NVIDIA accelerated graphics driver (Proprietary, Disabled, Not in use)    \n</code></pre> <p>And finally you have to reboot:</p> <pre><code>sudo reboot\n</code></pre>"},{"location":"super-agile-possible-without-unit-tests/","title":"Super Agile: Not possible without unit tests","text":"<p>It is never too late to start writing unit tests. Add unit tests to your \u201cDefinition of Done\u201d document. Automate your build process, so it runs unit tests with every code change.</p>"},{"location":"dual-boot-windows-8-1-virtualbox-hyper-v/","title":"Dual boot Windows 8.1 for VirtualBox and Hyper-V","text":"<p>Most of the time I use VirtualBox to run Linux distros like Ubuntu and Debian. At the same time, I have to work with Windows Phone SDK which needs Hyper-V to run the Windows Phone emulator. Understandably VirtualBox and Hyper-V will not run at the same time. The easiest way I found to solve that problem is creating a dual boot configuration where one of the boot options has Hyper-V disabled. Here is how to do it:</p> <p>Run Command Prompt (not PowerShell) as Administrator and execute the following commands (note that the GUID will be different on your system):</p> <pre><code>bcdedit /set {current} hypervisorlaunchtype off \n\nbcdedit /copy {current} /d \"Windows 8.1 with Hyper-V\"\nThe entry was successfully copied to {5e0b6781-81ec-11e3-be83-74d02bc4e906}.\n\nbcdedit /set {5e0b6781-81ec-11e3-be83-74d02bc4e906} hypervisorlaunchtype auto \nThe operation completed successfully.\n</code></pre> <p>You should now have two boot options in the Windows start menu: \"Windows 8.1\" and \"Windows 8.1 with Hyper-V\". To switch between the different configurations, make sure you hold the <code>Shift</code> key while clicking on the Restart option.</p>"},{"location":"executable-shell-scripts-open-gedit-ubuntu/","title":"Executable shell scripts open in Gedit on Ubuntu","text":"<p>This started happening after an upgrade to Ubuntu 13.04. We have shell scripts here and there saved as .run files, e.g. <code>Build.linux.auto.run</code>, to automate AVBlocks builds on Linux. Normally Nautilus will ask you whether you want to run the script when you double click a <code>.run</code> file, but on Ubuntu 13.04, Nautilus suddenly started opening <code>.run</code> files in Gedit. It turns out there is a setting in Gnome for that. Here is how to fix it:</p> <ol> <li>Run <code>dconf-editor</code> and navigate to <code>org.gnome.nautilus.preferences</code></li> <li>Change the value of the <code>executable-text-activation</code> setting from <code>display</code> to <code>ask</code>.</li> </ol> <p>If you do not have <code>dconf-editor</code> you can install these packages:</p> <pre><code>sudo apt-get install dconf-tools\nsudo apt-get install gconf-editor\n</code></pre> <p>And just in case, this is how you run it:</p> <pre><code>dconf-editor\n</code></pre>"},{"location":"fix-tortoisehg-nautilus-ubuntu-13-04/","title":"How to fix Tortoisehg Nautilus extension on Ubuntu 13.04","text":"<p>The TortoiseHg Nautilus extension stopped working after upgrading one of my Ubuntu machines from 12.10 to 13.04. It turned out the problem was it could not find <code>libpython2.7.so.1.0</code>.</p> <p>Here is the fix on a 32-bit distro:</p> <pre><code>sudo ln -s /usr/lib/i386-linux-gnu/libpython2.7.so.1.0 /usr/lib/libpython2.7.so.1.0\nnautilus -q\n</code></pre> <p>and on a 64-bit distro:</p> <pre><code>sudo ln -s /usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0 /usr/lib/libpython2.7.so.1.0\nnautilus -q\n</code></pre>"},{"location":"upgrade-linux-kernel-3-11-ubuntu-12-04-4-lts/","title":"How to upgrade the Linux kernel to 3.11 on Ubuntu 12.04.4 LTS","text":"<p>I have two Ubuntu 12.04.4 virtual machines that I use for building and testing AVBlocks - one 32 bit (i386) and one 64 bit (x86_64). Normally I keep them in sync and regularly updated via the Update Manager. </p> <p>I noticed today that for some reason, the 32-bit machine upgraded to Linux kernel 3.11, but the 64-bit machine is stuck with Linux kernel 3.8. The Update Manager reports that both systems are up-to-date, yet the kernel versions are different on both systems.</p>"},{"location":"upgrade-linux-kernel-3-11-ubuntu-12-04-4-lts/#ubuntu-12044-lts-x86_64","title":"Ubuntu 12.04.4 LTS x86_64","text":"<pre><code>uname -a\nLinux ubuntu-12-04-x64 3.8.0-39-generic #58~precise1-Ubuntu SMP Fri May 2 21:33:40 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux\n</code></pre> <pre><code>lsb_release -a\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 12.04.4 LTS\nRelease:    12.04\nCodename:   precise\n</code></pre>"},{"location":"upgrade-linux-kernel-3-11-ubuntu-12-04-4-lts/#ubuntu-12044-lts-i386","title":"Ubuntu 12.04.4 LTS i386","text":"<pre><code>uname -a\nLinux ubuntu-12-04-i386 3.11.0-20-generic #35~precise1-Ubuntu SMP Fri May 2 21:35:48 UTC 2014 i686 i686 i386 GNU/Linux\n</code></pre> <pre><code>lsb_release -a\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 12.04.4 LTS\nRelease:    12.04\nCodename:   precise\n</code></pre>"},{"location":"upgrade-linux-kernel-3-11-ubuntu-12-04-4-lts/#the-solution","title":"The solution","text":"<p>After some reading on internet, I found that, only installations made from Ubuntu 12.04.2 ISO images and above will receive the 3.11 Linux kernel update automatically. For all other installations you will have to update it manually per this Ubuntu wiki article.</p> <p>So, for Ubuntu 12.04.4, you have to install the Saucy (13.10) Hardware Enablement Stack:</p> <pre><code>sudo apt-get install --install-recommends linux-generic-lts-saucy xserver-xorg-lts-saucy libgl1-mesa-glx-lts-saucy\nsudo reboot\n</code></pre>"},{"location":"unable-to-generate-an-explicit-migration-because-the-following-explicit-migrations-are-pending/","title":"Unable to generate an explicit migration because the following explicit migrations are pending","text":"<p>After renaming the namespace of some POCO classes from <code>Primo.LicenseManager.Models</code> to <code>Primo.Licensing.DataModel</code>, the Entity Framework scaffolding no longer recognizes the applied migrations:</p> <pre><code>Add-Migration -Name AddInvoiceEntity -Verbose -StartUpProjectName LicensingDataModel -ProjectName LicensingDataModel\n\nUnable to generate an explicit migration because the following explicit migrations are pending: [201310191546582_CreateTables]. \nApply the pending explicit migrations before attempting to generate a new explicit migration.\n</code></pre>"},{"location":"unable-to-generate-an-explicit-migration-because-the-following-explicit-migrations-are-pending/#in-sql-server-management-studio","title":"In SQL Server Management Studio:","text":"<pre><code>select * \nfrom __MigrationHistory \nwhere MigrationId = '201310191546582_CreateTables'\n\nMigrationId: 201310191546582_CreateTables\nContextKey: Primo.LicenseManager.Models.Migrations.Configuration\nModel: 0x1F8B08000000....\nProductVersion: 5.0.0.net45\n</code></pre>"},{"location":"unable-to-generate-an-explicit-migration-because-the-following-explicit-migrations-are-pending/#the-problem","title":"The problem","text":"<p>In the database, the ContextKey in the __MigrationHistory table is still the old namespace: <code>Primo.LicenseManager.Models.Migrations.Configuration</code>.</p>"},{"location":"unable-to-generate-an-explicit-migration-because-the-following-explicit-migrations-are-pending/#the-solution","title":"The solution","text":"<p>Update the ContextKey to the new namespace <code>Primo.Licensing.DataModel.Migrations.Configuration</code></p> <pre><code>update __MigrationHistory \nset ContextKey = 'Primo.Licensing.DataModel.Migrations.Configuration'\nwhere MigrationId = '201310191546582_CreateTables'\n</code></pre> <p>Now this works:</p> <pre><code>Add-Migration -Name AddInvoiceEntity -Verbose -StartUpProjectName LicensingDataModel -ProjectName LicensingDataModel\n</code></pre>"},{"location":"use-different-cache-directory-chocolatey-packages/","title":"How to use a different cache directory for Chocolatey packages","text":""},{"location":"use-different-cache-directory-chocolatey-packages/#about-chocolatey","title":"About Chocolatey","text":"<p>In short, Chocolatey is a package manager for Windows which saves time by automating otherwise manual installation tasks. You can install Chocolatey by following the instructions on chocolatey.org.</p>"},{"location":"use-different-cache-directory-chocolatey-packages/#configure-chocolateys-cache-folder","title":"Configure Chocolatey's Cache Folder","text":"<p>For security reasons, Chocolatey installs in <code>C:\\ProgramData\\chocolatey</code> by default. See Why does Chocolatey install where it does? for more information.</p> <p>Also by default, Chocolatey will download packages in <code>C:\\Users\\USERNAME\\AppData\\Local\\Temp\\chocolatey</code> which might work or not for you. If you need to use a different folder, you can set the <code>cacheLocation</code> key in <code>C:\\ProgramData\\chocolatey\\config\\chocolatey.config</code> to a folder of your choice. </p> <p>For example, to use <code>C:\\ChocolateyCache</code> as a cache folder, add <code>&lt;add key=\"cacheLocation\" value=\"C:\\ChocolateyCache\" description=\"Cache location if not TEMP folder.\" /&gt;</code> to the <code>chocolatey.config</code> file like this:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;chocolatey xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt;\n  &lt;containsLegacyPackageInstalls&gt;false&lt;/containsLegacyPackageInstalls&gt;\n  &lt;commandExecutionTimeoutSeconds&gt;0&lt;/commandExecutionTimeoutSeconds&gt;\n  &lt;config&gt;\n    &lt;add key=\"cacheLocation\" value=\"C:/ChocolateyCache\" description=\"Cache location if not TEMP folder.\" /&gt;\n    &lt;add key=\"containsLegacyPackageInstalls\" value=\"true\" description=\"Install has packages installed prior to 0.9.9 series.\" /&gt;\n    &lt;add key=\"commandExecutionTimeoutSeconds\" value=\"2700\" description=\"Default timeout for command execution.\" /&gt;\n    &lt;add key=\"proxy\" value=\"\" description=\"Explicit proxy location.\" /&gt;\n    &lt;add key=\"proxyUser\" value=\"\" description=\"Optional proxy user.\" /&gt;\n    &lt;add key=\"proxyPassword\" value=\"\" description=\"Optional proxy password. Encrypted.\" /&gt;\n  &lt;/config&gt;\n  &lt;sources&gt;\n    &lt;source id=\"chocolatey\" value=\"https://chocolatey.org/api/v2/\" disabled=\"false\" priority=\"0\" /&gt;\n  &lt;/sources&gt;\n  &lt;features&gt;\n    &lt;feature name=\"checksumFiles\" enabled=\"true\" setExplicitly=\"false\" description=\"Checksum files when pulled in from internet (based on package).\" /&gt;\n    &lt;feature name=\"autoUninstaller\" enabled=\"false\" setExplicitly=\"false\" description=\"Uninstall from programs and features without requiring an explicit uninstall script.\" /&gt;\n    &lt;feature name=\"allowGlobalConfirmation\" enabled=\"false\" setExplicitly=\"false\" description=\"Prompt for confirmation in scripts or bypass.\" /&gt;\n    &lt;feature name=\"failOnAutoUninstaller\" enabled=\"false\" setExplicitly=\"false\" description=\"Fail if automatic uninstaller fails.\" /&gt;\n  &lt;/features&gt;\n  &lt;apiKeys /&gt;\n&lt;/chocolatey&gt;\n</code></pre>"},{"location":"install-git-windows-via-chocolatey/","title":"Install Git on Windows via Chocolatey","text":"<p>This post shows how to use Chocolatey to install Git.</p>"},{"location":"install-git-windows-via-chocolatey/#chocolatey","title":"Chocolatey","text":"<p>If you do not have Chocolatey, you can install it by following the instructions on chocolatey.org. You may also see this post for instructions on how to set the Chocolatey cache location. </p>"},{"location":"install-git-windows-via-chocolatey/#git","title":"Git","text":""},{"location":"install-git-windows-via-chocolatey/#install-git","title":"Install Git","text":"<p>In PowerShell as Administrator:</p> <pre><code>choco install git --params \"/GitAndUnixToolsOnPath /NoAutoCrlf\"\n</code></pre> <p>Close and open PowerShell, so it can pick the updated PATH environment.</p>"},{"location":"install-git-windows-via-chocolatey/#verify","title":"Verify","text":"<p>Verify you have <code>git</code>:</p> <pre><code>git --version\ngit version 2.6.4.windows.1\n</code></pre> <p>Verify you have <code>ssh</code>:</p> <pre><code>ssh\nusage: ssh [-1246AaCfGgKkMNnqsTtVvXxYy] [-b bind_address] [-c cipher_spec]\n           [-D [bind_address:]port] [-E log_file] [-e escape_char]\n           [-F configfile] [-I pkcs11] [-i identity_file]\n           [-L address] [-l login_name] [-m mac_spec]\n           [-O ctl_cmd] [-o option] [-p port]\n           [-Q cipher | cipher-auth | mac | kex | key]\n           [-R address] [-S ctl_path] [-W host:port]\n           [-w local_tun[:remote_tun]] [user@]hostname [command]\n</code></pre>"},{"location":"ubuntu-with-vagrant-and-virtualbox-on-windows/","title":"Ubuntu with Vagrant and VirtualBox on Windows","text":"<p>In this post I show how you can use VirtualBox and Vagrant to create and launch an Ubuntu 14.04 virtual machine on Windows 8.1 host.</p>"},{"location":"ubuntu-with-vagrant-and-virtualbox-on-windows/#preparation","title":"Preparation","text":""},{"location":"ubuntu-with-vagrant-and-virtualbox-on-windows/#chocolatey","title":"Chocolatey","text":"<p>We will use Chocolatey to install all the required software. If you do not have it, you can install it by following the instructions on chocolatey.org. You may also see this post for instructions on how to set the Chocolatey cache location. </p>"},{"location":"ubuntu-with-vagrant-and-virtualbox-on-windows/#virtualbox","title":"VirtualBox","text":"<p>In order to use VirtualBox on Windows 10 you first need to disable Hyper-V. </p>"},{"location":"ubuntu-with-vagrant-and-virtualbox-on-windows/#install-virtualbox","title":"Install VirtualBox","text":"<p>In PowerShell as Administrator:</p> <pre><code>choco install virtualbox\n</code></pre> <p>IMPORTANT: After the installation, run Oracle VM VirtualBox once and when prompted, follow the instructions to install the Oracle VM VirtualBox Extension Pack. The version of the installed extension pack should match the version of Oracle VM VirtualBox. </p>"},{"location":"ubuntu-with-vagrant-and-virtualbox-on-windows/#add-virtualbox-to-system-path","title":"Add VirtualBox To System Path","text":"<p>Vagrant will need access to <code>VBoxManage.exe</code>. For that you need to add <code>C:\\Program Files\\Oracle\\VirtualBox</code> to your path. You can do that easily in PowerShell, by using the Environment.SetEnvironmentVariable .NET method.  </p> <pre><code>[Environment]::SetEnvironmentVariable(\"Path\", \"C:/Program Files/Oracle/VirtualBox;\" + $env:Path, \"Machine\")\n</code></pre> <p>Close the PowerShell terminal and open it again, so it can pick up the PATH to VirtualBox.</p>"},{"location":"ubuntu-with-vagrant-and-virtualbox-on-windows/#git","title":"Git","text":"<p>We want Git for <code>ssh.exe</code> and other Linux tools, which are needed later by Vagrant. If you have installed <code>ssh.exe</code> using some other way, you may skip this step.</p>"},{"location":"ubuntu-with-vagrant-and-virtualbox-on-windows/#install-git","title":"Install Git","text":"<p>In PowerShell as Administrator:</p> <pre><code>choco install git --params \"/GitAndUnixToolsOnPath /NoAutoCrlf\"\n</code></pre> <p>Now, besides <code>git</code>, you should have <code>ssh</code>, <code>rsync</code>, <code>touch</code>, <code>clear</code> and a number of other useful Linux tools. </p>"},{"location":"ubuntu-with-vagrant-and-virtualbox-on-windows/#verify-git-and-ssh","title":"Verify Git and SSH","text":"<p>Close and open PowerShell, so it can pick the updated PATH environment.</p> <p>Verify you have <code>git</code>:</p> <pre><code>git --version\ngit version 2.6.4.windows.1\n</code></pre> <p>Verify you have <code>ssh</code>:</p> <pre><code>ssh\nusage: ssh [-1246AaCfGgKkMNnqsTtVvXxYy] [-b bind_address] [-c cipher_spec]\n           [-D [bind_address:]port] [-E log_file] [-e escape_char]\n           [-F configfile] [-I pkcs11] [-i identity_file]\n           [-L address] [-l login_name] [-m mac_spec]\n           [-O ctl_cmd] [-o option] [-p port]\n           [-Q cipher | cipher-auth | mac | kex | key]\n           [-R address] [-S ctl_path] [-W host:port]\n           [-w local_tun[:remote_tun]] [user@]hostname [command]\n</code></pre>"},{"location":"ubuntu-with-vagrant-and-virtualbox-on-windows/#vagrant","title":"Vagrant","text":""},{"location":"ubuntu-with-vagrant-and-virtualbox-on-windows/#install-vagrant","title":"Install Vagrant","text":"<p>In PowerShell as Administrator:</p> <pre><code>choco install vagrant\n</code></pre>"},{"location":"ubuntu-with-vagrant-and-virtualbox-on-windows/#set-vagrant_home-optional","title":"Set VAGRANT_HOME (Optional)","text":"<p>The Vagrant home directory is where things such as boxes are stored, so it can actually become quite large on disk. By default, this is set to <code>C:\\Users\\yourusername\\.vagrant.d</code>.  </p> <p>In PowerShell as Administrator:</p> <pre><code>mkdir C:/VagrantHome\n[Environment]::SetEnvironmentVariable(\"VAGRANT_HOME\", \"C:/VagrantHome\", \"Machine\")\n</code></pre> <p>You are now ready to launch virtual machines.</p>"},{"location":"ubuntu-with-vagrant-and-virtualbox-on-windows/#initialize-an-ubuntu-1404-box-and-launch-it","title":"Initialize an Ubuntu 14.04 Box and Launch it","text":"<p>Create a directory for your project, e.g. <code>C:\\Ubuntu</code>. Open PowerShell in the new directory and run the following commands:</p> <pre><code>vagrant init ubuntu/trusty64\nvagrant up\n</code></pre> <p>That creates a <code>Vagrantfile</code> file from the <code>ubuntu/trusty64</code> box. Every Vagrant development environment requires a box. You can search for boxes at https://atlas.hashicorp.com/search.   </p>"},{"location":"ubuntu-with-vagrant-and-virtualbox-on-windows/#virtualbox-guest-additions","title":"VirtualBox Guest Additions","text":"<p>During virtual machine boot you may get a warning about the VirtualBox Guest Additions version, something similar to this:</p> <pre><code>==&gt; default: Checking for guest additions in VM...\n    default: The guest additions on this VM do not match the installed version of\n    default: VirtualBox! In most cases this is fine, but in rare cases it can\n    default: prevent things such as shared folders from working properly. If you see\n    default: shared folder errors, please make sure the guest additions within the\n    default: virtual machine match the version of VirtualBox you have installed on\n    default: your host and reload your VM.\n    default:\n    default: Guest Additions Version: 4.3.10\n    default: VirtualBox Version: 5.0\n</code></pre> <p>There is a Vagrant plugin for that. The <code>vagrant-vbguest</code> plugin will check for and install the correct guest additions automatically on startup. To get the <code>vagrant-vbguest</code> plugin:</p> <pre><code>vagrant plugin install vagrant-vbguest\n</code></pre> <p>Now restart the VM:</p> <pre><code>vagrant reload\n</code></pre>"},{"location":"ubuntu-with-vagrant-and-virtualbox-on-windows/#login-with-ssh","title":"Login with SSH","text":"<pre><code>vagrant ssh\n</code></pre>"},{"location":"how-to-install-jekyll-on-windows/","title":"How to Install Jekyll on Windows","text":"<p>This post shows how to install Ruby and Jekyll via Chocolatey on Windows 8.1 or Windows Server 2012 R2 Update 1.</p>"},{"location":"how-to-install-jekyll-on-windows/#chocolatey","title":"Chocolatey","text":"<p>If you do not have Chocolatey, you can install it by following the instructions on chocolatey.org. You may also see this post for instructions on how to set the Chocolatey cache location.</p>"},{"location":"how-to-install-jekyll-on-windows/#ruby","title":"Ruby","text":""},{"location":"how-to-install-jekyll-on-windows/#install","title":"Install","text":"<p>Open PowerShell as Administrator and run the following command:</p> <pre><code>choco install ruby\n</code></pre> <p>This will install Ruby 2.1.6 in <code>C:\\tools\\ruby21\\bin</code>. </p>"},{"location":"how-to-install-jekyll-on-windows/#configure","title":"Configure","text":"<p>Close PowerShell and open it again, so it can pick the changes to the PATH environment.</p>"},{"location":"how-to-install-jekyll-on-windows/#test","title":"Test","text":"<pre><code>ruby --version\nruby 2.1.6p336 (2015-04-13 revision 50298) [x64-mingw32]\n</code></pre>"},{"location":"how-to-install-jekyll-on-windows/#ruby-devkit-20","title":"Ruby DevKit (2.0+)","text":""},{"location":"how-to-install-jekyll-on-windows/#install_1","title":"Install","text":"<p>Open PowerShell as Administrator and run the following command:</p> <pre><code>choco install ruby2.devkit\n</code></pre> <p>This will install Ruby DevKit 2.0+ and its dependencies- in <code>C:\\tools\\DevKit2</code>.  </p>"},{"location":"how-to-install-jekyll-on-windows/#configure_1","title":"Configure","text":"<p>Open <code>C:\\tools\\DevKit2\\config.yml</code>and add <code>C:\\tools\\ruby21</code> path at the end. The complete <code>config.yml</code> should look like this:</p> <pre><code># This configuration file contains the absolute path locations of all\n# installed Rubies to be enhanced to work with the DevKit. This config\n# file is generated by the 'ruby dk.rb init' step and may be modified\n# before running the 'ruby dk.rb install' step. To include any installed\n# Rubies that were not automagically discovered, simply add a line below\n# the triple hyphens with the absolute path to the Ruby root directory.\n#\n# Example:\n#\n# ---\n# - C:/ruby19trunk\n# - C:/ruby192dev\n#\n---\n - C:/tools/ruby21\n</code></pre> <p>Run the DevKit installer: </p> <pre><code>cd C:/tools/DevKit2\nruby dk.rb install\n</code></pre>"},{"location":"how-to-install-jekyll-on-windows/#jekyll","title":"Jekyll","text":""},{"location":"how-to-install-jekyll-on-windows/#install-bundler","title":"Install Bundler","text":"<pre><code>gem install bundler\n</code></pre>"},{"location":"how-to-install-jekyll-on-windows/#create-jekyll-site","title":"Create Jekyll Site","text":"<p>Create a <code>jekyll</code> directory under your home:</p> <pre><code>cd ~\nmkdir jekyll\n</code></pre>"},{"location":"how-to-install-jekyll-on-windows/#create-a-new-bundle","title":"Create a New Bundle","text":"<pre><code>cd ~/jekyll\nbundle init\n</code></pre>"},{"location":"how-to-install-jekyll-on-windows/#jekyll-gem","title":"Jekyll Gem","text":"<p>For Jekyll we need the <code>jekyll</code> gem.</p>"},{"location":"how-to-install-jekyll-on-windows/#syntax-highlighter-gem","title":"Syntax Highlighter Gem","text":"<p>We will use <code>rouge</code> as a syntax highlighter. This comes in the <code>rouge</code> gem.</p>"},{"location":"how-to-install-jekyll-on-windows/#auto-generation-gem","title":"Auto-generation Gem","text":"<p>Jekyll has a built-in auto-regeneration feature that watches your source folder for changes and then re-builds your site. On Windows, you need to install the <code>wdm</code> gem to enable this functionality.</p>"},{"location":"how-to-install-jekyll-on-windows/#gemfile","title":"Gemfile","text":"<p>Open the <code>Gemfile</code> file and add <code>jekyll</code>, <code>rouge</code>, and <code>wdm</code> packages. Here is the final file:</p> <pre><code># A sample Gemfile\nsource \"https://rubygems.org\"\n\ngem \"jekyll\"\ngem \"rouge\"\ngem \"wdm\"\n</code></pre>"},{"location":"how-to-install-jekyll-on-windows/#install-gems","title":"Install Gems","text":"<p>Install gems locally:</p> <pre><code>bundle install --binstubs --path vendor\n</code></pre>"},{"location":"how-to-install-jekyll-on-windows/#create-site","title":"Create Site","text":"<pre><code>cd ~/jekyll\nbundle exec jekyll new site\n</code></pre>"},{"location":"how-to-install-jekyll-on-windows/#configure_2","title":"Configure","text":""},{"location":"how-to-install-jekyll-on-windows/#syntax-highlighter","title":"Syntax Highlighter","text":"<p>Open <code>~/jekyll/site/_config.yml</code>. Add this line at the end to set <code>rouge</code> as a syntax highlighter:</p> <pre><code>highlighter: rouge\n</code></pre>"},{"location":"how-to-install-jekyll-on-windows/#test_1","title":"Test","text":""},{"location":"how-to-install-jekyll-on-windows/#build","title":"Build","text":"<pre><code>cd ~/jekyll/site\nchcp 65001\nbundle exec jekyll build --watch\n</code></pre>"},{"location":"how-to-install-jekyll-on-windows/#serve","title":"Serve","text":"<p>Open a second PowerShell window</p> <pre><code>cd ~/jekyll/site\nchcp 65001\nbundel exec jekyll serve\n</code></pre> <p>Open a browser and navigate to <code>http://localhost:4000</code>. You should see a basic Jekyll site running.</p>"},{"location":"how-to-install-jekyll-on-windows/#auto-generation","title":"Auto-generation","text":"<p>Go to <code>~/jekyll/site</code> and open <code>About.md</code> with a text editor capable of using UTF-8 encoding, e.g. Sublime Text. Change the title from <code>About</code> to <code>About Me</code>. Save the file. Refresh your browser and navigate to <code>http://localhost:4000/about/</code>. You should see the page has the new <code>About Me</code> title.   </p>"},{"location":"provision-chef-vagrant-omnibus-plugin/","title":"Provision Chef with Vagrant-Omnibus Plugin","text":"<p>In this post we show how you can provision Chef from Vagrant using the <code>vagrant-omnibus</code> plugin. This post is for Ubuntu 14.04 guest running in VirtualBox on Windows 10 host.</p>"},{"location":"provision-chef-vagrant-omnibus-plugin/#prerequisites","title":"Prerequisites","text":"<p>You need VirtualBox and Vagrant installed. To do that, you can follow the steps described in Ubuntu with Vagrant and VirtualBox on Windows.</p>"},{"location":"provision-chef-vagrant-omnibus-plugin/#install-chef-development-kit-chefdk","title":"Install Chef Development Kit (ChefDK)","text":"<p>In PowerShell as Administrator:</p> <pre><code>choco install chefdk\n</code></pre>"},{"location":"provision-chef-vagrant-omnibus-plugin/#provision-chef","title":"Provision Chef","text":"<p>Before you can use Chef Solo, Chef Zero, or Chef Client for provisioning, you need to install the latest Chef client on the guest. This can be done with a shell script or with a Vagrant plugin called <code>vagrant-omnibus</code>.  </p> <p>In PowerShell:</p> <pre><code>vagrant plugin install vagrant-omnibus\n</code></pre> <p>Open <code>Vagrantfile</code> and add the following code at the end of the configuration:</p> <pre><code># Install the latest version of Chef.\n# For more information see https://github.com/chef/vagrant-omnibus\n#\nconfig.omnibus.chef_version = :latest\n</code></pre> <p>The complete <code>Vagrantfile</code> file should look like this:</p> <pre><code># -*- mode: ruby -*-\n# vi: set ft=ruby :\n\n# All Vagrant configuration is done below. The \"2\" in Vagrant.configure\n# configures the configuration version (we support older styles for\n# backwards compatibility). Please don't change it unless you know what\n# you're doing.\n#\nVagrant.configure(2) do |config|\n\n  # Every Vagrant development environment requires a box. You can search for\n  # boxes at https://atlas.hashicorp.com/search.\n  #\n  config.vm.box = \"ubuntu/trusty64\"\n\n  # Provider-specific configuration so you can fine-tune various\n  # backing providers for Vagrant. These expose provider-specific options.\n  #\n  config.vm.provider \"virtualbox\" do |vb|\n    # For a complete reference, please see the online documentation at\n    # https://docs.vagrantup.com/v2/virtualbox/configuration.html\n\n    # Name used in Oracle VM VirtualBox Manager GUI\n    vb.name = \"Ubuntu-x64-Vagrant\"\n\n    # Customize the amount of memory on the VM (in MB):\n    vb.memory = \"2048\"\n\n    # Customize the amount of video memory on the VM (in MB):\n    vb.customize [\"modifyvm\", :id, \"--vram\", \"128\"]\n  end\n\n  # Install the latest version of Chef.\n  # For more information see https://github.com/chef/vagrant-omnibus\n  #\n  config.omnibus.chef_version = :latest\nend\n</code></pre>"},{"location":"provision-chef-vagrant-omnibus-plugin/#test","title":"Test","text":"<p>Finally launch and provision the Vagrant box. It should install the latest Chef Client:</p> <pre><code>vagrant reload\nvagrant provision\n</code></pre>"},{"location":"ubuntu-chef-vagrant-virtualbox-windows/","title":"Ubuntu and Chef with Vagrant and VirtualBox on Windows","text":"<p>In this post we show how you can use VirtualBox and Vagrant to launch an Ubuntu 14.04 guest and install the latest Chef client on it using Windows 10 as a host.</p>"},{"location":"ubuntu-chef-vagrant-virtualbox-windows/#prerequisites","title":"Prerequisites","text":"<p>You need VirtualBox and Vagrant installed. To do that, you can follow the steps described in Ubuntu with Vagrant and VirtualBox on Windows.</p>"},{"location":"ubuntu-chef-vagrant-virtualbox-windows/#chef","title":"Chef","text":""},{"location":"ubuntu-chef-vagrant-virtualbox-windows/#install-chef-development-kit-chefdk","title":"Install Chef Development Kit (ChefDK)","text":"<p>In PowerShell as Administrator:</p> <pre><code>choco install chefdk\n</code></pre>"},{"location":"ubuntu-chef-vagrant-virtualbox-windows/#install-chef-on-the-guest","title":"Install Chef on the guest","text":"<p>Before you can use Chef Solo, Chef Zero, or Chef Client for provisioning, you need to install the latest Chef client on the guest. </p> <p>Open <code>Vagrantfile</code> and add the following code at the end of the configuration:</p> <pre><code># Provision Chef Client with a shell script that runs the Chef Omnibus Installer\n# For more information see https://docs.chef.io/install_omnibus.html\n# \nconfig.vm.provision \"shell\", inline: &lt;&lt;-SHELL\n  sudo apt-get update -y\n  sudo apt-get install curl -y\n  curl -L https://www.opscode.com/chef/install.sh | sudo bash\nSHELL\n</code></pre> <p>The complete <code>Vagrantfile</code> file should look like this:</p> <pre><code># -*- mode: ruby -*-\n# vi: set ft=ruby :\n\n# All Vagrant configuration is done below. The \"2\" in Vagrant.configure\n# configures the configuration version (we support older styles for\n# backwards compatibility). Please don't change it unless you know what\n# you're doing.\n#\nVagrant.configure(2) do |config|\n\n  # Every Vagrant development environment requires a box. You can search for\n  # boxes at https://atlas.hashicorp.com/search.\n  #\n  config.vm.box = \"ubuntu/trusty64\"\n\n  # Provider-specific configuration so you can fine-tune various\n  # backing providers for Vagrant. These expose provider-specific options.\n  #\n  config.vm.provider \"virtualbox\" do |vb|\n    # For a complete reference, please see the online documentation at\n    # https://docs.vagrantup.com/v2/virtualbox/configuration.html\n\n    # Name used in Oracle VM VirtualBox Manager GUI\n    vb.name = \"Ubuntu-x64-Vagrant\"\n\n    # Customize the amount of memory on the VM (in MB):\n    vb.memory = \"2048\"\n\n    # Customize the amount of video memory on the VM (in MB):\n    vb.customize [\"modifyvm\", :id, \"--vram\", \"128\"]\n  end\n\n  # Provision Chef Client with a shell script that runs the Chef Omnibus Installer\n  # For more information see https://docs.chef.io/install_omnibus.html\n  # \n  config.vm.provision \"shell\", inline: &lt;&lt;-SHELL\n    sudo apt-get update -y\n    sudo apt-get install curl -y\n    curl -L https://www.opscode.com/chef/install.sh | sudo bash\n  SHELL\nend\n</code></pre>"},{"location":"ubuntu-chef-vagrant-virtualbox-windows/#test","title":"Test","text":"<p>Reload and provision the guest virtual machine. This should install the latest Chef Client:</p> <pre><code>vagrant reload\nvagrant provision\n</code></pre>"},{"location":"how-to-use-berkshelf-chef-zero-vagrant-and-virtualbox/","title":"How to use Berkshelf, Chef Zero, Vagrant and VirtualBox","text":"<p>In this post we show how you can use Berkshelf, Chef Zero, Vagrant, and VirtualBox to provision Ubuntu 14.04 guest on Windows 10 host.</p>"},{"location":"how-to-use-berkshelf-chef-zero-vagrant-and-virtualbox/#before-you-begin","title":"Before You Begin","text":"<p>You need VirtualBox and Vagrant installed. To do that, you can follow the steps described in Ubuntu with Vagrant and VirtualBox on Windows.</p>"},{"location":"how-to-use-berkshelf-chef-zero-vagrant-and-virtualbox/#install-vagrant-omnibus-plugin","title":"Install Vagrant-Omnibus Plugin","text":"<pre><code>vagrant plugin install vagrant-omnibus\n</code></pre>"},{"location":"how-to-use-berkshelf-chef-zero-vagrant-and-virtualbox/#install-vagrant-berkshelf-plugin","title":"Install Vagrant-Berkshelf Plugin","text":"<pre><code>vagrant plugin install vagrant-berkshelf\n</code></pre>"},{"location":"how-to-use-berkshelf-chef-zero-vagrant-and-virtualbox/#install-chef-development-kit-chefdk","title":"Install Chef Development Kit (ChefDK)","text":"<p>In PowerShell as Administrator:</p> <pre><code>choco install chefdk\n</code></pre>"},{"location":"how-to-use-berkshelf-chef-zero-vagrant-and-virtualbox/#install-knife-solo","title":"Install Knife Solo","text":"<p>At this time we only need knife solo to generate an empty Chef repository that is compatible with Chef Zero. For more information see Knife Solo.</p> <pre><code>chef gem install knife-solo\n</code></pre>"},{"location":"how-to-use-berkshelf-chef-zero-vagrant-and-virtualbox/#create-chef-repository","title":"Create Chef Repository","text":""},{"location":"how-to-use-berkshelf-chef-zero-vagrant-and-virtualbox/#create-a-chef-repo-directory","title":"Create a chef-repo directory","text":"<pre><code>mkdir ubuntu-chef-repo\ncd ubuntu-chef-repo\n</code></pre>"},{"location":"how-to-use-berkshelf-chef-zero-vagrant-and-virtualbox/#setup-the-the-chef-repo-directory","title":"Setup the the chef-repo directory","text":"<pre><code>touch Berksfile\nchef exec knife solo init . --no-git\n</code></pre> <p>Paste this into the <code>Berksfile</code>:</p> <pre><code>source 'https://supermarket.chef.io'\n\ncookbook 'main', path: './site-cookbooks/main'\n</code></pre>"},{"location":"how-to-use-berkshelf-chef-zero-vagrant-and-virtualbox/#create-new-cookbook","title":"Create New Cookbook","text":"<pre><code>cd site-cookbooks\nchef exec berks cookbook main --skip-git --skip-test-kitchen --no-foodcritic --no-chef-minitest --no-bundler --skip-vagrant\n</code></pre> <p>Check the structure of the <code>main</code> cookbook:</p> <pre><code>tree /F main\n</code></pre> <p>It should have the following structure:</p> <pre><code>\u2502   Berksfile\n\u2502   CHANGELOG.md\n\u2502   chefignore\n\u2502   LICENSE\n\u2502   metadata.rb\n\u2502   README.md\n\u2502   Thorfile\n\u2502\n\u251c\u2500\u2500\u2500attributes\n\u251c\u2500\u2500\u2500files\n\u2502   \u2514\u2500\u2500\u2500default\n\u251c\u2500\u2500\u2500libraries\n\u251c\u2500\u2500\u2500providers\n\u251c\u2500\u2500\u2500recipes\n\u2502       default.rb\n\u2502\n\u251c\u2500\u2500\u2500resources\n\u2514\u2500\u2500\u2500templates\n    \u2514\u2500\u2500\u2500default\n</code></pre>"},{"location":"how-to-use-berkshelf-chef-zero-vagrant-and-virtualbox/#add-the-apt-cookbook-as-a-dependency","title":"Add the Apt Cookbook as a Dependency","text":"<p>The <code>apt</code> cookbook runs the <code>apt-get update</code> command on the guest system. See apt Cookbook - Chef Supermarket for details.</p> <p>Open the <code>site-cookbooks/main/metadata.rb</code> file and add the following code at the end (the version may be different than 2.9.2):</p> <pre><code>depends 'apt', '~&gt; 2.9.2'\n</code></pre> <p>This is how the final file should look like:</p> <pre><code>name             'main'\nmaintainer       'YOUR_NAME'\nmaintainer_email 'YOUR_EMAIL'\nlicense          'All rights reserved'\ndescription      'Installs/Configures main'\nlong_description 'Installs/Configures main'\n\nversion          '0.1.0'\n\ndepends 'apt', '~&gt; 2.9.2'\n</code></pre>"},{"location":"how-to-use-berkshelf-chef-zero-vagrant-and-virtualbox/#include-the-apt-cookbook-in-the-default-recipe","title":"Include the Apt Cookbook in the Default Recipe","text":"<p>Open <code>site-cookbooks/main/recipes/default.rb</code> and add the following code at the end:</p> <pre><code>include_recipe 'apt::default'\n</code></pre> <p>The final file looks like this:</p> <pre><code>#\n# Cookbook Name:: main\n# Recipe:: default\n#\n# Copyright (C) 2016 YOUR_NAME\n#\n# All rights reserved - Do Not Redistribute\n#\n\ninclude_recipe 'apt::default'\n</code></pre>"},{"location":"how-to-use-berkshelf-chef-zero-vagrant-and-virtualbox/#test","title":"Test","text":"<p>This will generate Berksfile.lock</p> <pre><code>berks install\n</code></pre>"},{"location":"how-to-use-berkshelf-chef-zero-vagrant-and-virtualbox/#create-vagrantfile","title":"Create Vagrantfile","text":"<p>Go to the Chef Repo root (<code>ubuntu-chef-repo</code>).</p> <pre><code>touch Vagrantfile\n</code></pre> <p>Open <code>Vagrantfile</code> and replace its content with the following one:</p> <pre><code># -*- mode: ruby -*-\n# vi: set ft=ruby :\n\nVagrant.configure(2) do |config|\n  # Every Vagrant development environment requires a box. You can search for\n  # boxes at https://atlas.hashicorp.com/search.\n  #\n  config.vm.box = \"ubuntu/trusty64\"\n\n  # Provider-specific configuration so you can fine-tune various\n  # backing providers for Vagrant. These expose provider-specific options.\n  #\n  config.vm.provider \"virtualbox\" do |vb|\n    # For a complete reference, please see the online documentation at\n    # https://docs.vagrantup.com/v2/virtualbox/configuration.html\n\n    # Name used in Oracle VM VirtualBox Manager GUI\n    vb.name = \"berkshelf-ubuntu-kitchen\"\n\n    # Customize the amount of memory on the VM (in MB):\n    vb.memory = \"2048\"\n\n    # Customize the amount of video memory on the VM (in MB):\n    vb.customize [\"modifyvm\", :id, \"--vram\", \"128\"]\n  end\n\n  # Install the latest version of Chef.\n  # For more information see https://github.com/chef/vagrant-omnibus\n  #\n  config.omnibus.chef_version = :latest\n\n  # Enabling the Berkshelf plugin.\n  config.berkshelf.enabled = true\n\n  # Provision with Chef Zero\n  #\n  config.vm.provision :chef_zero do |chef|\n    # Specify the local paths where Chef data is stored\n    chef.cookbooks_path = [ 'cookbooks', 'site-cookbooks' ]\n    chef.data_bags_path = \"data_bags\"\n    chef.nodes_path = \"nodes\"\n    chef.roles_path = \"roles\"\n\n    # Add a recipe\n    chef.add_recipe \"main::default\"\n  end\nend\n</code></pre>"},{"location":"how-to-use-berkshelf-chef-zero-vagrant-and-virtualbox/#test_1","title":"Test","text":"<pre><code>vagrant up\nvagrant provision\n</code></pre>"},{"location":"install-nginx-ubuntu-using-chef/","title":"How To Install Nginx On Ubuntu Using Chef","text":"<p>In this post we show how to install NGINX on Ubuntu using Chef on Windows 10 workstation.</p> <p>All commands are executed in PowerShell on a Windows workstation.  </p>"},{"location":"install-nginx-ubuntu-using-chef/#before-you-begin","title":"Before You Begin","text":""},{"location":"install-nginx-ubuntu-using-chef/#install-chocolatey","title":"Install Chocolatey","text":"<p>If you do not have Chocolatey, you can install it by following the instructions on chocolatey.org. You may also see this post for instructions on how to set the Chocolatey cache location. </p>"},{"location":"install-nginx-ubuntu-using-chef/#install-chef-development-kit-chefdk","title":"Install Chef Development Kit (ChefDK)","text":"<p>In PowerShell as Administrator:</p> <pre><code>choco install chefdk\n</code></pre>"},{"location":"install-nginx-ubuntu-using-chef/#install-virtualbox-and-vagrant","title":"Install VirtualBox and Vagrant","text":"<p>To install VirtualBox and Vagrant, follow the steps described in Ubuntu with Vagrant and VirtualBox on Windows.</p>"},{"location":"install-nginx-ubuntu-using-chef/#install-vagrant-plugins","title":"Install Vagrant Plugins","text":"<pre><code>vagrant plugin install vagrant-omnibus\nvagrant plugin install vagrant-berkshelf\nvagrant plugin install vagrant-hostmanager\n</code></pre>"},{"location":"install-nginx-ubuntu-using-chef/#create-chef-cookbook","title":"Create Chef Cookbook","text":"<p>This directory will become the root of your source repository:</p> <pre><code>chef generate cookbook my_ubuntu_nginx\ncd my_ubuntu_nginx\n</code></pre>"},{"location":"install-nginx-ubuntu-using-chef/#ensure-the-apt-cache-is-up-to-date","title":"Ensure the apt cache is up to date","text":""},{"location":"install-nginx-ubuntu-using-chef/#reference-the-apt-cookbook","title":"Reference the <code>apt</code> Cookbook","text":"<p>Add this line to <code>metadata.rb</code>:</p> <pre><code>depends 'apt', '~&gt; 2.9.2'\n</code></pre> <p>To get the latest version string, run <code>knife cookbook site show apt</code>: </p> <pre><code>chef exec knife cookbook site show apt | grep latest_version\nlatest_version:     https://supermarket.chef.io/api/v1/cookbooks/apt/versions/2.9.2\n</code></pre> <p>Here is the complete file:</p> <pre><code>name 'my_ubuntu_nginx'\nmaintainer 'The Authors'\nmaintainer_email 'you@example.com'\nlicense 'all_rights'\ndescription 'Installs/Configures my_ubuntu_nginx'\nlong_description 'Installs/Configures my_ubuntu_nginx'\nversion '0.1.0'\n\ndepends 'apt', '~&gt; 2.9.2'\n</code></pre>"},{"location":"install-nginx-ubuntu-using-chef/#set-the-apt-cookbooks-default-recipe-to-run","title":"Set the apt cookbook's default recipe to run","text":"<p>Add this line to <code>recipes/default.rb</code>:</p> <pre><code>include_recipe 'apt::default'\n</code></pre> <p>Here is the complete file:</p> <pre><code>#\n# Cookbook Name:: my_ubuntu_nginx\n# Recipe:: default\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\ninclude_recipe 'apt::default'\n</code></pre>"},{"location":"install-nginx-ubuntu-using-chef/#test","title":"Test","text":"<pre><code>chef exec berks install\n</code></pre> <p>This generates <code>Berksfile.lock</code> file.</p>"},{"location":"install-nginx-ubuntu-using-chef/#configure-nginx","title":"Configure NGINX","text":""},{"location":"install-nginx-ubuntu-using-chef/#reference-the-nginx-cookbook","title":"Reference the nginx cookbook","text":"<p>We need the <code>nginx</code> cookbook for it's <code>nginx::repo</code> recipe. Add this line to <code>metadata.rb</code>:</p> <pre><code>depends 'nginx', '~&gt; 2.7.6'\n</code></pre> <p>To get the latest version string, run <code>knife cookbook site show nginx</code>: </p> <pre><code>chef exec knife cookbook site show nginx | grep latest_version\nlatest_version:     https://supermarket.chef.io/api/v1/cookbooks/nginx/versions/2.7.6\n</code></pre> <p>Here is the complete file:</p> <pre><code>name 'my_ubuntu_nginx'\nmaintainer 'The Authors'\nmaintainer_email 'you@example.com'\nlicense 'all_rights'\ndescription 'Installs/Configures my_ubuntu_nginx'\nlong_description 'Installs/Configures my_ubuntu_nginx'\nversion '0.1.0'\n\ndepends 'apt', '~&gt; 2.9.2'\ndepends 'nginx', '~&gt; 2.7.6'\n</code></pre>"},{"location":"install-nginx-ubuntu-using-chef/#write-the-install_nginx-recipe","title":"Write the install_nginx recipe","text":"<p>The first step is to create the recipe file, <code>install_nginx.rb</code>. Run the following command to generate it:</p> <pre><code>chef generate recipe install_nginx\n</code></pre> <p>Write out <code>recipes/install_nginx.rb</code> like this:</p> <pre><code>#\n# Cookbook Name:: my_ubuntu_nginx\n# Recipe:: install_nginx\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\n# Only needed if you want to install latest stable package from nginx.org\ninclude_recipe 'nginx::repo'\n\npackage 'nginx' do\n  action :install\nend\n\nservice 'nginx' do\n  supports status: true, restart: true, reload: true\n  action :enable\nend\n</code></pre>"},{"location":"install-nginx-ubuntu-using-chef/#set-the-install_nginx-recipe-to-run","title":"Set the install_nginx recipe to run","text":"<p>Add this line to <code>cookbooks/my_web_server/recipes/default.rb</code>:</p> <pre><code>include_recipe 'my_ubuntu_nginx::install_nginx'\n</code></pre> <p>Here is the complete file:</p> <pre><code>#\n# Cookbook Name:: my_ubuntu_nginx\n# Recipe:: default\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\ninclude_recipe 'apt::default'\ninclude_recipe 'my_ubuntu_nginx::install_nginx'\n</code></pre>"},{"location":"install-nginx-ubuntu-using-chef/#update-the-integration-test","title":"Update the integration test","text":"<p>Replace the contents of <code>test/integration/default/serverspec/default_spec.rb</code> with this code:</p> <pre><code>require 'spec_helper'\n\ndescribe 'my_ubuntu_nginx::default' do\n  # Serverspec examples can be found at\n  # http://serverspec.org/resource_types.html\n  describe package('nginx') do\n    it { should be_installed }\n  end\n\n  describe service('nginx') do\n    it { should be_enabled }\n    it { should be_running }\n  end\nend\n</code></pre>"},{"location":"install-nginx-ubuntu-using-chef/#test_1","title":"Test","text":""},{"location":"install-nginx-ubuntu-using-chef/#ruby-lint","title":"Ruby Lint","text":"<pre><code>chef exec rubocop\n</code></pre>"},{"location":"install-nginx-ubuntu-using-chef/#chef-lint","title":"Chef Lint","text":"<pre><code>chef exec foodcritic .\n</code></pre>"},{"location":"install-nginx-ubuntu-using-chef/#unit-tests","title":"Unit Tests","text":"<p>Install / Update cookbooks:</p> <pre><code>chef exec berks install\n</code></pre> <p>Create a <code>.rspec</code> file:</p> <pre><code>touch .rspec\n</code></pre> <p>Paste these lines in <code>.rspec</code></p> <pre><code>--color\n--format documentation\n</code></pre> <p>Run: </p> <pre><code>chef exec rspec\n</code></pre>"},{"location":"install-nginx-ubuntu-using-chef/#integration-tests","title":"Integration Tests","text":"<p>Update <code>.kitchen.yml</code> to include the Ubuntu platform only. This is how it should look:</p> <pre><code>---\ndriver:\n  name: vagrant\n  network:\n    - [\"private_network\", {type: \"dhcp\"}]\n\nprovisioner:\n  name: chef_zero\n\nplatforms:\n  - name: ubuntu-14.04\n\nsuites:\n  - name: default\n    run_list:\n      - recipe[my_ubuntu_nginx::default]\n</code></pre> <p>Run the integration tests:</p> <pre><code>chef exec kitchen test --destroy=never\n</code></pre>"},{"location":"getting-started-flashdevelop-windows-10/","title":"Getting Started with FlashDevelop on Windows 10","text":"<p>FlashDevelop is a free IDE for Windows. You can use it to develop Adobe Flash and AIR applications using ActionScript. </p>"},{"location":"getting-started-flashdevelop-windows-10/#install-chocolatey","title":"Install Chocolatey","text":"<p>Chcocolatey is a package manager for Windows.</p> <p>Open PowerShell as Administrator and run the following command:</p> <pre><code>iex ((new-object net.webclient).DownloadString('https://chocolatey.org/install.ps1'))\n</code></pre>"},{"location":"getting-started-flashdevelop-windows-10/#install-java-8-sdk-32-bit","title":"Install Java 8 SDK 32-bit","text":"<p>FlashDevelop requires a 32-bit java on the system path.</p> <p>In PowerShell as Administrator:</p> <pre><code>choco install jdk8 -params \"x64=false\"\n</code></pre>"},{"location":"getting-started-flashdevelop-windows-10/#install-flashdevelop","title":"Install FlashDevelop","text":"<p>Download the latest FlashDevelop setup package from www.flashdevelop.org and install it, <code>FlashDevelop-5.0.2.exe</code> at the time of writing.</p>"},{"location":"getting-started-flashdevelop-windows-10/#install-additional-software","title":"Install Additional Software","text":"<ol> <li>Start FlashDevelop</li> <li>Install SDKs and other tools using AppMan, from Tools -&gt; Install Software ...<ul> <li>Flex SDK + AIR SDK</li> <li>Flash Player (SA)</li> </ul> </li> <li>Restart FlashDevelop, so that it can detect the installed SDKs and tools properly.</li> </ol>"},{"location":"getting-started-flashdevelop-windows-10/#create-new-project","title":"Create New Project","text":"<ol> <li>Create a new project from: Project -&gt; New Project</li> <li>For project type choose AS3 Project</li> <li>Set a breakpoint in Main method - Ctrl+Shift+B</li> <li>Compile - F11</li> <li>Debug - F5 </li> </ol>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/","title":"How to Build an NGINX Server and Deploy a Python Flask App Using Chef","text":"<p>In this post we show how you can use Chef to build an Ubuntu 14.04 LTS web server running Nginx, Python 2, virtualenv, uWSGI, and Flask - all done on Windows 10 host. </p> <p>All commands are executed in PowerShell on a Windows workstation. The Chef version that is used is 12.5.1 - it is the version that comes with ChefDK 0.10.0. To avoid unexpected behavior, we recommend using those versions, when following this step-by-step guide.</p>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#before-you-begin","title":"Before You Begin","text":""},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#test-flask-application","title":"Test Flask Application","text":"<p>The test application that we use for this deployment is available in the my_flask_app repository. The application was created using Visual Studio 2015 with Python Tools for Visual Studio (PTVS).</p>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#install-chocolatey","title":"Install Chocolatey","text":"<p>If you do not have Chocolatey, you can install it by following the instructions on chocolatey.org. You may also see this post for instructions on how to set the Chocolatey cache location. </p>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#install-chef-development-kit-chefdk","title":"Install Chef Development Kit (ChefDK)","text":"<p>In PowerShell as Administrator:</p> <pre><code>choco install chefdk -version 0.10.0.1\n</code></pre> <p>Find your Chef version:</p> <pre><code>chef --version\n\nChef Development Kit Version: 0.10.0\nchef-client version: 12.5.1\nberks version: 4.0.1\nkitchen version: 1.4.2\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#install-virtualbox-and-vagrant","title":"Install VirtualBox and Vagrant","text":"<p>To install VirtualBox and Vagrant, follow the steps described in Ubuntu with Vagrant and VirtualBox on Windows.</p>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#install-vagrant-plugins","title":"Install Vagrant Plugins","text":"<pre><code>vagrant plugin install vagrant-omnibus\nvagrant plugin install vagrant-berkshelf\nvagrant plugin install vagrant-hostmanager\nvagrant plugin install vagrant-cachier\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#give-your-user-modify-access-to-windirsystem32driversetchosts","title":"Give your user <code>Modify</code> access to <code>WINDIR%\\System32\\drivers\\etc\\hosts</code>","text":"<p>This is needed by the vagrant-hostmanager Vagrant plugin. In PowerShell as Administrator:</p> <pre><code>$acl = Get-Acl -Path $env:SystemRoot\\System32\\drivers\\etc\\hosts\n$ar = New-Object System.Security.AccessControl.FileSystemAccessRule($env:username, 'Modify', 'None', 'None', 'Allow')\n$acl.SetAccessRule($ar)\nSet-Acl -Path $env:SystemRoot\\System32\\drivers\\etc\\hosts -AclObject $acl\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#create-chef-cookbook","title":"Create Chef Cookbook","text":"<p>This directory will become the root of your source repository:</p> <pre><code>chef generate cookbook my_flask_server\ncd my_flask_server\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#ensure-the-apt-cache-is-up-to-date","title":"Ensure the apt cache is up to date","text":""},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#reference-the-apt-cookbook","title":"Reference the <code>apt</code> Cookbook","text":"<p>Add this line to <code>metadata.rb</code>:</p> <pre><code>depends 'apt', '~&gt; 2.9.2'\n</code></pre> <p>To get the latest version string, run <code>knife cookbook site show apt</code>: </p> <pre><code>chef exec knife cookbook site show apt | grep latest_version\nlatest_version:     https://supermarket.chef.io/api/v1/cookbooks/apt/versions/2.9.2\n</code></pre> <p>Here is the complete file:</p> <pre><code>name 'my_flask_server'\nmaintainer 'The Authors'\nmaintainer_email 'you@example.com'\nlicense 'all_rights'\ndescription 'Installs/Configures my_flask_server'\nlong_description 'Installs/Configures my_flask_server'\nversion '0.1.0'\n\ndepends 'apt', '~&gt; 2.9.2'\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#set-the-apt-cookbooks-default-recipe-to-run","title":"Set the apt cookbook's default recipe to run","text":"<p>Add this line to <code>recipes/default.rb</code>:</p> <pre><code>include_recipe 'apt::default'\n</code></pre> <p>Here is the complete file:</p> <pre><code>#\n# Cookbook Name:: my_flask_server\n# Recipe:: default\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\ninclude_recipe 'apt::default'\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#prepare-for-test-driven-development","title":"Prepare for Test Driven Development","text":""},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#add-rspec-file","title":"Add <code>.rspec</code> file","text":"<p><pre><code>touch .rspec\n</code></pre> Paste this in the <code>.rspec</code> file:</p> <pre><code>--color\n--format documentation\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#add-kitchenvagrant_cachierrb-file","title":"Add <code>.kitchen.vagrant_cachier.rb</code> file","text":"<p>This file will be merged within Test Kitchen's generated Vagrantfile. In it, we put the configuration for the <code>vagrant-cachier</code> plugin</p> <p><pre><code>touch .kitchen.vagrant_cachier.rb\n</code></pre> Paste this in the <code>.kitchen.vagrant_hostmanager.rb</code> file:</p> <pre><code># This requires vagrant-cachier plugin.\n# For more information see http://fgrehm.viewdocs.io/vagrant-cachier/\n#\nVagrant.configure(\"2\") do |config|\n  if Vagrant.has_plugin?(\"vagrant-cachier\")\n    config.cache.auto_detect = true\n    config.cache.scope = :box\n  end\n\n  if Vagrant.has_plugin?(\"vagrant-omnibus\")\n    config.omnibus.cache_packages = true\n    config.omnibus.chef_version = \"12.5.1\"\n  end\n\n  config.vbguest.auto_update = false\nend\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#add-kitchenvagrant_hostmanagerrb-file","title":"Add <code>.kitchen.vagrant_hostmanager.rb</code> file","text":"<p>This file will be merged within Test Kitchen's generated Vagrantfile. In it, we put the configuration for the <code>vagrant-hostmanager</code> plugin, which updates <code>C:/Windows/System32/drivers/etc/hosts</code>, and allows you to access the virtual machine by name instead of IP address, e.g. <code>default-ubuntu-1404</code>.  </p> <pre><code>touch .kitchen.vagrant_hostmanager.rb\n</code></pre> <p>Paste this in the <code>.kitchen.vagrant_hostmanager.rb</code> file:</p> <pre><code># This requires vagrant-hostmanager plugin.\n# For more information see https://github.com/smdahlen/vagrant-hostmanager\n#\nVagrant.configure(\"2\") do |config|\n  if Vagrant.has_plugin?(\"vagrant-hostmanager\")\n    # update /ect/hosts on all running guests\n    config.hostmanager.enabled = true\n\n    # do not add offline guests to /etc/hosts\n    config.hostmanager.include_offline = false\n\n    # use the private ip address with ip_reslover, see below\n    config.hostmanager.ignore_private_ip = false\n\n    # custom IP resolver\n    # get each guest's IP address by running `hostname -I` on the guest\n    config.hostmanager.ip_resolver = proc do |vm, resolving_vm|\n      if hostname = (vm.ssh_info &amp;&amp; vm.ssh_info[:host])\n        `vagrant ssh -c \"hostname -I\"`.split()[1]\n      end\n    end\n\n    # also update host's /ect/hosts\n    config.hostmanager.manage_host = true\n  end\nend\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#update-kitchenyml","title":"Update <code>.kitchen.yml</code>","text":"<p>Update <code>.kitchen.yml</code> to include only the <code>ubuntu-14.04</code> platform for now. Also add the data bag path and Chef version. This is how it should look at the end:</p> <pre><code>---\ndriver:\n  name: vagrant\n  require_chef_omnibus: 12.5.1\n  network:\n    - [\"private_network\", {type: \"dhcp\"}]\n  vagrantfiles:\n    - .kitchen.vagrant_cachier.rb\n    - .kitchen.vagrant_hostmanager.rb\n\nprovisioner:\n  name: chef_zero\n\nplatforms:\n  - name: ubuntu-14.04\n\nsuites:\n  - name: default\n    run_list:\n      - recipe[my_flask_server::default]\n    attributes:\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#run-all-tests-manually","title":"Run All Tests Manually","text":"<p>Run all tests manually to verify everything works as expected. </p> <p>First install cookbook dependencies:</p> <pre><code>chef exec berks install\n</code></pre> <p>then run the tests:</p> <pre><code>chef exec rubocop\nchef exec foodcritic .\nchef exec rspec\nchef exec kitchen test --destroy=never\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#setup-a-build-system","title":"Setup a Build System","text":"<p>We will use Rake to automate the build and test tasks. Rake already comes preinstalled in the ChefDK.</p>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#create-a-rakefile","title":"Create a Rakefile","text":"<pre><code>touch Rakefile\n</code></pre> <p>Paste this into the <code>Rakefile</code>:</p> <pre><code># See:\n# https://github.com/chef-cookbooks/chef-server/blob/master/Rakefile\n\nrequire 'rspec/core/rake_task'\nrequire 'rubocop/rake_task'\nrequire 'foodcritic'\nrequire 'kitchen'\n\n# Style tests. Rubocop and Foodcritic\nnamespace :style do\n  desc 'Run Ruby style checks'\n  RuboCop::RakeTask.new(:ruby)\n\n  desc 'Run Chef style checks'\n  FoodCritic::Rake::LintTask.new(:chef) do |t|\n    t.options = {\n      fail_# categories: ['any']\n    }\n  end\nend\n\ndesc 'Run all style checks'\ntask style: ['style:ruby', 'style:chef']\n\n# Rspec and ChefSpec\ndesc 'Run ChefSpec examples'\nRSpec::Core::RakeTask.new(:spec)\n\n# Integration tests. Kitchen.ci\nnamespace :integration do\n  desc 'Same as `chef exec kitchen test -d=never`'\n  task :test do\n    Kitchen.logger = Kitchen.default_file_logger\n    Kitchen::Config.new.instances.each do |instance|\n      instance.test(:never)\n    end\n  end\nend\n\n# Default\ntask default: ['style', 'spec', 'integration:test']\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#test","title":"Test","text":""},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#list-tasks","title":"List Tasks","text":"<pre><code>chef exec rake -T\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#run-all-tests","title":"Run all tests","text":"<pre><code>chef exec rake\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#create-application-directory","title":"Create Application Directory","text":""},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#add-an-integration-test","title":"Add an integration test","text":"<pre><code>touch test/integration/default/serverspec/my_app_dir_spec.rb\n</code></pre> <p>Add this code to <code>my_app_dir_spec.rb</code>:</p> <pre><code>require 'spec_helper'\n\ndescribe 'my_flask_server::my_app_dir' do\n  # Serverspec examples can be found at\n  # http://serverspec.org/resource_types.html\n\n  # verify virtual environment dir\n  describe file('/var/www/my_flask_app/shared/.env2') do\n    it { should be_directory }\n    it { should be_owned_by 'www-data' }\n    it { should be_grouped_into 'www-data' }\n  end\n\n  # verify uwsgi dir\n  describe file('/var/www/my_flask_app/shared/.uwsgi') do\n    it { should be_directory }\n    it { should be_owned_by 'www-data' }\n    it { should be_grouped_into 'www-data' }\n  end\n\n  # verify ssh dir\n  describe file('/var/www/.ssh') do\n    it { should be_directory }\n    it { should be_owned_by 'www-data' }\n    it { should be_grouped_into 'www-data' }\n  end\n\n  # verify pip cache dir\n  describe file('/var/www/.cache') do\n    it { should be_directory }\n    it { should be_owned_by 'www-data' }\n    it { should be_grouped_into 'www-data' }\n  end\nend\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#write-the-my_app_dir-recipe","title":"Write the <code>my_app_dir</code> recipe","text":"<p>The first step is to create the recipe file, <code>my_app_dir.rb</code>. Run the following command to generate it:</p> <pre><code>chef generate recipe my_app_dir\nrm spec/unit/recipes/my_app_dir_spec.rb\n</code></pre> <p>Write out <code>recipes/my_app_dir.rb</code> like this:</p> <pre><code>#\n# Cookbook Name:: my_flask_server\n# Recipe:: my_app_dir\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\n# app root directory\ndirectory '/var/www/my_flask_app' do\n  action :create\n  recursive true\n  user 'www-data'\n  group 'www-data'\nend\n\n# app shared directory\ndirectory '/var/www/my_flask_app/shared' do\n  action :create\n  user 'www-data'\n  group 'www-data'\nend\n\n# for virtualenv\ndirectory '/var/www/my_flask_app/shared/.env2' do\n  action :create\n  user 'www-data'\n  group 'www-data'\nend\n\n# for uwsgi socket and uwsgi config\ndirectory '/var/www/my_flask_app/shared/.uwsgi' do\n  action :create\n  user 'www-data'\n  group 'www-data'\nend\n\n# required by ssh\ndirectory '/var/www/.ssh' do\n  action :create\n  recursive true\n  user 'www-data'\n  group 'www-data'\nend\n\n# required by pip\ndirectory '/var/www/.cache' do\n  action :create\n  recursive true\n  user 'www-data'\n  group 'www-data'\nend\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#set-the-my_app_dirrb-recipe-to-run","title":"Set the <code>my_app_dir.rb</code> recipe to run","text":"<p>Add this line to <code>recipes/default.rb</code>:</p> <pre><code>include_recipe 'my_flask_server::my_app_dir'\n</code></pre> <p>Here is the complete file:</p> <pre><code>#\n# Cookbook Name:: my_flask_server\n# Recipe:: default\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\ninclude_recipe 'apt::default'\n\ninclude_recipe 'my_flask_server::my_app_dir'\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#run-all-tests_1","title":"Run all tests","text":"<pre><code>chef exec rake\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#install-python","title":"Install Python","text":""},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#add-an-integration-test_1","title":"Add an integration test","text":"<pre><code>touch test/integration/default/serverspec/my_app_python_spec.rb\n</code></pre> <p>Add this code to <code>my_app_python_spec.rb</code>:</p> <pre><code>require 'spec_helper'\n\ndescribe 'my_flask_server::my_app_python' do\n  # Serverspec examples can be found at\n  # http://serverspec.org/resource_types.html\n\n  # verify system python\n  describe package('python') do\n    it { should be_installed }\n  end\n\n  # verify system pip\n  describe command('which pip') do\n    its(:stdout) { should contain '/usr/local/bin/pip' }\n  end\n\n  # verify system setuptools\n  describe command('which easy_install') do\n    its(:stdout) { should contain '/usr/local/bin/easy_install' }\n  end\n\n  # verify system virtualenv\n  describe command('which virtualenv') do\n    its(:stdout) { should contain '/usr/local/bin/virtualenv' }\n  end\n\n  # verify my_flask_app virtual environment\n  # See `helpers/serverspec/type/virtualenv.rb`\n  describe virtualenv('/var/www/my_flask_app/shared/.env2') do\n    it { should be_virtualenv }\n  end\nend\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#create-virtualenv-serverspec-type","title":"Create <code>virtualenv</code> serverspec type","text":"<pre><code>mkdir test/integration/helpers/serverspec/type\ntouch test/integration/helpers/serverspec/type/virtualenv.rb\n</code></pre> <p>Paste this code into <code>virtualenv.rb</code>:</p> <pre><code>##############################################################################\n# You can find the original code at:\n# &lt;https://github.com/jantman/serverspec-extended-types&gt;\n# Licensed under the MIT License\n##############################################################################\n\n# Serverspec\nmodule Serverspec\n  # Type\n  module Type\n    # Virtualenv\n    class Virtualenv &lt; Base\n      # Test whether this appears to be a working venv\n      #\n      # Tests performed:\n      # - venv_path/bin/pip executable by owner?\n      # - venv_path/bin/python executable by owner?\n      # - venv_path/bin/activate readable by owner?\n      # - 'export VIRTUAL_ENV' in venv_path/bin/activate?\n      #\n      # @example\n      #   describe virtualenv('/path/to/venv') do\n      #     it { should be_virtualenv }\n      #   end\n      #\n      # @api public\n      # @return [Boolean]\n      def virtualenv?\n        pip_path = ::File.join(@name, 'bin', 'pip')\n        python_path = ::File.join(@name, 'bin', 'python')\n        act_path = ::File.join(@name, 'bin', 'activate')\n        cmd = \"grep -q 'export VIRTUAL_ENV' #{act_path}\"\n\n        @runner.check_file_is_executable(pip_path, 'owner') &amp;&amp;\n          @runner.check_file_is_executable(python_path, 'owner') &amp;&amp;\n          @runner.check_file_is_readable(act_path, 'owner') &amp;&amp;\n          @runner.run_command(cmd).exit_status.to_i == 0\n      end\n    end\n\n    # Serverspec Type wrapper method for Serverspec::Type::Virtualenv\n    #\n    # @example\n    #   describe virtualenv('/path/to/venv') do\n    #     # tests here\n    #   end\n    #\n    # @param name [String] the absolute path to the virtualenv root\n    #\n    # @api public\n    # @return {Serverspec::Type::Virtualenv}\n    def virtualenv(name)\n      Virtualenv.new(name)\n    end\n  end\nend\n\ninclude Serverspec::Type\n</code></pre> <p>Add this line to <code>test/integration/helpers/serverspec/spec_helper.rb</code>:</p> <pre><code>require 'type/virtualenv'\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#reference-the-poise-python-cookbook","title":"Reference the <code>poise-python</code> cookbook","text":"<p>Add this line to <code>metadata.rb</code>:</p> <pre><code>depends 'poise-python', '~&gt; 1.2.1'\n</code></pre> <p>To get the latest version string, run <code>knife cookbook site show nginx</code>: </p> <pre><code>chef exec knife cookbook site show poise-python | grep latest_version\nlatest_version:     https://supermarket.chef.io/api/v1/cookbooks/poise-python/versions/1.2.1\n</code></pre> <p>Here is the complete file:</p> <pre><code>name 'my_flask_server'\nmaintainer 'The Authors'\nmaintainer_email 'you@example.com'\nlicense 'all_rights'\ndescription 'Installs/Configures my_flask_server'\nlong_description 'Installs/Configures my_flask_server'\nversion '0.1.0'\n\ndepends 'apt', '~&gt; 2.9.2'\ndepends 'poise-python', '~&gt; 1.2.1'\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#write-the-my_app_python-recipe","title":"Write the <code>my_app_python</code> recipe","text":"<p>The first step is to create the recipe file, <code>my_app_python.rb</code>. Run the following command to generate it:</p> <p><pre><code>chef generate recipe my_app_python\nrm spec/unit/recipes/my_app_python_spec.rb\n</code></pre> Write out <code>recipes/my_app_python.rb</code> like this:</p> <pre><code>#\n# Cookbook Name:: my_flask_server\n# Recipe:: my_python\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\n# See https://supermarket.chef.io/cookbooks/poise-python\n\n# install python 2\npython_runtime 'python_2' do\n  version '2'\nend\n\n# create my_flask_app virtual environment\npython_virtualenv 'my_flask_app_env' do\n  path '/var/www/my_flask_app/shared/.env2'\n  python 'python_2'\n  user 'www-data'\n  group 'www-data'\nend\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#set-the-my_app_python-recipe-to-run","title":"Set the <code>my_app_python</code> recipe to run","text":"<p>Add this line to <code>recipes/default.rb</code>:</p> <pre><code>include_recipe 'my_flask_server::my_app_python'\n</code></pre> <p>Here is the complete file:</p> <pre><code>#\n# Cookbook Name:: my_flask_server\n# Recipe:: default\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\ninclude_recipe 'apt::default'\n\ninclude_recipe 'my_flask_server::my_app_dir'\n\ninclude_recipe 'my_flask_server::my_app_python'\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#run-all-tests_2","title":"Run all tests","text":"<pre><code>chef exec rake\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#install-ssh-key","title":"Install SSH Key","text":""},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#update-kitchenyml_1","title":"Update <code>.kitchen.yml</code>","text":"<p>Add this code to <code>.kitchen.yml</code> under <code>provisioner</code>: </p> <pre><code>    data_bags_path: \"./data_bags\"\n    encrypted_data_bag_secret_key_path: &lt;%= ENV['CHEF_DATA_BAG_SECRET'] %&gt;\n</code></pre> <p>Here is the complete file:</p> <pre><code>---\ndriver:\n  name: vagrant\n  require_chef_omnibus: 12.5.1\n  network:\n    - [\"private_network\", {type: \"dhcp\"}]\n  vagrantfiles:\n    - .kitchen.vagrant_cachier.rb\n    - .kitchen.vagrant_hostmanager.rb\n\nprovisioner:\n  name: chef_zero\n  data_bags_path: \"./data_bags\"\n  encrypted_data_bag_secret_key_path: &lt;%= ENV['CHEF_DATA_BAG_SECRET'] %&gt;\n\nplatforms:\n  - name: ubuntu-14.04\n\nsuites:\n  - name: default\n    run_list:\n      - recipe[my_flask_server::default]\n    attributes:\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#generate-a-data-bag-secret","title":"Generate a Data Bag Secret","text":"<pre><code>mkdir ~/.chef\n</code></pre> <pre><code>$key = New-Object byte[](512)\n$rng = [System.Security.Cryptography.RNGCryptoServiceProvider]::Create().GetBytes($key)\n[Convert]::ToBase64String($key) | Out-File \"~/.chef/chef_data_bag_secret\" -encoding \"UTF8\"\n[array]::Clear($key, 0, $key.Length)\n</code></pre> <p>This key will be used to encrypt sensitive cookbook information like SSH private keys. Make sure you store a copy of the <code>~/.chef/chef_data_bag_secret</code> file in a secure location.</p>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#create-environment-variable","title":"Create Environment Variable","text":"<pre><code>$chef_secret = (rvpa '~/.chef/chef_data_bag_secret').Path\n$env:CHEF_DATA_BAG_SECRET = $chef_secret\n[Environment]::SetEnvironmentVariable(\"CHEF_DATA_BAG_SECRET\", $chef_secret, \"User\")\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#generate-ssh-key","title":"Generate SSH Key","text":"<pre><code>mkdir ~/.ssh\n</code></pre> <p>Make sure you use an empty passphrase.</p> <pre><code>pushd\ncd ~/.ssh\nssh-keygen -f id_my_flask_app_deploy\npopd \n</code></pre> <p>If you have an existing key with a passphrase, remove the passphrase from a private key using code similar to:</p> <pre><code>ssh-keygen -p -P 'PASSPHRASE' -N '' -f id_deploy\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#add-the-ssh-key-to-bitbucket","title":"Add the SSH key to Bitbucket","text":"<p>We will use Bitbucket to host the source code of our test application. Go ahead and fork the my_flask_app repository. </p> <p>Then add the public part of the SSH key, <code>~/.ssh/id_my_flask_app_deploy.pub</code>, to your Bitbucket fork. See Use deployment keys for more details. </p>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#create-data-bag-item","title":"Create Data Bag Item","text":"<pre><code>$json = @\"\n{\n    \"id\" : \"my_flask_app\",\n    \"deploy_key\" : \"&lt;key&gt;\"\n}\n\"@\n$json = $json -replace \"&lt;key&gt;\", ([io.file]::ReadAllText(\".ssh/id_my_flask_app_deploy\").Replace(\"`n\", \"\\n\") + \"\\n\")\n[io.file]::WriteAllText(\".chef/my_flask_app.json\", $json)\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#encrypt-data-bag-item","title":"Encrypt Data Bag Item","text":"<pre><code>mkdir ./data_bags/secrets\n\nchef exec knife data bag from file secrets ~/.chef/my_flask_app.json -z --secret-file (rvpa ~/.chef/chef_data_bag_secret).Path\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#create-ssh-wrapper-script","title":"Create SSH Wrapper Script","text":"<p>Create <code>files/default/wrap-ssh4git.sh</code> file:</p> <pre><code>chef generate file wrap-ssh-4-git.sh\n</code></pre> <p>Add this content to the <code>files/default/wrap-ssh-4-git.sh</code>:</p> <pre><code>#!/bin/bash\nssh -o \"StrictHostKeyChecking=no\" -i \"/tmp/my_flask_app/ssh/id_my_flask_app_deploy\" $1 $2\n</code></pre> <p>IMPORTANT: Make sure the file uses Unix Line Ending (\\n, LF) and UTF-8 encoding. Otherwise you may get weird errors when Chef client runs the script during deployment.</p>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#add-an-integration-test_2","title":"Add an integration test","text":"<pre><code>touch test/integration/default/serverspec/my_app_ssh_spec.rb\n</code></pre> <p>Add this code to <code>my_app_ssh_spec.rb</code>:</p> <pre><code>require 'spec_helper'\n\ndescribe 'my_flask_server::my_app_ssh' do\n  # Serverspec examples can be found at\n  # http://serverspec.org/resource_types.html\n\n  describe file('/tmp/my_flask_app/ssh/wrap-ssh-4-git.sh') do\n    it { should be_file }\n    it { should be_mode '755' }\n    it { should be_owned_by 'www-data' }\n    it { should be_grouped_into 'www-data' }\n  end\n\n  describe file('/tmp/my_flask_app/ssh/id_my_flask_app_deploy') do\n    it { should be_file }\n    it { should be_mode '600' }\n    it { should be_owned_by 'www-data' }\n    it { should be_grouped_into 'www-data' }\n  end\nend\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#write-the-my_app_ssh-recipe","title":"Write the <code>my_app_ssh</code> recipe","text":"<p>The first step is to create the recipe file, <code>my_app_ssh.rb</code>. Run the following command to generate it:</p> <pre><code>chef generate recipe my_app_ssh\nrm spec/unit/recipes/my_app_ssh_spec.rb\n</code></pre> <p>Write out <code>recipes/my_app_ssh.rb</code> like this:</p> <pre><code>#\n# Cookbook Name:: my_flask_server\n# Recipe:: my_app_ssh\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\ndirectory '/tmp/my_flask_app/ssh' do\n  recursive true\n  user 'www-data'\n  group 'www-data'\nend\n\n# copy git ssh wrapper\ncookbook_file '/tmp/my_flask_app/ssh/wrap-ssh-4-git.sh' do\n  source 'wrap-ssh-4-git.sh'\n  mode 0755\n  user 'www-data'\n  group 'www-data'\nend\n\n# decrypt the private ssh key\nmy_flask_app = Chef::EncryptedDataBagItem.load('secrets', 'my_flask_app')\n\nif my_flask_app['deploy_key']\n  ruby_block 'decrypt `id_my_flask_app_deploy` private ssh key' do\n    block do\n      f = ::File.open('/tmp/my_flask_app/ssh/id_my_flask_app_deploy', 'w')\n      f.print(my_flask_app['deploy_key'])\n      f.close\n    end\n\n    not_if do\n      ::File.exist?('/tmp/my_flask_app/ssh/id_my_flask_app_deploy')\n    end\n  end\n\n  # change permissions\n  file '/tmp/my_flask_app/ssh/id_my_flask_app_deploy' do\n    mode 0600\n    user 'www-data'\n    group 'www-data'\n  end\nend\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#set-the-my_app_ssh-recipe-to-run","title":"Set the <code>my_app_ssh</code> recipe to run","text":"<p>Add this line to <code>recipes/default.rb</code>:</p> <pre><code>include_recipe 'my_flask_server::my_app_ssh'\n</code></pre> <p>Here is the complete file:</p> <pre><code>#\n# Cookbook Name:: my_flask_server\n# Recipe:: default\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\ninclude_recipe 'apt::default'\n\ninclude_recipe 'my_flask_server::my_app_dir'\n\ninclude_recipe 'my_flask_server::my_app_python'\n\ninclude_recipe 'my_flask_server::my_app_ssh'\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#run-all-tests_3","title":"Run all tests","text":"<pre><code>chef exec rake\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#deploy-application-from-git","title":"Deploy Application From Git","text":"<p>The test application is available in the my_flask_app repository on Bitbucket. Make sure you have forked it, and configured your SSH key, as explained earlier in this tutorial.</p>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#reference-the-git-cookbook","title":"Reference the <code>git</code> cookbook","text":"<p>Add this line to <code>metadata.rb</code>:</p> <pre><code>depends 'git', '~&gt; 4.3.6'\n</code></pre> <p>To get the latest version string, run <code>knife cookbook site show git</code>: </p> <pre><code>chef exec knife cookbook site show git | grep latest_version\nlatest_version:     https://supermarket.chef.io/api/v1/cookbooks/git/versions/4.3.6\n</code></pre> <p>Here is the complete file:</p> <pre><code>name 'my_flask_server'\nmaintainer 'The Authors'\nmaintainer_email 'you@example.com'\nlicense 'all_rights'\ndescription 'Installs/Configures my_flask_server'\nlong_description 'Installs/Configures my_flask_server'\nversion '0.1.0'\n\ndepends 'apt', '~&gt; 2.9.2'\ndepends 'poise-python', '~&gt; 1.2.1'\ndepends 'git', '~&gt; 4.3.6'\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#add-an-integration-test_3","title":"Add an integration test","text":"<pre><code>touch test/integration/default/serverspec/my_app_deploy_spec.rb\n</code></pre> <p>Add this code to <code>my_app_deploy_spec.rb</code>:</p> <pre><code>require 'spec_helper'\n\ndescribe 'my_flask_server::my_app_deploy' do\n  # Serverspec examples can be found at\n  # http://serverspec.org/resource_types.html\n\n  # verify git deployment\n  describe file('/var/www/my_flask_app/current') do\n    it { should be_symlink }\n  end\n\n  describe file('/var/www/my_flask_app/current/app.py') do\n    it { should exist }\n  end\n\n  # verify requirements.txt has been processed\n  # i.e. local python packages like `Flask` have been installed\n  describe command('/var/www/my_flask_app/shared/.env2/bin/pip list') do\n    its(:stdout) { should contain 'Flask' }\n    its(:exit_status) { should eq 0 }\n  end\nend\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#write-the-my_app_deploy-recipe","title":"Write the <code>my_app_deploy</code> recipe","text":"<p>The first step is to create the recipe file, <code>my_app_deploy.rb</code>. Run the following command to generate it:</p> <pre><code>chef generate recipe my_app_deploy\nrm spec/unit/recipes/my_app_deploy_spec.rb\n</code></pre> <p>Write out <code>recipes/my_app_deploy.rb</code> like this:</p> <pre><code>#\n# Cookbook Name:: my_flask_server\n# Recipe:: my_app_deploy\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\ninclude_recipe 'git::default'\n\n# checkout app from git repo / master branch\n# creates `releases`, and `current` directories\n# links `current` to latest revision\ndeploy_revision '/var/www/my_flask_app' do\n  action :deploy\n\n  repo 'ssh://git@bitbucket.org/vkantchev/my_flask_app.git'\n  branch 'master'\n\n  user 'www-data'\n  group 'www-data'\n\n  ssh_wrapper '/tmp/my_flask_app/ssh/wrap-ssh-4-git.sh'\n\n  purge_before_symlink []\n  create_dirs_before_symlink []\n\n  symlinks({})\n\n  migrate false\n  symlink_before_migrate({})\nend\n\n# install python packages in `my_flask_app_env` via pip\n# `my_flask_app_env` is defined in the `my_app_python.rb`\npip_requirements '/var/www/my_flask_app/current/requirements.txt' do\n  virtualenv 'my_flask_app_env'\n  user 'www-data'\n  group 'www-data'\n  action :install\nend\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#set-the-my_app_deploy-recipe-to-run","title":"Set the <code>my_app_deploy</code> recipe to run","text":"<p>Add this line to <code>recipes/default.rb</code>:</p> <pre><code>include_recipe 'my_flask_server::my_app_deploy'\n</code></pre> <p>Here is the complete file:</p> <pre><code>#\n# Cookbook Name:: my_flask_server\n# Recipe:: default\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\ninclude_recipe 'apt::default'\n\ninclude_recipe 'my_flask_server::my_app_dir'\n\ninclude_recipe 'my_flask_server::my_app_python'\n\ninclude_recipe 'my_flask_server::my_app_ssh'\ninclude_recipe 'my_flask_server::my_app_deploy'\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#run-all-tests_4","title":"Run all tests","text":"<pre><code>chef exec rake\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#install-uwsgi","title":"Install uWSGI","text":""},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#add-an-integration-test_4","title":"Add an integration test","text":"<p>Create <code>test/integration/default/serverspec/my_app_uwsgi_spec.rb</code></p> <p>Add this code to <code>my_app_uwsgi_spec.rb</code>:</p> <pre><code>require 'spec_helper'\n\ndescribe 'my_flask_server::my_app_uwsgi' do\n  # Serverspec examples can be found at\n  # http://serverspec.org/resource_types.html\n\n  # verify uWSGI package\n  describe command('/var/www/my_flask_app/shared/.env2/bin/pip list') do\n    its(:stdout) { should contain 'uWSGI' }\n    its(:exit_status) { should eq 0 }\n  end\n\n  # verify my_flask_app uWSGI serice\n  describe service('my_flask_app') do\n    it { should be_enabled }\n    it { should be_running }\n  end\nend\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#create-uwsgi-python-config-file","title":"Create uWSGI Python Config File","text":"<p>Create <code>files/default/uwsgi/my_flask_app.ini</code> file:</p> <pre><code>mkdir files/default/uwsgi\nchef generate file uwsgi/my_flask_app.ini\n</code></pre> <p>Add this content to the <code>files/default/uwsgi/my_flask_app.ini</code>:</p> <pre><code># See:\n# http://uwsgi-docs.readthedocs.org/en/latest/WSGIquickstart.html\n# http://uwsgi-docs.readthedocs.org/en/latest/Upstart.html\n# http://uwsgi-docs.readthedocs.org/en/latest/Options.html#plugin-python\n[uwsgi]\n\n# socket configuration\nsocket = /var/www/my_flask_app/shared/.uwsgi/my_flask_app.sock\nchmod-socket = 664\nvacuum = true\n\n# process configuration\nmaster = true\nprocesses = 2\nthreads = 4\ndie-on-term = true\n\n# app configuration\n\n# virtual environment\nvirtualenv = /var/www/my_flask_app/shared/.env2\n\n# call the app instance from the app.py module\nchdir = /var/www/my_flask_app/current\nmodule = app\ncallable = app\n</code></pre> <p>IMPORTANT: Make sure the file uses Unix Line Ending (\\n, LF) and UTF-8 encoding. Otherwise you may get weird errors when Chef client runs the script during deployment.</p>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#create-uwsgi-service-config-file","title":"Create uWSGI Service Config File","text":"<p>Create <code>files/default/uwsgi/my_flask_app.conf</code> file:</p> <pre><code>chef generate file uwsgi/my_flask_app.conf\n</code></pre> <p>Add this content to the <code>files/default/uwsgi/my_flask_app.conf</code>:</p> <pre><code>description \"uWSGI instance to serve my_flask_app\"\n\nstart on runlevel [2345]\nstop on runlevel [!2345]\n\nsetuid www-data\nsetgid www-data\n\nscript\n  cd /var/www/my_flask_app/shared\n  . .env2/bin/activate\n  uwsgi --ini .uwsgi/my_flask_app.ini\nend script\n</code></pre> <p>IMPORTANT: Make sure the file uses Unix Line Ending (\\n, LF) and UTF-8 encoding. Otherwise you may get weird errors when Chef client runs the script during deployment.</p>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#write-the-my_app_uwsgi-recipe","title":"Write the <code>my_app_uwsgi</code> recipe","text":"<p>The first step is to create the recipe file, <code>my_app_uwsgi.rb</code>. Run the following command to generate it:</p> <pre><code>chef generate recipe my_app_uwsgi\nrm spec/unit/recipes/my_app_uwsgi_spec.rb\n</code></pre> <p>Write out <code>recipes/my_app_uwsgi.rb</code> like this:</p> <pre><code>#\n# Cookbook Name:: my_flask_server\n# Recipe:: my_app_uwsgi\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\n# Install the uwsgi package in virtual environment using pip\n# See https://supermarket.chef.io/cookbooks/poise-python\n\n# install uwsgi python package\npython_package 'uwsgi' do\n  virtualenv 'my_flask_app_env'\n  user 'www-data'\n  group 'www-data'\nend\n\n# my_flask_app uWSGI configuration\ncookbook_file '/var/www/my_flask_app/shared/.uwsgi/my_flask_app.ini' do\n  source 'uwsgi/my_flask_app.ini'\n  owner 'root'\n  group 'root'\n  mode 0644\nend\n\n# create my_flask_app uWSGI service\ncookbook_file '/etc/init/my_flask_app.conf' do\n  source 'uwsgi/my_flask_app.conf'\n  owner 'root'\n  group 'root'\n  mode 0644\nend\n\n# start my_flask_app uWSGI service\nservice 'my_flask_app' do\n  provider Chef::Provider::Service::Upstart\n  supports status: true, restart: true, reload: true\n  action [:enable, :start]\nend\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#set-the-my_app_uwsgi-recipe-to-run","title":"Set the <code>my_app_uwsgi</code> recipe to run","text":"<p>Add this line to <code>recipes/default.rb</code>:</p> <pre><code>include_recipe 'my_flask_server::my_app_uwsgi'\n</code></pre> <p>Here is the complete file:</p> <pre><code>#\n# Cookbook Name:: my_flask_server\n# Recipe:: default\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\ninclude_recipe 'apt::default'\n\ninclude_recipe 'my_flask_server::my_app_dir'\n\ninclude_recipe 'my_flask_server::my_app_python'\n\ninclude_recipe 'my_flask_server::my_app_ssh'\ninclude_recipe 'my_flask_server::my_app_deploy'\n\ninclude_recipe 'my_flask_server::my_app_uwsgi'\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#run-all-tests_5","title":"Run all tests","text":"<pre><code>chef exec rake\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#install-nginx","title":"Install Nginx","text":""},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#add-an-integration-test_5","title":"Add an integration test","text":"<p>Rename <code>test/integration/default/serverspec/default_spec.rb</code> to <code>test/integration/default/serverspec/my_app_nginx_spec.rb</code> </p> <p>Replace the contents of <code>my_app_nginx_spec.rb</code> with this code:</p> <pre><code>require 'spec_helper'\n\ndescribe 'my_flask_server::my_app_nginx' do\n  # Serverspec examples can be found at\n  # http://serverspec.org/resource_types.html\n\n  # verify nginx package\n  describe package('nginx') do\n    it { should be_installed }\n  end\n\n  # verify nginx serice\n  describe service('nginx') do\n    it { should be_enabled }\n    it { should be_running }\n  end\nend\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#create-nginx-site-file","title":"Create Nginx Site File","text":"<p>Create <code>files/default/nginx/my_flask_app</code> file:</p> <pre><code>mkdir files/default/nginx\nchef generate file nginx/my_flask_app\n</code></pre> <p>Add this content to the <code>files/default/nginx/my_flask_app</code>:</p> <pre><code>server {\n  listen 80 default_server;\n  listen [::]:80 default_server ipv6only=on;\n\n  # Make site accessible from http://localhost/\n  server_name localhost;\n\n  location / {\n    include uwsgi_params;\n    uwsgi_pass unix:/var/www/my_flask_app/shared/.uwsgi/my_flask_app.sock;\n  }\n}\n</code></pre> <p>IMPORTANT: Make sure the file uses Unix Line Ending (\\n, LF) and UTF-8 encoding. Otherwise you may get weird errors when Chef client runs the script during deployment.</p>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#write-the-my_app_nginx-recipe","title":"Write the <code>my_app_nginx</code> recipe","text":"<p>The first step is to create the recipe file, <code>my_app_nginx.rb</code>. Run the following command to generate it:</p> <pre><code>chef generate recipe my_app_nginx\nrm spec/unit/recipes/my_app_nginx_spec.rb\n</code></pre> <p>Write out <code>recipes/my_app_nginx.rb</code> like this:</p> <pre><code>#\n# Cookbook Name:: my_flask_server\n# Recipe:: my_nginx\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\n# install nginx\npackage 'nginx' do\n  :upgrade\nend\n\n# start nginx service\nservice 'nginx' do\n  supports status: true, restart: true, reload: true\n  action [:enable, :start]\nend\n\n# Uncomment to use a custom nginx.conf\n# cookbook_file '/etc/nginx/nginx.conf' do\n#   source 'nginx/nginx.conf'\n#   mode 0640\n#   owner 'root'\n#   group 'root'\n#   notifies :restart, 'service[nginx]'\n# end\n\n# disable default site\nlink '/etc/nginx/sites-enabled/default' do\n  action :delete\n  only_if 'test -L /etc/nginx/sites-enabled/default'\n  notifies :restart, 'service[nginx]'\nend\n\n# add my_flask_app site\ncookbook_file '/etc/nginx/sites-available/my_flask_app' do\n  source 'nginx/my_flask_app'\n  mode 0640\n  owner 'root'\n  group 'root'\nend\n\n# enable my_flask_app site\nlink '/etc/nginx/sites-enabled/my_flask_app' do\n  to '/etc/nginx/sites-available/my_flask_app'\n  notifies :restart, 'service[nginx]'\nend\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#set-the-my_app_nginx-recipe-to-run","title":"Set the <code>my_app_nginx</code> recipe to run","text":"<p>Add this line to <code>recipes/default.rb</code>:</p> <pre><code>include_recipe 'my_flask_server::my_app_nginx'\n</code></pre> <p>Here is the complete file:</p> <pre><code>#\n# Cookbook Name:: my_flask_server\n# Recipe:: default\n#\n# Copyright (c) 2016 The Authors, All Rights Reserved.\n\ninclude_recipe 'apt::default'\n\ninclude_recipe 'my_flask_server::my_app_dir'\n\ninclude_recipe 'my_flask_server::my_app_python'\n\ninclude_recipe 'my_flask_server::my_app_ssh'\ninclude_recipe 'my_flask_server::my_app_deploy'\n\ninclude_recipe 'my_flask_server::my_app_uwsgi'\n\ninclude_recipe 'my_flask_server::my_app_nginx'\n</code></pre>"},{"location":"build-nginx-server-deploy-python-flask-app-using-chef/#run-all-tests_6","title":"Run all tests","text":"<pre><code>chef exec rake\n</code></pre> <p>Open a browser and navigate to <code>http://default-ubuntu-1404/</code>. You should see the \"Hello World!\" page of the my_flask application.</p>"},{"location":"installing-an-older-version-of-xcode-alongside-xcode-9/","title":"Installing an Older Version of Xcode Alongside Xcode 9","text":"<p>Today I started working on updating Apport code from Swift 2 to Swift 4. So I got everything ready, made a fresh cup of coffee and opened the project workspace in Xcode 9. And then I got this message:</p> <p></p> <p>I have to convert the project to Swift 3 first in Xcode 8 and then convert once again to Swift 4 in Xcode 9. </p> <p>So I need both Xcode 8 and Xcode 9 installed, and here is how that can be done:</p>"},{"location":"installing-an-older-version-of-xcode-alongside-xcode-9/#install","title":"Install","text":"<ol> <li> <p>Download Xcode 8.3.3 from Apple Developer Downloads. You will receive a file named Xcode8.3.3.xip which is a digitally signed zip file.</p> </li> <li> <p>Expand the xip file. It will be expanded to <code>Xcode.app</code></p> </li> <li> <p>Rename <code>Xcode.app</code> to <code>Xcode8.app</code> </p> </li> <li> <p>Drag <code>Xcode8.app</code> to your <code>Applications</code> folder</p> </li> </ol>"},{"location":"installing-an-older-version-of-xcode-alongside-xcode-9/#selecting-xcode-version","title":"Selecting Xcode version","text":""},{"location":"installing-an-older-version-of-xcode-alongside-xcode-9/#switch-to-xcode-8","title":"Switch to Xcode 8","text":"<pre><code>sudo xcode-select --switch /Applications/Xcode8.app\n</code></pre>"},{"location":"installing-an-older-version-of-xcode-alongside-xcode-9/#switch-to-xcode-9","title":"Switch to Xcode 9","text":"<pre><code>sudo xcode-select --switch /Applications/Xcode.app\n</code></pre>"},{"location":"installing-an-older-version-of-xcode-alongside-xcode-9/#print-version-that-is-selected","title":"Print version that is selected","text":"<pre><code>xcode-select --print-path\n</code></pre>"},{"location":"ways-blockchain-technology-transforming-world/","title":"3 Ways Blockchain Technology is Transforming the World of Advertising","text":"<p>If you work as an investment advisor or are part of the banking industry, you already know how blockchain technology is transforming your workplace and changing the rules of the game. </p> <p>{: .align-center}</p> <p>Investment advisors can barely go a day without at least one Bitcoin inquiry, and financial professionals are constantly looking for new ways to incorporate cryptocurrencies and blockchain technology into their day-to-day operations. </p> <p>For those in other industries, the recognition of blockchain technology and its inherent transformative power is often slower, but that does not mean it is not happening. Indeed, blockchain technology has the power to change virtually every industry, and those who fail to adapt to the shifting landscape could find themselves left behind. </p> <p>The advertising industry is a case in point and an illustrative example of how blockchain technology is already changing the world. Whether you work in the advertising industry or are just an interested observer, it pays to know what to expect, and how blockchain technology could transform the world of marketing in just a few short years. Here are three ways blockchain technology is already changing the world of advertising. </p> <p>Transformation #1 - Advertising Will Become More Transparent</p> <p>Throughout the years, the advertising industry has been called many things, but transparent has rarely been one of them. Indeed, many consumers have complained that advertising was often opaque and even deceptive, with unproven claims, dishonest operators and a host of other problems. </p> <p>In the future, blockchain technology could make advertising far more transparent than it is today. Many of these changes are already underway., with voluntary reporting on the origin of social media ads and other types of marketing outreach. In the future, blockchain technology will make advertising even more accessible and transparent, benefitting consumers and businesses alike. </p> <p>Transformation #2 - Video Content Advertising Will Be Changed Forever</p> <p>The widespread adoption of high-speed internet has changed the media landscape forever, and those alterations are still underway. Video content is quickly supplementing its text-only counterparts, as content production gets easier and less expensive and bandwidth capabilities expand. </p> <p>The power of the blockchain will change the creation and distribution of content just as much, allowing even the smallest businesses to produce and distribute high-quality video. From simple animations to studio-quality video, the world of advertising will be transformed, thanks to the power of the blockchain. </p> <p>Transformation #3 - Direct Access to the Consumer</p> <p>From the earliest days of the advertising industry, there has always been a middleman standing between consumers with money to spend and advertisers with something sell. Initially, those middlemen were newspaper publishers and magazine owners, then the owners of television studios and finally the operators of search engines and online directories. </p> <p>Thanks to the transformational power of the blockchain, those middlemen may soon become a thing of the past. Blockchain technology is already allowing more direct contact between consumers and advertisers, increasingly making the middlemen obsolete. This change promises to revolutionize the world of advertising, changing the publishing business in countless ways and disrupting the industry like never before. </p> <p>Blockchain technology is changing the world in many different ways, from the way we bank and invest to the way we work and create business relationships. For those in the advertising industry, the transformational power of blockchain technology could be even greater, and the time to get ready for the changes is now. </p>"},{"location":"how-to-streamline-working-relationships-with-multiple-parties/","title":"How to Streamline Working Relationships with Multiple Parties","text":"<p>If you want to facilitate a smooth and efficient working relationship, all relevant parties must first agree on a few critical aspects of the project. The ability to communicate ideas is integral to the creation of any stable working relationship. Before starting a joint project, discuss these five elements with each party.</p> <p>{: .align-center}</p> <p>1. Wants </p> <p>What does each team member want to get out of the shared project? You may assume that your goals naturally match everyone else's, but that might not be the case. Ask every party to outline their wants and desires openly. Agreeing with an entity whose goals differ significantly from your own may lead to organizational difficulties.</p> <p>Ideally, to preserve consistency and efficiency throughout the project, your goals should be in sync. Identify and explain to the other parties your company values and the ethics upon which you would want your enterprise judged. Open and unambiguous dialogue is the best way to remove the opportunity for misunderstanding.</p> <p>2. Policies </p> <p>Policies are self-imposed rules to which an organization adheres. It's essential for all parties to declare any plan they have regarding the project on which they will be working. Whether the other parties agree to follow the same policy is a matter of compromise. Each entity involved in the shared project may have plans of their own, so you should decide as a group which ones would benefit the project if adopted by every party.</p> <p>Likewise, it may be necessary to temporarily alter some of your policies to facilitate a more efficient working relationship. Be willing to compromise to a degree but don't infringe upon your own moral or ethical view if it makes you uncomfortable to do so.</p> <p>3. Milestones </p> <p>Before starting work, identify and outline any critical milestones of the project, to ensure completion according to schedule and at a satisfactory standard. It's essential to agree to a timeline of events before beginning the project to avoid any misunderstandings or miscommunications further down the line.</p> <p>Discuss which performance indicators you will use and agree upon a time and method for analyzing your collective performance. Once you reach an agreed milestone, make sure you establish a plan of communication that facilitates a smooth and professional discourse if needed. By acknowledging set milestones, the project will benefit from an added cohesiveness and increased efficiency.</p> <p>4. Information </p> <p>The success of any working relationship is wholly dependent on the smooth and straightforward sharing of information between all relevant parties. In the digital age, there are many options available to business for sharing data, but you still need to agree on which method to use. Discuss the benefits of each communication option before starting work, and decide on a regular schedule to keep every party updated.</p> <p>Every member of the project should be able to access any information that is relevant to their work. If new data becomes available, it needs to get shared quickly. Once you've agreed on a method and schedule for doing so, make sure every individual is aware of the decision.</p> <p>5. Trust </p> <p>Ultimately, every successful relationship is built on a bedrock of trust. It can take time and experience to develop real confidence in another party, but you may initially have to make a small leap of faith based upon research and second-hand information. Once the project begins, you must trust the other party to be competent and professional when doing their job. If you don't, the relationship could be irrevocably impaired before it even gets going.</p> <p>Working with other businesses can lead to great things. The ability of two or more parties to come together is helped immeasurably by agreeing upon a clear and defined plan of action. Take the time to adequately communicate your ideas, intentions, and worries with the other parties. A more cohesive and profitable working relationship will be your reward.</p>"},{"location":"signing-in-or-out-of-chrome-signs-you-in-or-out-of-google-web-services/","title":"Signing in or out of Chrome signs you in or out of Google web services","text":"<p>Chrome 69 was released to users on September 5th, 2018. Besides the different look and feel one other annoying change is that Chrome now logs you automatically into Google services like Gmail with the same account that you use for browser syncing. Previously, users were allowed to keep those logins separate. To disable the forced login, navigate to chrome://flags/#account-consistency. Then set the option labeled, <code>Identity consistency between browser and cookie jar</code> to <code>Disabled</code> and restart your browser. </p>"},{"location":"setup-macos-for-aws-cloud-devops/","title":"Setup macOS for AWS Cloud DevOps","text":"<p>Step-by-step AWS DevOps environment setup for macOS.</p> <p>Scripts are <code>bash</code></p>"},{"location":"setup-macos-for-aws-cloud-devops/#misc","title":"Misc","text":""},{"location":"setup-macos-for-aws-cloud-devops/#finder","title":"Finder","text":"<p>Show hidden files:</p> <pre><code>defaults write com.apple.finder AppleShowAllFiles YES\n</code></pre> <p>Hold the 'Option/alt' key, then right click on the Finder icon in the dock and click Relaunch</p>"},{"location":"setup-macos-for-aws-cloud-devops/#tools","title":"Tools","text":""},{"location":"setup-macos-for-aws-cloud-devops/#aws-cli","title":"AWS CLI","text":"<p>Install:</p> <pre><code>cd ~/Downloads\ncurl \"https://awscli.amazonaws.com/AWSCLIV2.pkg\" -o \"AWSCLIV2.pkg\"\nsudo installer -pkg AWSCLIV2.pkg -target /\n</code></pre> <p>Test:</p> <pre><code>which aws\naws --version\n# /usr/local/bin/aws\n# aws-cli/2.8.2 Python/3.9.11 Darwin/21.6.0 exe/x86_64 prompt/off\n</code></pre> <p>Enable  <code>bash</code> auto-completion:</p> <pre><code>complete -C aws_completer aws\n</code></pre>"},{"location":"setup-macos-for-aws-cloud-devops/#homebrew","title":"Homebrew","text":"<p>Install Homebrew:</p> <pre><code>/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\n</code></pre>"},{"location":"setup-macos-for-aws-cloud-devops/#bash-5","title":"bash 5+","text":"<p>macOS comes with outdated version of bash. Install latest version.</p> <pre><code>brew update\nbrew install bash\n</code></pre>"},{"location":"setup-macos-for-aws-cloud-devops/#gnupg","title":"gnupg","text":"<pre><code>brew install gnupg\n</code></pre>"},{"location":"setup-macos-for-aws-cloud-devops/#jq","title":"jq","text":"<p>See jq for details. Install via Homebrew:</p> <pre><code>brew install jq\n</code></pre>"},{"location":"setup-macos-for-aws-cloud-devops/#mo","title":"mo","text":"<p>Mustache Templates in Bash. </p> <p>See: https://github.com/tests-always-included/mo</p> <pre><code># Download\ncurl -sSL https://git.io/get-mo -o mo\n\n# Make executable\nchmod +x mo\n\n# Move to the right folder\nsudo mv mo /usr/local/bin/\n\n# Test\necho \"works\" | mo\n</code></pre>"},{"location":"setup-macos-for-aws-cloud-devops/#reg","title":"reg","text":"<p><code>reg</code> is Docker registry v2 command line client and repo listing generator. </p> <p>Switch to root:</p> <pre><code>sudo su -\n</code></pre> <p>Install:</p> <pre><code># Export the sha256sum for verification.\nexport REG_SHA256=\"2768ac56ad640e8ee5b74752fc9bbeaf37f37a34c7e1ddcb6d0e384a3096b1c2\"\n\n# Download and check the sha256sum.\nsudo curl -fSL \"https://github.com/genuinetools/reg/releases/download/v0.16.1/reg-darwin-amd64\" -o \"/usr/local/bin/reg\" \\\n  &amp;&amp; echo \"${REG_SHA256}  /usr/local/bin/reg\" | sha256sum -c - \\\n  &amp;&amp; sudo chmod a+x \"/usr/local/bin/reg\"\n</code></pre> <p>Test:</p> <pre><code>reg --help\n</code></pre>"},{"location":"setup-macos-for-aws-cloud-devops/#docker-desktop","title":"Docker Desktop","text":"<p>Install via Homebrew:</p> <pre><code>brew install --cask docker\n</code></pre>"},{"location":"setup-macos-for-aws-cloud-devops/#adjust-memory","title":"Adjust Memory","text":"<p>On macOS Docker Desktop the standard memory settings are too low (3 GB)</p> <p>Start Docker Desktop</p> <p>Open: Preferences &gt; Resources &gt; Advanced </p> <p>Set Memory to 4GB or more</p> <p>Hit Apply &amp; Restart</p>"},{"location":"aws-authentication/","title":"AWS Authentication","text":"<p>Set up your AWS credentials. For more information, see Configuration and credential file settings. </p> <p>Make sure you go through this setup first:</p> <ol> <li>Setup macOS for AWS Cloud DevOps</li> </ol> <p>Scripts are <code>bash</code></p>"},{"location":"aws-authentication/#aws-cli","title":"AWS CLI","text":"<p>Run <code>aws configure</code> to configure access key ID and secret access key, default region. Request access key ID and secret access key from you AWS admin. </p> <p><pre><code># To configure the default profile:\naws configure\n\n# To configure a specific named profile, e.g. `swift`:\naws configure --profile swift\n</code></pre> - Specify Access key ID  - Specify  Secret access key  - Set <code>us-west-2</code> for region - Set <code>json</code> for output format   </p> <p>IMPORTANT: Disable CLI pager. Otherwise you will not be able to parse AWS CLI json responses:</p> <pre><code>aws configure set cli_pager \"\"\n</code></pre> <p>The files generated by the CLI for a default profile configured with <code>aws configure</code> looks similar to the following.</p> <pre><code>cat ~/.aws/credentials\n</code></pre> <pre><code>[default]\naws_access_key_id=QWERTYUIOPASDFGHJKLZ\naws_secret_access_key=abcdEfgHijklm/NOPQARS/BxcfghGHEXAMPLEKEY\n</code></pre> <pre><code>cat ~/.aws/config\n</code></pre> <pre><code>[default]\nregion=us-west-2\noutput=json\n</code></pre> <p>Test:</p> <pre><code>aws ec2 describe-instances\n</code></pre>"},{"location":"aws-authentication/#ec2-key-pair","title":"EC2 Key Pair","text":"<p>Generate EC2 SSH key pair:</p> <pre><code>ssh-keygen -t rsa -C \"aws-ec2-key\" -f ~/.ssh/aws-ec2-key\n</code></pre> <p>Import the key in AWS EC2:</p> <pre><code>aws ec2 import-key-pair --key-name \"aws-ec2-key\" --public-key-material fileb://~/.ssh/aws-ec2-key.pub\n</code></pre>"},{"location":"create-aws-ec2-instance-aws-cli/","title":"Create an AWS EC2 instance with the AWS CLI","text":"<p>Make sure you do this setup first:</p> <ol> <li>Setup macOS for AWS Cloud DevOps</li> <li>AWS Authentication</li> </ol> <p>Steps:</p> <ol> <li>Launch an AWS EC2 instance (this post)</li> </ol> <p>Scripts are <code>bash</code></p>"},{"location":"create-aws-ec2-instance-aws-cli/#setup","title":"Setup","text":""},{"location":"create-aws-ec2-instance-aws-cli/#names","title":"Names","text":"<p>Assign resource names:</p> <pre><code># VPC\nvpc=\"vpc-ec2\"\n\n# Subnets\nsubnet_1=\"subnet-ec2-1\"\nsubnet_2=\"subnet-ec2-2\"\n\n# Internet Gateway\ninternet_gateway=\"igw-ec2\"\n\n# Route Table\nroute_table=\"rtb-ec2\"\n\n# Security Group\nsecurity_group=\"security-ec2\"\n\n# instance\ninstance=\"instance-ec2\"\n\n# SSH access key\nkey=\"aws-ec2-key\"\n</code></pre>"},{"location":"create-aws-ec2-instance-aws-cli/#vpc","title":"VPC","text":"<p>Create a VPC  (Virtual Private Cloud):</p> <pre><code>aws ec2 create-vpc \\\n  --cidr-block 10.0.0.0/16  \\\n  --tag-specifications 'ResourceType=vpc,Tags=[{Key=Name,Value='$vpc'}]'\n</code></pre>"},{"location":"create-aws-ec2-instance-aws-cli/#subnets","title":"Subnets","text":"<p>Create 2 subnets:</p> <pre><code>vpc_id=$(aws ec2 describe-vpcs --filters Name=tag:Name,Values=$vpc | jq -r '.Vpcs[0].VpcId')\n\n# 1st subnet\naws ec2 create-subnet \\\n  --vpc-id $vpc_id \\\n  --cidr-block 10.0.0.0/24 \\\n  --availability-zone us-west-2a \\\n  --tag-specifications 'ResourceType=subnet,Tags=[{Key=Name,Value='$subnet_1'}]'  \n\n# 2nd subnet\naws ec2 create-subnet \\\n  --vpc-id $vpc_id \\\n  --cidr-block 10.0.1.0/24 \\\n  --availability-zone us-west-2a \\\n  --tag-specifications 'ResourceType=subnet,Tags=[{Key=Name,Value='$subnet_2'}]'  \n</code></pre> <p>Optionally modify the public IP addressing behavior of your subnet so that an instance launched into the subnet automatically receives a public IP address. Otherwise, you should associate an Elastic IP address with your instance after launch so that it's reachable from the Internet.</p> <pre><code>subnet_id=$(aws ec2 describe-subnets --filters Name=tag:Name,Values=$subnet_1 | jq -r '.Subnets[0].SubnetId')\naws ec2 modify-subnet-attribute --subnet-id $subnet_id --map-public-ip-on-launch\n</code></pre>"},{"location":"create-aws-ec2-instance-aws-cli/#internet-gateway","title":"Internet Gateway","text":"<p>After you've created the VPC and subnets, you can make one of the subnets a public subnet by attaching an Internet gateway to your VPC, creating a custom route table, and configuring routing for the subnet to the Internet gateway.</p>"},{"location":"create-aws-ec2-instance-aws-cli/#create","title":"Create","text":"<pre><code>aws ec2 create-internet-gateway \\\n  --tag-specifications 'ResourceType=internet-gateway,Tags=[{Key=Name,Value='$internet_gateway'}]' \n</code></pre>"},{"location":"create-aws-ec2-instance-aws-cli/#attach-to-vpc","title":"Attach to VPC","text":"<pre><code>vpc_id=$(aws ec2 describe-vpcs --filters Name=tag:Name,Values=$vpc | jq -r '.Vpcs[0].VpcId')\n\ninternet_gateway_id=$(aws ec2 describe-internet-gateways --filters Name=tag:Name,Values=$internet_gateway | jq -r '.InternetGateways[0].InternetGatewayId')\n\naws ec2 attach-internet-gateway --vpc-id $vpc_id --internet-gateway-id $internet_gateway_id\n</code></pre>"},{"location":"create-aws-ec2-instance-aws-cli/#route-table","title":"Route Table","text":"<p>Create:</p> <pre><code>vpc_id=$(aws ec2 describe-vpcs --filters Name=tag:Name,Values=$vpc | jq -r '.Vpcs[0].VpcId')\n\naws ec2 create-route-table \\\n  --vpc-id $vpc_id \\\n  --tag-specifications 'ResourceType=route-table,Tags=[{Key=Name,Value='$route_table'}]' \n</code></pre> <p>Associate with a subnet:</p> <pre><code># 1st subnet\nsubnet_id=$(aws ec2 describe-subnets --filters Name=tag:Name,Values=$subnet_1 | jq -r '.Subnets[0].SubnetId')\n\nroute_table_id=$(aws ec2 describe-route-tables --filters Name=tag:Name,Values=$route_table | jq -r '.RouteTables[0].RouteTableId')\n\naws ec2 associate-route-table  --subnet-id $subnet_id --route-table-id $route_table_id\n</code></pre> <p>Create a route in the route table that points all traffic (<code>0.0.0.0/0</code>) to the Internet gateway:</p> <pre><code>route_table_id=$(aws ec2 describe-route-tables --filters Name=tag:Name,Values=$route_table | jq -r '.RouteTables[0].RouteTableId')\ninternet_gateway_id=$(aws ec2 describe-internet-gateways --filters Name=tag:Name,Values=$internet_gateway | jq -r '.InternetGateways[0].InternetGatewayId')\n\naws ec2 create-route \\\n  --route-table-id $route_table_id \\\n  --gateway-id $internet_gateway_id \\\n  --destination-cidr-block 0.0.0.0/0\n</code></pre> <p>Confirm route is active:</p> <pre><code>route_table_id=$(aws ec2 describe-route-tables --filters Name=tag:Name,Values=$route_table | jq -r '.RouteTables[0].RouteTableId')\naws ec2 describe-route-tables --route-table-id $route_table_id\n</code></pre>"},{"location":"create-aws-ec2-instance-aws-cli/#security-group","title":"Security Group","text":"<p>Create a security group in your VPC:</p> <pre><code>vpc_id=$(aws ec2 describe-vpcs --filters Name=tag:Name,Values=$vpc | jq -r '.Vpcs[0].VpcId')\n\naws ec2 create-security-group \\\n    --group-name $security_group \\\n  --description \"Security group for instance access\" \\\n  --vpc-id $vpc_id \\\n  --tag-specifications 'ResourceType=security-group,Tags=[{Key=Name,Value='$security_group'}]' \n</code></pre> <p>Add a rule that allows SSH access from anywhere:</p> <pre><code>group_id=$(aws ec2 describe-security-groups --filters Name=tag:Name,Values=$security_group | jq -r '.SecurityGroups[0].GroupId')\naws ec2 authorize-security-group-ingress \\\n  --group-id $group_id \\\n  --protocol tcp --port 22 --cidr 0.0.0.0/0\n</code></pre>"},{"location":"create-aws-ec2-instance-aws-cli/#ec2-instance","title":"EC2 Instance","text":"<p>List Amazon Linux images (via System Manager):</p> <pre><code>aws ssm get-parameters-by-path --path /aws/service/ami-amazon-linux-latest --query \"Parameters[].Name\"\n</code></pre> <p>Launch instance:</p> <pre><code>subnet_id=$(aws ec2 describe-subnets --filters Name=tag:Name,Values=$subnet_1 | jq -r '.Subnets[0].SubnetId')\ngroup_id=$(aws ec2 describe-security-groups --filters Name=tag:Name,Values=$security_group | jq -r '.SecurityGroups[0].GroupId')\n\naws ec2 run-instances \\\n  --subnet-id $subnet_id \\\n  --security-group-ids $group_id \\\n  --image-id resolve:ssm:/aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2 \\\n  --instance-type t2.micro \\\n  --count 1 \\\n  --key-name $key \\\n   --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value='$instance'}]'\n</code></pre> <p>Check instance status. Wait until it is <code>running</code>:</p> <pre><code>instance_id=$(aws ec2 describe-instances --filters Name=tag:Name,Values=$instance | jq -r '.Reservations[0].Instances[0].InstanceId')\naws ec2 describe-instances --instance-id $instance_id | jq -r '.Reservations[0].Instances[0].State'\n</code></pre> <p>Login into the instance:</p> <pre><code>instance_public_ip=$(aws ec2 describe-instances --filters Name=tag:Name,Values=$instance | jq -r '.Reservations[0].Instances[0].PublicIpAddress')\nssh -i ~/.ssh/$key ec2-user@$instance_public_ip\n</code></pre>"},{"location":"create-aws-ec2-instance-aws-cli/#clean-up","title":"Clean up","text":"<p>Delete all resources in reverse order of creation.</p>"},{"location":"create-aws-ec2-instance-aws-cli/#ec2-instance_1","title":"EC2 Instance","text":"<pre><code>instance_id=$(aws ec2 describe-instances --filters Name=tag:Name,Values=$instance | jq -r '.Reservations[0].Instances[0].InstanceId')\naws ec2 terminate-instances --instance-ids $instance_id\n</code></pre> <p>Check instance status. Wait until it is <code>terminated</code>:</p> <pre><code>aws ec2 describe-instances --instance-id $instance_id | jq -r '.Reservations[0].Instances[0].State'\n</code></pre>"},{"location":"create-aws-ec2-instance-aws-cli/#security-group_1","title":"Security Group","text":"<pre><code>group_id=$(aws ec2 describe-security-groups --filters Name=tag:Name,Values=$security_group | jq -r '.SecurityGroups[0].GroupId')\naws ec2 delete-security-group --group-id $group_id\n</code></pre>"},{"location":"create-aws-ec2-instance-aws-cli/#subnets_1","title":"Subnets","text":"<p>Delete:</p> <pre><code># 1st subnet\nsubnet_id=$(aws ec2 describe-subnets --filters Name=tag:Name,Values=$subnet_1 | jq -r '.Subnets[0].SubnetId')\naws ec2 delete-subnet --subnet-id $subnet_id\n\n# 2nd subnet\nsubnet_id=$(aws ec2 describe-subnets --filters Name=tag:Name,Values=$subnet_2 | jq -r '.Subnets[0].SubnetId')\naws ec2 delete-subnet --subnet-id $subnet_id\n</code></pre>"},{"location":"create-aws-ec2-instance-aws-cli/#route-table_1","title":"Route Table","text":"<p>Delete:</p> <pre><code>route_table_id=$(aws ec2 describe-route-tables --filters Name=tag:Name,Values=$route_table | jq -r '.RouteTables[0].RouteTableId')\naws ec2 delete-route-table --route-table-id $route_table_id\n</code></pre>"},{"location":"create-aws-ec2-instance-aws-cli/#internet-gateway_1","title":"Internet Gateway","text":"<p>Detach:</p> <pre><code>vpc_id=$(aws ec2 describe-vpcs --filters Name=tag:Name,Values=$vpc | jq -r '.Vpcs[0].VpcId')\n\ninternet_gateway_id=$(aws ec2 describe-internet-gateways --filters Name=tag:Name,Values=$internet_gateway | jq -r '.InternetGateways[0].InternetGatewayId')\n\naws ec2 detach-internet-gateway --internet-gateway-id $internet_gateway_id --vpc-id $vpc_id\n</code></pre> <p>Delete:</p> <pre><code>internet_gateway_id=$(aws ec2 describe-internet-gateways --filters Name=tag:Name,Values=$internet_gateway | jq -r '.InternetGateways[0].InternetGatewayId')\naws ec2 delete-internet-gateway --internet-gateway-id $internet_gateway_id\n</code></pre>"},{"location":"create-aws-ec2-instance-aws-cli/#vpc_1","title":"VPC","text":"<pre><code>vpc_id=$(aws ec2 describe-vpcs --filters Name=tag:Name,Values=$vpc | jq -r '.Vpcs[0].VpcId')\naws ec2 delete-vpc --vpc-id $vpc_id\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-1-network-setup/","title":"Launch ECS container using AWS CLI - Step 1 - Network Setup","text":"<p>Setup network infrastructure including new VPC (Virtual Private Cloud), public and private subnets, internet gateway, security group, and ssh access.</p> <p>This is part of a multi-post thread involving these steps:</p> <ol> <li>Network Setup (this post)</li> <li>Launch EC2 Instance</li> <li>Create Docker Image</li> <li>Create Service</li> <li>Cleanup</li> </ol> <p>Make sure you do this setup first:</p> <ol> <li>Setup macOS for AWS Cloud DevOps</li> <li>AWS Authentication</li> </ol>"},{"location":"launch-ecs-container-aws-cli-step-1-network-setup/#define-names","title":"Define names","text":"<pre><code># VPC\nvpc=\"vpc-ecs\"\n\n# Subnets\nsubnet_1=\"subnet-ecs-1\"\nsubnet_2=\"subnet-ecs-2\"\n\n# Internet Gateway\ninternet_gateway=\"igw-ecs\"\n\n# Route Table\nroute_table=\"rtb-ecs\"\n\n# Security Group\nsecurity_group=\"security-ecs\"\n\n# instance\ninstance=\"instance-ecs\"\n\n# SSH access key\nkey=\"aws-ecs-key\"\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-1-network-setup/#create-vpc","title":"Create VPC","text":"<pre><code># VPC\n\necho \"Create a VPC  (Virtual Private Cloud) ...\"\n\naws ec2 create-vpc \\\n    --cidr-block 10.0.0.0/16  \\\n    --tag-specifications 'ResourceType=vpc,Tags=[{Key=Name,Value='$vpc'}]'\n\nvpc_id=$(aws ec2 describe-vpcs --filters Name=tag:Name,Values=$vpc | jq -r '.Vpcs[0].VpcId')\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-1-network-setup/#create-subnets","title":"Create Subnets","text":"<p>Create 2 subnets in the VPC. First subnet will be our public interface. The second subnet will be private.</p> <pre><code># Subnets\necho \"Create subnet 1 ...\"\n\naws ec2 create-subnet \\\n    --vpc-id $vpc_id \\\n    --cidr-block 10.0.0.0/24 \\\n    --availability-zone us-west-2a \\\n    --tag-specifications 'ResourceType=subnet,Tags=[{Key=Name,Value='$subnet_1'}]'  \n\nsubnet_1_id=$(aws ec2 describe-subnets --filters Name=tag:Name,Values=$subnet_1 | jq -r '.Subnets[0].SubnetId')\n\necho \"Create subnet 2 ...\"\n\naws ec2 create-subnet \\\n    --vpc-id $vpc_id \\\n    --cidr-block 10.0.1.0/24 \\\n    --availability-zone us-west-2a \\\n    --tag-specifications 'ResourceType=subnet,Tags=[{Key=Name,Value='$subnet_2'}]'  \n\nsubnet_2_id=$(aws ec2 describe-subnets --filters Name=tag:Name,Values=$subnet_2 | jq -r '.Subnets[0].SubnetId')\n\n## Automatically assign Elastic IP address after launch to all instances in subnet 1 \naws ec2 modify-subnet-attribute --subnet-id $subnet_1_id --map-public-ip-on-launch\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-1-network-setup/#create-internet-gateway","title":"Create Internet Gateway","text":"<p>Create an Internet gateway and attach it to the VPC. An internet gateway allows communication between your VPC and the Internet:</p> <pre><code># Internet Gateway\n\necho \"Create Internet Gateway ...\"\n\naws ec2 create-internet-gateway \\\n    --tag-specifications 'ResourceType=internet-gateway,Tags=[{Key=Name,Value='$internet_gateway'}]' \n\ninternet_gateway_id=$(aws ec2 describe-internet-gateways --filters Name=tag:Name,Values=$internet_gateway | jq -r '.InternetGateways[0].InternetGatewayId')\n\n## Attach to VPC\naws ec2 attach-internet-gateway --vpc-id $vpc_id --internet-gateway-id $internet_gateway_id\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-1-network-setup/#create-route-table","title":"Create Route Table","text":"<p>Create a route table, associate it with the public subnet, and add a route to allow all traffic to the Internet gateway. </p> <pre><code># Route Table\n\necho \"Create Route Table ...\"\n\naws ec2 create-route-table \\\n    --vpc-id $vpc_id \\\n    --tag-specifications 'ResourceType=route-table,Tags=[{Key=Name,Value='$route_table'}]' \n\nroute_table_id=$(aws ec2 describe-route-tables --filters Name=tag:Name,Values=$route_table | jq -r '.RouteTables[0].RouteTableId')\n\n## Associate with a subnet\naws ec2 associate-route-table  --subnet-id $subnet_1_id --route-table-id $route_table_id\n\n## Create a route in the route table that points all traffic (`0.0.0.0/0`) to the Internet gateway:\naws ec2 create-route \\\n    --route-table-id $route_table_id \\\n    --gateway-id $internet_gateway_id \\\n    --destination-cidr-block 0.0.0.0/0\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-1-network-setup/#create-security-group","title":"Create Security Group","text":"<p>A security group controls the traffic that is allowed to reach and leave the resources that it is associated with. For example, after you associate a security group with a VPC, it controls the inbound and outbound traffic for the instances in the VPC.</p> <pre><code># Security Group\n\necho \"Create a Security Group ...\"\n\naws ec2 create-security-group \\\n    --group-name $security_group \\\n    --description \"Security group for instance access\" \\\n    --vpc-id $vpc_id \\\n    --tag-specifications 'ResourceType=security-group,Tags=[{Key=Name,Value='$security_group'}]' \n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-1-network-setup/#allow-ssh-connections","title":"Allow SSH Connections","text":"<p>This is done by adding an ingress rule to the Security Group:</p> <pre><code>group_id=$(aws ec2 describe-security-groups --filters Name=tag:Name,Values=$security_group | jq -r '.SecurityGroups[0].GroupId')\n\n# Add a rule that allows SSH access from anywhere:\naws ec2 authorize-security-group-ingress \\\n    --group-id $group_id \\\n    --protocol tcp --port 22 --cidr 0.0.0.0/0\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-2-launch-ec2-instance/","title":"Launch ECS container using AWS CLI - Step 2 - Launch EC2 Instance","text":"<p>Create an \"EC2 Contaner Service\" (ECS) cluster with one EC2 instance. This will be used to host ECS tasks / container instances. </p> <p>This is part of a multi-post thread involving these steps:</p> <ol> <li>Network Setup </li> <li>Launch EC2 Instance (this post)</li> <li>Create Docker Image</li> <li>Create Service</li> <li>Cleanup</li> </ol>"},{"location":"launch-ecs-container-aws-cli-step-2-launch-ec2-instance/#define-names","title":"Define names","text":"<pre><code># Subnets\nsubnet_1=\"subnet-ecs-1\"\nsubnet_2=\"subnet-ecs-2\"\n\n# Security Group\nsecurity_group=\"security-ecs\"\n\n# cluster\ncluster=\"cluster-ecs\"\n\n# IAM\ninstance_role=\"instance-role-ecs\"\ninstance_profile=\"instance-profile-ecs\"\n\n# EC2\ninstance=\"instance-ecs\"\n\n# SSH access key\nkey=\"aws-ec2-key\"\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-2-launch-ec2-instance/#ecs-cluster","title":"ECS Cluster","text":"<p>Create ECS Cluster:</p> <pre><code># Get IDs\ngroup_id=$(aws ec2 describe-security-groups --filters Name=tag:Name,Values=$security_group | jq -r '.SecurityGroups[0].GroupId')\nsubnet_1_id=$(aws ec2 describe-subnets --filters Name=tag:Name,Values=$subnet_1 | jq -r '.Subnets[0].SubnetId')\n\necho \"Create ECS cluster $cluster ...\"\naws ecs create-cluster --cluster-name $cluster\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-2-launch-ec2-instance/#ec2-instance-role","title":"EC2 Instance Role","text":"<p>Create an \"assume role\" policy configuration and save it to a file <code>instance-policy.json</code>:</p> <pre><code>cat &lt;&lt; EOT &gt; ./instance-policy.json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      },\n      \"Action\": \"sts:AssumeRole\"\n    }\n  ]\n}\nEOT\n</code></pre> <p>Create the EC2 Instance Role:</p> <pre><code># EC2 Instance Role\necho \"Create EC2 Instance Role ...\"\naws iam create-role \\\n    --role-name $instance_role \\\n    --assume-role-policy-document file://instance-policy.json\n</code></pre> <p>... and attach the <code>AmazonEC2ContainerServiceforEC2Role</code> policy to the instance role:</p> <pre><code>aws iam attach-role-policy \\\n    --role-name $instance_role \\\n    --policy-arn arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\n</code></pre> <p>When you attach a managed policy to a role, the managed policy becomes part of the role's permission (access) policy. </p>"},{"location":"launch-ecs-container-aws-cli-step-2-launch-ec2-instance/#ec2-instance-profile","title":"EC2 Instance Profile","text":"<p>Create EC2 Instance Profile:</p> <pre><code># EC2 Instance Profile\necho \"Create EC2 Instance Profile ...\"\naws iam create-instance-profile --instance-profile-name $instance_profile\n\naws iam add-role-to-instance-profile \\\n    --instance-profile-name $instance_profile \\\n    --role-name $instance_role\n\naws iam list-instance-profiles\n\necho \"Wait 15 seconds for new instance profile to replicate in AWS ...\"\nsleep 15\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-2-launch-ec2-instance/#ec2-instance","title":"EC2 Instance","text":"<p>Create a \"block device mappings\" configuration and save it to a file <code>instance-block-device-mappings.json</code>:</p> <pre><code>cat &lt;&lt; EOT &gt; ./instance-block-device-mappings.json\n[\n    {\n        \"DeviceName\": \"/dev/sdf\",\n        \"Ebs\": {\n            \"DeleteOnTermination\": true,\n            \"VolumeSize\": 50\n        }\n    }\n]\nEOT\n</code></pre> <p>Create an \"instance startup\" script and save it to a file <code>instance-user-data.sh</code>.  You can do anything in the startup script. In our case we use it to generate <code>/etc/ecs/ecs.config</code>. </p> <p>NOTE: This script runs on the EC2 instance after it launches.</p> <pre><code>cat &lt;&lt; \"EOT\" &gt; ./instance-user-data.sh\n#!/bin/bash\ncluster=\"cluster-ecs\"\n\necho \"ECS_CLUSTER=$cluster\" &gt;&gt; /etc/ecs/ecs.config\necho \"ECS_CONTAINER_INSTANCE_TAGS={\\\"ECS_CLUSTER\\\": \\\"$cluster\\\"}\" &gt;&gt; /etc/ecs/ecs.config\necho ECS_AVAILABLE_LOGGING_DRIVERS='[\"json-file\", \"awslogs\"]' &gt;&gt; /etc/ecs/ecs.config\nEOT\n</code></pre> <p>Now we have everything that's needed. Launch the EC2 instance in subnet 1:</p> <pre><code># EC2 Instance\necho \"Launch EC2 instance in subnet 1: $subnet_1_id ...\"\n\njson=$(aws ec2 run-instances \\\n    --subnet-id $subnet_1_id \\\n    --security-group-ids $group_id \\\n    --image-id resolve:ssm:/aws/service/ecs/optimized-ami/amazon-linux-2/recommended/image_id \\\n    --instance-type t2.micro \\\n    --count 1 \\\n    --key-name $key \\\n    --iam-instance-profile Name=$instance_profile \\\n    --user-data file://instance-user-data.sh \\\n    --block-device-mappings file://instance-block-device-mappings.json \\\n    --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value='$instance'}]')\n\ninstance_id=$(echo $json | jq -r '.Instances[0].InstanceId')\n\naws ec2 wait instance-exists --instance-ids $instance_id    \necho \"  Instance created ...\"\n\naws ec2 wait instance-running --instance-ids $instance_id    \necho \"  Instance is running ...\"\n\naws ec2 wait instance-status-ok --instance-ids $instance_id    \necho \"  Instance is ready ...\"\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-2-launch-ec2-instance/#verify","title":"Verify","text":"<p>Check that EC2 container instance has checked in to the ECS Cluster:</p> <pre><code>cluster=\"cluster-ecs\"\naws ecs list-container-instances --cluster $cluster\n</code></pre> <p>Also should be reported in <code>registeredContainerInstancesCount</code> when describing the ECS cluster:</p> <pre><code>cluster=\"cluster-ecs\"\naws ecs describe-clusters --cluster $cluster\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-3-create-docker-image/","title":"Launch ECS container using AWS CLI - Step 3 - Create Docker Image","text":"<p>Setup an ECS container repository, create a Docker image, and upload the Docker image to the repository. </p> <p>This is part of a multi-post thread involving these steps:</p> <ol> <li>Network Setup </li> <li>Launch EC2 Instance</li> <li>Create Docker Image (this post)</li> <li>Create Service</li> <li>Cleanup</li> </ol>"},{"location":"launch-ecs-container-aws-cli-step-3-create-docker-image/#define-names","title":"Define names","text":"<pre><code># registry (in the form $registryId.dkr.ecr.$region.amazonaws.com)\nregion=$(aws configure get region)\nregistryId=$(aws ecr describe-registry | jq -r '.registryId')\nregistry=\"$registryId.dkr.ecr.$region.amazonaws.com\"\n\n# image\nimage=\"ecs-test\"\ntag=\"latest\"\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-3-create-docker-image/#create-ecs-repository","title":"Create ECS Repository","text":"<pre><code>echo \"Create repository $image in registry $registry ...\"\naws ecr create-repository --repository-name $image\nrepository=$(aws ecr describe-repositories | jq -r \".repositories[] | select(.repositoryName==\\\"$image\\\") | .repositoryUri\")\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-3-create-docker-image/#create-docker-image","title":"Create Docker Image","text":""},{"location":"launch-ecs-container-aws-cli-step-3-create-docker-image/#dockerfile","title":"Dockerfile","text":"<p>Create a <code>Dockerfile</code> with the following contents:</p> <pre><code>cat &lt;&lt; \"EOT\" &gt; ./Dockerfile\n# See https://hub.docker.com/_/oraclelinux for all supported \n# Oracle Linux categories from Docker Hub.\n\n# this image will be the actual running container\nFROM  oraclelinux:8\n\nLABEL Name=ecs-test\n\n## System Config\nENV TZ=America/Los_Angeles\n\n# Packages\nRUN yum -y install bind-utils \n\nCMD [\"/bin/ping\", \"localhost\"]\nEOT\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-3-create-docker-image/#build-image","title":"Build Image","text":"<pre><code>echo \"Build image ...\"\ndocker build --tag ${image}:${tag} .\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-3-create-docker-image/#tag-image","title":"Tag Image","text":"<pre><code>echo \"Tag image ...\"\ndocker tag ${image}:${tag} ${repository}:${tag}\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-3-create-docker-image/#publish-image","title":"Publish Image","text":"<pre><code># refresh AWS token for docker\naws ecr get-login-password --region $region \\\n  | docker login --username AWS --password-stdin $registry\n\n# push image\necho \"Push image ...\"\ndocker push ${repository}:${tag}\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-3-create-docker-image/#verify","title":"Verify","text":"<pre><code># verify\nred='\\e[0;31m'    \ngreen='\\e[0;32m'    \nclear='\\e[0m'\n\npushed_tag=$(reg categories ${repository} | grep \"${tag}\")\nif [ \"${pushed_tag}\" != \"${tag}\" ]; then\n    printf \"${red}Failed${clear}\"; echo\nelse    \n    printf \"${green}Success${clear}\"; echo\nfi\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-4-create-service/","title":"Launch ECS container using AWS CLI - Step 4 - Create Service","text":"<p>Setup an ECS container repository, create a Docker image, and upload the Docker image to the repository. </p> <p>This is part of a multi-post thread involving these steps:</p> <ol> <li>Network Setup </li> <li>Launch EC2 Instance</li> <li>Create Docker Image</li> <li>Create Service (this post)</li> <li>Cleanup</li> </ol>"},{"location":"launch-ecs-container-aws-cli-step-4-create-service/#define-names","title":"Define Names","text":"<pre><code># registry (in the form $registryId.dkr.ecr.$region.amazonaws.com)\nregion=$(aws configure get region)\nregistryId=$(aws ecr describe-registry | jq -r '.registryId')\nregistry=\"$registryId.dkr.ecr.$region.amazonaws.com\"\n\ncluster=\"cluster-ecs\"\nservice=\"ecs-test-service\"\ntask_def_family=\"ecs-test\"\ntask=\"ecs-test\"\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-4-create-service/#create-task-definition","title":"Create Task Definition","text":"<pre><code>cat &lt;&lt; EOT &gt; ./test-ecs-task-def.json\n{\n    \"family\": \"ecs-test\",\n    \"containerDefinitions\": [\n        {\n            \"image\": \"$registry/ecs-test:latest\",\n            \"name\": \"test\",\n            \"cpu\": 512,\n            \"memory\": 512, \n            \"essential\": true\n        }\n    ]\n}\nEOT\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-4-create-service/#register-task-definition","title":"Register Task Definition","text":"<p>Register task definition:</p> <pre><code>echo \"Register task definition ...\"\naws ecs register-task-definition --cli-input-json file://test-ecs-task-def.json\n</code></pre> <p>To list task definitions:</p> <pre><code>aws ecs list-task-definitions\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-4-create-service/#create-service","title":"Create Service","text":"<pre><code>task_def_arn=$(aws ecs list-task-definitions --sort DESC --family-prefix $task_def_family | jq -r '.taskDefinitionArns[0]')\n\necho \"Launch service $service ...\"\naws ecs create-service \\\n    --cluster $cluster \\\n    --service-name $service \\\n    --task-definition $task_def_arn \\\n    --desired-count 1\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-4-create-service/#connect-to-the-container","title":"Connect to the Container","text":"<p>Find EC2 instance IP address:</p> <pre><code>task_arn=$(aws ecs list-tasks --cluster=$cluster --service-name=$service | jq -r '.taskArns[0]')\ncontainer_instance_arn=$(aws ecs describe-tasks --cluster=$cluster --tasks $task_arn | jq -r '.tasks[0].containerInstanceArn')\n\nec2_instance=$(aws ecs describe-container-instances --cluster=$cluster --container-instances $container_instance_arn | jq -r '.containerInstances[0].ec2InstanceId')\nec2_ip=$(aws ec2 describe-instances --instance-ids $ec2_instance | jq -r '.Reservations[0].Instances[0].PublicIpAddress')\n\nec2_key=\"~/.ssh/aws-ec2-key\"\n</code></pre> <p>Connect to the EC2 instance: </p> <pre><code>ssh -i $ec2_key ec2-user@$ec2_ip\n</code></pre> <p>Connect to the Docker container:</p> <pre><code># On the EC2 instance\ntask=\"ecs-test\"\ncontainer_id=$(docker ps -a -q -f name=ecs-$task | head -n 1)\ndocker exec -it $container_id bash\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-5-cleanup/","title":"Launch ECS container using AWS CLI - Step 5 - Cleanup","text":"<p>Delete all the resources that were created in this series. </p> <p>This is the last part of a multi-post thread involving these steps:</p> <ol> <li>Network Setup </li> <li>Launch EC2 Instance</li> <li>Create Docker Image</li> <li>Create Service</li> <li>Cleanup (this post)</li> </ol>"},{"location":"launch-ecs-container-aws-cli-step-5-cleanup/#define-names","title":"Define Names","text":"<pre><code># service\nservice=\"ecs-test-service\"\ntask=\"ecs-test\"\n\n# task definition\ntask_def_family=\"ecs-test\"\n\n# cluster\ncluster=\"cluster-ecs\"\n\n# IAM\ninstance_profile=\"instance-profile-ecs\"\ninstance_role=\"instance-role-ecs\"\n\n# EC2\ninstance=\"instance-ecs\"\n\n# VPC\nvpc=\"vpc-ecs\"\n\n# Subnets\nsubnet_1=\"subnet-ecs-1\"\nsubnet_2=\"subnet-ecs-2\"\n\n# Internet Gateway\ninternet_gateway=\"igw-ecs\"\n\n# Route Table\nroute_table=\"rtb-ecs\"\n\n# Security Group\nsecurity_group=\"security-ecs\"\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-5-cleanup/#cleanup","title":"Cleanup","text":"<p>Delete all resources in reverse order of creation:</p> <pre><code>echo \"Delete service $service ...\"\naws ecs delete-service --force --cluster $cluster --service $service \n\necho \"Deregister task definition $task ...\"\ntask_def_arn=$(aws ecs list-task-definitions --sort DESC --family-prefix $task_def_family | jq -r '.taskDefinitionArns[0]')\naws ecs deregister-task-definition --task-definition $task_def_arn\n\necho \"Delete EC2 Instance ...\"\ninstance_id=$(aws ec2 describe-instances \\\n    --filters \\\n        Name=tag:Name,Values=$instance \\\n        Name=instance-state-name,Values=running \\\n| jq -r '.Reservations[0].Instances[0].InstanceId')\n\naws ec2 terminate-instances --instance-ids $instance_id\n\necho \"Wait until EC2 instance terminates ...\"\naws ec2 wait instance-terminated --instance-ids $instance_id\n\necho \"Delete EC2 Instance Profile ...\"\naws iam remove-role-from-instance-profile \\\n    --instance-profile-name $instance_profile \\\n    --role-name $instance_role\n\naws iam delete-instance-profile --instance-profile-name $instance_profile\n\necho \"Delete EC2 Instance Role ...\"\naws iam detach-role-policy \\\n    --role-name $instance_role \\\n    --policy-arn arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role\n\naws iam delete-role --role-name $instance_role\n\necho \"Delete ECS cluster ...\"\naws ecs delete-cluster --cluster $cluster\n\necho \"Delete Security Group ...\"\ngroup_id=$(aws ec2 describe-security-groups --filters Name=tag:Name,Values=$security_group | jq -r '.SecurityGroups[0].GroupId')\naws ec2 delete-security-group --group-id $group_id\n\necho \"Delete Subnets ...\"\nsubnet_1_id=$(aws ec2 describe-subnets --filters Name=tag:Name,Values=$subnet_1 | jq -r '.Subnets[0].SubnetId')\naws ec2 delete-subnet --subnet-id $subnet_1_id\n\nsubnet_2_id=$(aws ec2 describe-subnets --filters Name=tag:Name,Values=$subnet_2 | jq -r '.Subnets[0].SubnetId')\naws ec2 delete-subnet --subnet-id $subnet_2_id\n\necho \"Delete Route Table ...\"\nroute_table_id=$(aws ec2 describe-route-tables --filters Name=tag:Name,Values=$route_table | jq -r '.RouteTables[0].RouteTableId')\naws ec2 delete-route-table --route-table-id $route_table_id\n\necho \"Delete Internet Gateway ...\"\ninternet_gateway_id=$(aws ec2 describe-internet-gateways --filters Name=tag:Name,Values=$internet_gateway | jq -r '.InternetGateways[0].InternetGatewayId')\nvpc_id=$(aws ec2 describe-vpcs --filters Name=tag:Name,Values=$vpc | jq -r '.Vpcs[0].VpcId')\naws ec2 detach-internet-gateway --internet-gateway-id $internet_gateway_id --vpc-id $vpc_id\n\naws ec2 delete-internet-gateway --internet-gateway-id $internet_gateway_id\n\necho \"Delete VPC ...\"\naws ec2 delete-vpc --vpc-id $vpc_id\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-5-cleanup/#danger","title":"!!! DANGER !!!","text":""},{"location":"launch-ecs-container-aws-cli-step-5-cleanup/#delete-latest-image","title":"Delete <code>latest</code> image","text":"<pre><code>repo=\"ecs-test\"\nregistryId=$(aws ecr describe-registry | jq -r '.registryId')\n\naws ecr batch-delete-image \\\n  --registry-id $registryId \\\n  --repository-name $repo \\\n  --image-ids imageTag=latest\n</code></pre>"},{"location":"launch-ecs-container-aws-cli-step-5-cleanup/#delete-repository","title":"Delete repository","text":"<p>NOTE: This will delete all images in the repo and the repo itself:</p> <pre><code>repo=\"ecs-test\"\nregistryId=$(aws ecr describe-registry | jq -r '.registryId')\n\naws ecr delete-repository \\\n  --force \\\n  --registry-id $registryId \\\n  --repository-name $repo\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/","title":"Launch ECS container using AWS ECS CLI","text":"<p>The Amazon ECS Command Line Interface (CLI) is a command line tool for Amazon Elastic Container Service (Amazon ECS) that provides high-level commands to simplify creating, updating, and monitoring clusters and tasks from a local development environment.</p> <p>Make sure you do this setup first:</p> <ol> <li>Setup macOS for AWS Cloud DevOps</li> <li>AWS Authentication</li> </ol>"},{"location":"launch-ecs-container-ecs-cli/#install-aws-ecs-cli","title":"Install AWS ECS CLI","text":"<p>Install:</p> <pre><code>mkdir -p ~/ecs-cli\npushd ~/ecs-cli\n\n# Download\ncurl -Lo ecs-cli https://amazon-ecs-cli.s3.amazonaws.com/ecs-cli-darwin-amd64-latest\ncurl -Lo ecs-cli.asc https://amazon-ecs-cli.s3.amazonaws.com/ecs-cli-darwin-amd64-latest.asc\n\n# Verify signature\ngpg --keyserver hkp://keys.gnupg.net --recv BCE9D9A42D51784F\ngpg --verify ecs-cli.asc ecs-cli\n\n# Copy to path\nsudo cp ecs-cli /usr/local/bin\nsudo chmod a+x /usr/local/bin/ecs-cli\n\npopd\n</code></pre> <p>Test:</p> <pre><code>ecs-cli --version\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#define-variables","title":"Define Variables","text":"<pre><code>image=\"ecs-test\"\ntag=\"latest\"\nservice_name=\"test\"\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#ecs-cli-setup","title":"ECS CLI Setup","text":"<p>Configuration information is stored in the <code>~/.ecs</code> directory on macOS and Linux systems and in <code>C:\\Users\\&lt;username&gt;\\AppData\\local\\ecs</code> on Windows systems.</p> <p>Create a profile using your access key and secret key:</p> <pre><code>export AWS_ACCESS_KEY_ID=$(aws configure get aws_access_key_id)\nexport AWS_SECRET_ACCESS_KEY=$(aws configure get aws_secret_access_key)\nexport AWS_REGION=$(aws configure get region)\n\necs-cli configure profile --profile-name swift\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#ecs-cluster-configuration","title":"ECS Cluster Configuration","text":"<p>Create a cluster configuration:</p> <pre><code>export AWS_REGION=$(aws configure get region)\n\necs-cli configure \\\n  --config-name test-ecs \\\n  --region $AWS_REGION \\\n  --cluster test-ecs \\\n  --default-launch-type EC2\n\necs-cli configure default --config-name test-ecs  \n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#launch-ecs-cluster","title":"Launch ECS Cluster","text":"<p>This will take a few minutes to complete:</p> <pre><code>ecs-cli up \\\n  --ecs-profile swift \\\n  --cluster-config test-ecs \\\n  --keypair aws-ec2-key \\\n  --capability-iam \\\n  --instance-type t2.micro \\\n  --size 1 \\\n  --port 22\n</code></pre> <p>In addition to EC2 Instances, other resources created by default include:</p> <ul> <li>Autoscaling Group</li> <li>Autoscaling Launch Configuration</li> <li>EC2 VPC</li> <li>EC2 Internet Gateway</li> <li>EC2 VPC Gateway Attachment</li> <li>EC2 Route Table</li> <li>EC2 Route</li> <li>2 Public EC2 Subnets</li> <li>2 EC2 SubnetRouteTableAssociations</li> <li>EC2 Security Group</li> </ul>"},{"location":"launch-ecs-container-ecs-cli/#create-ecs-repository","title":"Create ECS Repository","text":"<pre><code># registry (in the form $registryId.dkr.ecr.$region.amazonaws.com)\nregion=$(aws configure get region)\nregistryId=$(aws ecr describe-registry | jq -r '.registryId')\nregistry=\"$registryId.dkr.ecr.$region.amazonaws.com\"\n\n# repository\nrepository=$(aws ecr describe-repositories | jq -r \".repositories[] | select(.repositoryName==\\\"$image\\\") | .repositoryUri\")\n\n# create if it does not exist\n[ -z \"$repository\" ] &amp;&amp; aws ecr create-repository --repository-name $image\nrepository=$(aws ecr describe-repositories | jq -r \".repositories[] | select(.repositoryName==\\\"$image\\\") | .repositoryUri\")\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#create-docker-image","title":"Create Docker image","text":""},{"location":"launch-ecs-container-ecs-cli/#dockerfile","title":"Dockerfile","text":"<p>Create a <code>Dockerfile</code> with the following contents:</p> <pre><code>cat &lt;&lt; \"EOT\" &gt; ./Dockerfile\n# See https://hub.docker.com/_/oraclelinux for all supported \n# Oracle Linux categories from Docker Hub.\n\n# this image will be the actual running container\nFROM  oraclelinux:8\n\nLABEL Name=ecs-test\n\n## System Config\nENV TZ=America/Los_Angeles\n\n# Packages\nRUN yum -y install bind-utils \n\nCMD [\"/bin/ping\", \"localhost\"]\nEOT\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#build-image","title":"Build Image","text":"<pre><code>echo \"Build image ...\"\ndocker build --tag ${image}:${tag} .\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#tag-image","title":"Tag Image","text":"<pre><code>repository=$(aws ecr describe-repositories | jq -r \".repositories[] | select(.repositoryName==\\\"$image\\\") | .repositoryUri\")\n\necho \"Tag image ...\"\ndocker tag ${image}:${tag} ${repository}:${tag}\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#publish-image","title":"Publish Image","text":"<pre><code># refresh AWS token for docker\naws ecr get-login-password --region $region \\\n  | docker login --username AWS --password-stdin $registry\n\n# push image\necho \"Push image ...\"\ndocker push ${repository}:${tag}\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#verify","title":"Verify","text":"<pre><code># verify\nred='\\e[0;31m'    \ngreen='\\e[0;32m'    \nclear='\\e[0m'\n\npushed_tag=$(reg categories ${repository} | grep \"${tag}\")\nif [ \"${pushed_tag}\" != \"${tag}\" ]; then\n    printf \"${red}Failed${clear}\"; echo\nelse    \n    printf \"${green}Success${clear}\"; echo\nfi\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#launch-ecs-task","title":"Launch ECS Task","text":""},{"location":"launch-ecs-container-ecs-cli/#service-description","title":"Service Description","text":"<p>Create <code>docker-compose.yml</code> file:</p> <pre><code>cat &lt;&lt; EOT &gt; ./docker-compose.yml\nversion: '3'\n\nservices:\n  ecs-test:\n    image: $repository:$tag\n\n    logging:\n      driver: awslogs\n      options: \n        awslogs-group: test-ecs\n        awslogs-region: us-west-2\n        awslogs-stream-prefix: test\nEOT\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#task-definition","title":"Task Definition","text":"<p>Create <code>ecs-params.yml</code> file:</p> <pre><code>cat &lt;&lt; EOT &gt; ./ecs-params.yml\nversion: 1\ntask_definition:\n  services:\n    ecs-test:\n      cpu_shares: 100\n      mem_limit: 524288000\nEOT\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#launch-service","title":"Launch Service","text":"<pre><code># create service\necs-cli compose \\\n    --project-name $service_name \\\n    --file ./docker-compose.yml \\\n    --ecs-params ./ecs-params.yml \\\n    service up \\\n    --create-log-groups \\\n    --cluster-config test-ecs \\\n    --ecs-profile swift\n</code></pre> <p>Login to the first task of the <code>test</code> service:</p> <pre><code>CLUSTER=test-ecs\nSERVICE=test\n\nTASK_ARN=$( aws ecs list-tasks --cluster=$CLUSTER --service-name=$SERVICE | jq -r '.taskArns[0]' )\nCONTAINER_INSTANCE_ARN=$( aws ecs describe-tasks --cluster=$CLUSTER --tasks $TASK_ARN | jq -r '.tasks[0].containerInstanceArn' )\n\nEC2_INSTANCE=$( aws ecs describe-container-instances --cluster=$CLUSTER --container-instances $CONTAINER_INSTANCE_ARN | jq -r '.containerInstances[0].ec2InstanceId' )\nEC2_IP=$( aws ec2 describe-instances --instance-ids $EC2_INSTANCE | jq -r '.Reservations[0].Instances[0].PublicIpAddress' )\n\nEC2_KEY=\"~/.ssh/aws-ec2-key\"\n\nssh -i $EC2_KEY ec2-user@$EC2_IP -t 'bash -c \"docker exec -it $( docker ps -a -q -f name=ecs-'$SERVICE' | head -n 1 ) bash\"'\n</code></pre> <p>Check task logs:</p> <pre><code>task_id=$( aws ecs list-tasks --cluster=test-ecs --service-name=test | jq -r '.taskArns[0]' | cut -d \"/\" -f 3 )\necs-cli logs --task-id $task_id\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#cleanup","title":"Cleanup","text":"<p>WARNING: These scripts destroy the created AWS resources. Proceed with caution!!!</p>"},{"location":"launch-ecs-container-ecs-cli/#stop-services","title":"Stop services","text":"<p>Stop running tasks and remove service:</p> <pre><code>ecs-cli compose --project-name test service down\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#delete-cluster","title":"Delete cluster","text":"<pre><code>ecs-cli down \\\n  --force  \\\n  --ecs-profile swift \\\n  --cluster-config test-ecs\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#delete-log-group","title":"Delete log group","text":"<pre><code>aws logs delete-log-group --log-group-name test-ecs\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#delete-image","title":"Delete image","text":"<pre><code>repo=ecs-test\nregistryId=$(aws ecr describe-registry | jq -r '.registryId')\n\naws ecr batch-delete-image \\\n  --registry-id $registryId \\\n  --repository-name $repo \\\n  --image-ids imageTag=latest\n</code></pre>"},{"location":"launch-ecs-container-ecs-cli/#delete-image-repository","title":"Delete image repository","text":"<p>This will delete all images in the repo and the repo itself</p> <pre><code>repo=\"ecs-test\"\nregistryId=$(aws ecr describe-registry | jq -r '.registryId')\n\naws ecr delete-repository \\\n  --force \\\n  --registry-id $registryId \\\n  --repository-name $repo\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-1-network-setup/","title":"Deploy Docker Swarm on AWS EC2 via cloud-formation templates - Step 1 - Network Setup","text":"<p>Setup network infrastructure including new VPC (Virtual Private Cloud), public and private subnets, internet gateway, security group, and ssh access.</p> <p>This post is part of a thread that includes these steps:</p> <ol> <li>Network Setup (this post)</li> <li>Storage</li> <li>Roles</li> <li>Manager Instance</li> <li>Worker Launch Template</li> <li>Worker Instances</li> <li>Docker Swarm</li> <li>Cleanup</li> </ol> <p>Make sure you do this setup first:</p> <ol> <li>Setup macOS for AWS Cloud DevOps</li> <li>AWS Authentication</li> </ol>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-1-network-setup/#project-structure","title":"Project Structure","text":"<p>For this deployment we will create 2 separate code repositories. The first one will be named <code>swift-aws-ec2-swarm</code> and the second one will be named <code>swift-aws-ec2-docker</code>. </p> <p>As a start, create the <code>swift-aws-ec2-swarm</code> directory in your home dir and switch to it. We will call this the \"project dir\".</p> <pre><code>mkdir -p ~/swift-aws-ec2-swarm\ncd ~/swift-aws-ec2-swarm\n</code></pre> <p>The rest of this post assumes we work from within the \"project dir\". </p>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-1-network-setup/#configuration","title":"Configuration","text":"<p>Create a folder <code>config</code> and <code>names.sh</code> file in it. </p> <pre><code>mkdir -p config\ntouch config/names.sh\nnano config/names.sh\n</code></pre> <p>Copy and paste this code into <code>names.sh</code>:</p> <pre><code>export AWS_DEFAULT_PROFILE=swift\n\nprefix=\"swift-swarm\"\n\nec2_key_pair=\"aws-ec2-key\"\n\nstack_vpc=\"$prefix-vpc\"\n\nstack_ebs=\"$prefix-ebs\"\n\nstack_iam_manager=\"$prefix-iam-manager\"\nstack_ec2_manager=\"$prefix-ec2-manager\"\n\nstack_iam_worker=\"$prefix-iam-worker\"\nstack_ec2_worker=\"$prefix-ec2-worker\"\nstack_ec2_worker_lt=\"$prefix-ec2-worker-lt\"\n\nvpc=\"$prefix-vpc-1\"\n\nsubnet_pub_1=\"$prefix-sn-pub-1\"\nsubnet_priv_1=\"$prefix-sn-priv-1\"\n\nsecurity_group_pub_1=\"$prefix-sg-pub-1\"\nsecurity_group_priv_1=\"$prefix-sg-priv-1\"\n</code></pre> <p>IMPORTANT: Replace <code>swift</code> in the first line with the name of your AWS CLI profile or set to <code>default</code> if you don;t use different profiles.</p>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-1-network-setup/#virtual-private-cloud-aws-vpc","title":"Virtual Private Cloud (AWS VPC)","text":""},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-1-network-setup/#cloud-formation-template","title":"cloud-formation Template","text":"<p>Create a folder <code>network</code> and a <code>vpc.yml</code> file in it. </p> <pre><code>mkdir -p vpc\ntouch vpc/vpc.yml\nnano vpc/vpc.yml\n</code></pre> <p>Copy and paste this code into <code>vpc.yml</code>:</p> <pre><code>Description: Create VPC, public subnet, private subnet, Internet gateway, NAT gateway, security groups, and Route53 hosted zone for the VPC. \n\nParameters:\n  Prefix:\n    Description: An environment name that is prefixed to resource names\n    Type: String\n\n  VpcCIDR:\n    Description: Please enter the IP range (CIDR notation) for this VPC\n    Type: String\n    Default: 10.0.0.0/16\n\n  PublicSubnetCIDR:\n    Description: Please enter the IP range (CIDR notation) for the public subnet in the first Availability Zone\n    Type: String\n    Default: 10.0.10.0/24\n\n  PrivateSubnetCIDR:\n    Description: Please enter the IP range (CIDR notation) for the private subnet in the first Availability Zone\n    Type: String\n    Default: 10.0.20.0/24\n\nResources:\n  # VPC\n  Vpc:\n    Type: AWS::EC2::VPC\n    Properties:\n      CidrBlock: !Ref VpcCIDR\n      EnableDnsSupport: true\n      EnableDnsHostnames: true\n      # categories:\n        - Key: Name\n          Value: !Sub ${Prefix}-vpc-1\n\n  # Internet Gateway\n  InternetGateway:\n    Type: AWS::EC2::InternetGateway\n    Properties:\n      # categories:\n        - Key: Name\n          Value: !Sub ${Prefix}-igw-1\n\n  InternetGatewayAttachment:\n    Type: AWS::EC2::VPCGatewayAttachment\n    Properties:\n      VpcId: !Ref Vpc\n      InternetGatewayId: !Ref InternetGateway\n\n  # Public Subnet\n  PublicSubnet:\n    Type: AWS::EC2::Subnet\n    Properties:\n      VpcId: !Ref Vpc\n      CidrBlock: !Ref PublicSubnetCIDR\n      AvailabilityZone: !Select [ 0, !GetAZs '' ]\n      MapPublicIpOnLaunch: true\n      # categories:\n        - Key: Name\n          Value: !Sub ${Prefix}-sn-pub-1\n\n  # Private Subnet\n  PrivateSubnet:\n    Type: AWS::EC2::Subnet\n    Properties:\n      VpcId: !Ref Vpc\n      CidrBlock: !Ref PrivateSubnetCIDR\n      AvailabilityZone: !Select [ 0, !GetAZs  '' ]\n      MapPublicIpOnLaunch: false\n      # categories:\n        - Key: Name\n          Value: !Sub ${Prefix}-sn-priv-1\n\n  # NAT Elastic IP\n  NatGatewayEIP:\n    Type: AWS::EC2::EIP\n    DependsOn: InternetGatewayAttachment\n    Properties:\n      Domain: vpc\n      # categories:\n        - Key: Name\n          Value: !Sub ${Prefix}-eip-1\n\n  # NAT Gateway\n  NatGateway:\n    Type: AWS::EC2::NatGateway\n    Properties:\n      AllocationId: !GetAtt NatGatewayEIP.AllocationId\n      SubnetId: !Ref PublicSubnet\n      # categories:\n        - Key: Name\n          Value: !Sub ${Prefix}-ng-1\n\n  # Public route table\n  PublicRouteTable:\n    Type: AWS::EC2::RouteTable\n    Properties:\n      VpcId: !Ref Vpc\n      # categories:\n        - Key: Name\n          Value: !Sub ${Prefix}-rt-pub-1\n\n  # Route to internet gateway\n  DefaultPublicRoute:\n    Type: AWS::EC2::Route\n    DependsOn: InternetGatewayAttachment\n    Properties:\n      RouteTableId: !Ref PublicRouteTable\n      DestinationCidrBlock: 0.0.0.0/0\n      GatewayId: !Ref InternetGateway\n\n  # Routes for public subnet\n  PublicSubnetRouteTableAssociation:\n    Type: AWS::EC2::SubnetRouteTableAssociation\n    Properties:\n      RouteTableId: !Ref PublicRouteTable\n      SubnetId: !Ref PublicSubnet\n\n  # Routes for private subnet\n  PrivateRouteTable:\n    Type: AWS::EC2::RouteTable\n    Properties:\n      VpcId: !Ref Vpc\n      # categories:\n        - Key: Name\n          Value: !Sub ${Prefix}-rt-priv-1\n\n  DefaultPrivateRoute:\n    Type: AWS::EC2::Route\n    Properties:\n      RouteTableId: !Ref PrivateRouteTable\n      DestinationCidrBlock: 0.0.0.0/0\n      NatGatewayId: !Ref NatGateway          \n\n  PrivateSubnetRouteTableAssociation:\n    Type: AWS::EC2::SubnetRouteTableAssociation\n    Properties:\n      RouteTableId: !Ref PrivateRouteTable\n      SubnetId: !Ref PrivateSubnet\n\n  ## Security groups\n  # Public\n  PublicSecurityGroup:\n    Type: AWS::EC2::SecurityGroup\n    Properties:\n      GroupDescription: Security group for manager nodes\n      # categories:\n        - Key: Name\n          Value: !Sub ${Prefix}-sg-pub-1\n      VpcId: !Ref Vpc\n      SecurityGroupIngress:\n        - IpProtocol: tcp\n          FromPort: 22\n          ToPort: 22\n          CidrIp: 0.0.0.0/0\n\n  # Private\n  PrivateSecurityGroup:\n    Type: AWS::EC2::SecurityGroup\n    Properties:\n      GroupDescription: Security group for worker nodes\n      # categories:\n        - Key: Name\n          Value: !Sub ${Prefix}-sg-priv-1\n      VpcId: !Ref Vpc\n\n  ## Ingress rules\n  # Public\n  PublicSecurityGroupIngressFromSelf:\n    Type: AWS::EC2::SecurityGroupIngress\n    Properties:\n      GroupId: !GetAtt [ PublicSecurityGroup, GroupId ]\n      IpProtocol: -1\n      SourceSecurityGroupId: !GetAtt [ PublicSecurityGroup, GroupId ]\n\n  PublicSecurityGroupIngressFromPrivate:\n    Type: AWS::EC2::SecurityGroupIngress\n    Properties:\n      GroupId: !GetAtt [ PublicSecurityGroup, GroupId ]\n      IpProtocol: -1\n      SourceSecurityGroupId: !GetAtt [ PrivateSecurityGroup, GroupId ]\n\n  # Private\n  PrivateSecurityGroupIngressFromSelf:\n    Type: AWS::EC2::SecurityGroupIngress\n    Properties:\n      GroupId: !GetAtt [ PrivateSecurityGroup, GroupId ]\n      IpProtocol: -1\n      SourceSecurityGroupId: !GetAtt [ PrivateSecurityGroup, GroupId ]\n\n  PrivateSecurityGroupIngressFromPublic:\n    Type: AWS::EC2::SecurityGroupIngress\n    Properties:\n      GroupId: !GetAtt [ PrivateSecurityGroup, GroupId ]\n      IpProtocol: -1\n      SourceSecurityGroupId: !GetAtt [ PublicSecurityGroup, GroupId ]\n\n  # Add DNS zone for our VPC\n  HostedZone:\n    Type: 'AWS::Route53::HostedZone'\n    Properties:\n      Name: swift.internal.\n      VPCs:\n        - VPCId: !Ref Vpc\n          VPCRegion: !Ref \"AWS::Region\"\n      HostedZoneConfig:\n        Comment: 'Hosted zone for swift.internal'      \n\nOutputs:\n  VpcId:\n    Description: A reference to the created VPC\n    Value: !Ref Vpc\n\n  PublicSubnetId:\n    Description: A reference to the public subnet in the 1st Availability Zone\n    Value: !Ref PublicSubnet\n\n  PrivateSubnetId:\n    Description: A reference to the private subnet in the 1st Availability Zone\n    Value: !Ref PrivateSubnet\n\n  PublicSecurityGroupId:\n    Description: A reference to the public SecurityGroup\n    Value: !Ref PublicSecurityGroup\n\n  PrivateSecurityGroupId:\n    Description: A reference to the private SecurityGroup\n    Value: !Ref PrivateSecurityGroup\n\n  HostedZoneId:\n    Description: A reference to the Route53 HostedZone\n    Value: !Ref HostedZone\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-1-network-setup/#scripts","title":"Scripts","text":"<p>Next add a script <code>deploy-vpc.sh</code> and paste this code in it:</p> <pre><code>#!/usr/bin/env bash\n\n# switch to parent directory\nscript_path=`dirname ${BASH_SOURCE[0]}`\npushd $script_path/..\n\nsource config/names.sh\n\necho\necho \"Deploying $stack_vpc stack via cloud-formation:\"\necho 'https://us-west-2.console.aws.amazon.com/cloudformation/home'\necho\n\nset -x\n\naws cloudformation deploy \\\n    --profile swift \\\n    --template-file vpc/vpc.yml \\\n    --stack-name $stack_vpc \\\n    --parameter-overrides Prefix=$prefix\n\npopd\n</code></pre> <p>Let's also add a clean up script <code>rm-vpc.sh</code>:</p> <pre><code>#!/usr/bin/env bash\n\n# switch to parent directory\nscript_path=`dirname ${BASH_SOURCE[0]}`\npushd $script_path/..\n\nsource config/names.sh\n\necho\necho \"Removing $stack_vpc stack via cloud-formation:\"\necho 'https://us-west-2.console.aws.amazon.com/cloudformation/home'\necho\n\nset -x\n\naws cloudformation delete-stack \\\n    --stack-name $stack_vpc \n\naws cloudformation wait stack-delete-complete \\\n    --stack-name $stack_vpc\n\npopd\n</code></pre> <p>Make the scripts executable:</p> <pre><code>chmod +x vpc/deploy-vpc.sh \nchmod +x vpc/rm-vpc.sh\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-1-network-setup/#deploy","title":"Deploy","text":"<p>Finally let's run the \"deploy\" script to setup our network:</p> <pre><code>./vpc/deploy-vpc.sh\n</code></pre> <p>You should see output similar to this:</p> <pre><code>Deploying swift-swarm-vpc stack via cloud-formation:\nhttps://us-west-2.console.aws.amazon.com/cloudformation/home\n\n+ aws cloudformation deploy --template-file network/vpc.yml --stack-name swift-swarm-vpc --parameter-overrides Prefix=swift-swarm\n\nWaiting for changeset to be created..\nWaiting for stack create/update to complete\nSuccessfully created/updated stack - swift-swarm-vpc\n</code></pre> <p>At this point your project structure should look like this:</p> <pre><code>.\n\u251c\u2500\u2500 config\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 names.sh\n\u2514\u2500\u2500 vpc\n    \u251c\u2500\u2500 deploy-vpc.sh\n    \u251c\u2500\u2500 rm-vpc.sh\n    \u2514\u2500\u2500 vpc.yml\n</code></pre> <p>Congratulations! </p> <p>We are done with <code>Step 1. Network Setup</code>. </p> <p>Next step is: Step 2. Storage</p>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-2-storage/","title":"Deploy Docker Swarm on AWS EC2 via cloud-formation templates - Step 2 - Storage","text":"<p>In this step we will create a shared EBS volume which will be used as a home directory for the Linux users.</p> <p>This post is part of a thread that includes these steps:</p> <ol> <li>Network Setup</li> <li>Storage (this post)</li> <li>Roles</li> <li>Manager Instance</li> <li>Worker Launch Template</li> <li>Worker Instances</li> <li>Docker Swarm</li> <li>Cleanup</li> </ol>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-2-storage/#elastic-block-storage-aws-ebs","title":"Elastic Block Storage (AWS EBS)","text":"<p>Start in the project directory:</p> <pre><code>cd ~/swift-aws-ec2-swarm\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-2-storage/#cloud-formation-template","title":"cloud-formation Template","text":"<p>Create a folder <code>ebs</code> and a <code>ebs.yml</code> file in it. </p> <pre><code>mkdir -p ebs\ntouch ebs/ebs.yml\nnano ebs/ebs.yml\n</code></pre> <p>Copy and paste this code into <code>ebs.yml</code>:</p> <pre><code>Description: Shared EBS volumes for the Docker Swarm instances  \n\nResources:\n  HomeVolume:\n    Type: 'AWS::EC2::Volume'\n    Properties:\n      VolumeType: io2\n      Iops: 3000      \n      Size: 30\n      Encrypted: true\n      AvailabilityZone: !Select [ 0, !GetAZs '' ]\n      MultiAttachEnabled: true\n      # categories:\n        - Key: Name\n          Value: shared-volume-home\n\nOutputs:\n  HomeVolumeId:\n    Description: The ID of the created home EBS volume\n    Value: !Ref HomeVolume\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-2-storage/#scripts","title":"Scripts","text":"<p>Next add a script <code>deploy-ebs.sh</code> and paste this code in it:</p> <pre><code>#!/usr/bin/env bash\n\n# switch to parent directory\nscript_path=`dirname ${BASH_SOURCE[0]}`\npushd $script_path/..\n\nsource config/names.sh\n\necho\necho \"Deploying $stack_ebs stack via cloud-formation:\"\necho 'https://us-west-2.console.aws.amazon.com/cloudformation/home'\necho\n\nset -x\n\naws cloudformation deploy \\\n    --template-file ebs/ebs.yml \\\n    --stack-name $stack_ebs\n\npopd\n</code></pre> <p>Let's also add a clean up script <code>rm-ebs.sh</code>:</p> <pre><code>#!/usr/bin/env bash\n\n\n# switch to parent directory\nscript_path=`dirname ${BASH_SOURCE[0]}`\npushd $script_path/..\n\nsource config/names.sh\n\necho\necho \"Destroying $stack_ebs stack via cloud-formation:\"\necho 'https://us-west-2.console.aws.amazon.com/cloudformation/home'\necho\n\nset -x\n\naws cloudformation delete-stack \\\n    --stack-name $stack_ebs \n\naws cloudformation wait stack-delete-complete \\\n    --stack-name $stack_ebs\n</code></pre> <p>Make the scripts executable:</p> <pre><code>chmod +x ebs/deploy-ebs.sh \nchmod +x ebs/rm-ebs.sh\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-2-storage/#deploy","title":"Deploy","text":"<p>Finally let's run the \"deploy\" script to create the EBS volumes:</p> <pre><code>./ebs/deploy-ebs.sh\n</code></pre> <p>You should see output similar to this:</p> <pre><code>Deploying swift-swarm-ebs stack via cloud-formation:\nhttps://us-west-2.console.aws.amazon.com/cloudformation/home\n\n+ aws cloudformation deploy --template-file ebs/ebs.yml --stack-name swift-swarm-ebs\n\nWaiting for changeset to be created..\nWaiting for stack create/update to complete\nSuccessfully created/updated stack - swift-swarm-ebs\n</code></pre> <p>At this point your project structure should look like this:</p> <pre><code>.\n\u251c\u2500\u2500 config\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 names.sh\n\u251c\u2500\u2500 ebs\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 deploy-ebs.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ebs.yml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 rm-ebs.sh\n\u2514\u2500\u2500 vpc\n    \u251c\u2500\u2500 deploy-vpc.sh\n    \u251c\u2500\u2500 rm-vpc.sh\n    \u2514\u2500\u2500 vpc.yml\n</code></pre> <p>Congratulations! </p> <p>We are done with <code>Step 2. Storage</code>. </p> <p>Next step is: Step 3. Roles</p>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-3-roles/","title":"Deploy Docker Swarm on AWS EC2 via cloud-formation templates - Step 3 - Roles","text":"<p>In this step we create the IAM roles and policies needed by the EC2 instances.</p> <p>This post is part of a thread that includes these steps:</p> <ol> <li>Network Setup</li> <li>Storage</li> <li>Roles (this post)</li> <li>Manager Instance</li> <li>Worker Launch Template</li> <li>Worker Instances</li> <li>Docker Swarm</li> <li>Cleanup</li> </ol>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-3-roles/#identity-and-access-management-aws-iam","title":"Identity and Access Management (AWS IAM)","text":"<p>Start in the project directory:</p> <pre><code>cd ~/swift-aws-ec2-swarm\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-3-roles/#cloud-formation-template","title":"cloud-formation Template","text":"<p>We need to create IAM Role and Instance Profile for two types of instances:</p> <ol> <li>Manager - this will be used by the Manager instance</li> <li>Worker - this will be used by the Worker instances</li> </ol>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-3-roles/#manager","title":"Manager","text":"<p>Create a folder <code>iam</code> and a <code>iam-manager.yml</code> file in it. </p> <pre><code>mkdir -p iam\ntouch iam/iam-manager.yml\nnano iam/iam-manager.yml\n</code></pre> <p>Copy and paste this code into <code>iam-manager.yml</code>:</p> <pre><code>Description:  IAM role and instance profile for the Manager instance\n\nParameters:\n  Prefix:\n    Description: An environment name that is prefixed to resource names\n    Type: String\n\n# Permissions for the Manager instance\nResources:\n  Role:\n    Type: AWS::IAM::Role\n    Properties:\n      # categories:\n        - Key: Name\n          Value: !Sub ${Prefix}-iam-role-manager\n      AssumeRolePolicyDocument:\n        Version: 2012-10-17\n        Statement:\n          - Effect: Allow\n            Principal:\n              Service: ec2.amazonaws.com\n            Action: sts:AssumeRole\n      ManagedPolicyArns:\n        - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly\n      Policies:\n        - PolicyName: root\n          PolicyDocument:\n            Version: 2012-10-17\n            Statement:\n              - Effect: Allow\n                Action: \n                  - ec2:DescribeTags\n                  - ec2:AttachVolume\n                  - ec2:DetachVolume\n                  - ecr:DescribeRegistry\n                  - route53:*\n                Resource: '*'\n\n  InstanceProfile:\n    Type: AWS::IAM::InstanceProfile\n    Properties:\n      Roles:\n        - !Ref Role\n\nOutputs:\n  InstanceProfile:\n    Description: A reference to the created InstanceProfile\n    Value: !Ref InstanceProfile\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-3-roles/#worker","title":"Worker","text":"<p>Create a file <code>iam/iam-worker.yml</code></p> <pre><code>touch iam/iam-worker.yml\nnano iam/iam-worker.yml\n</code></pre> <p>Copy and paste this code into <code>iam-worker.yml</code>:</p> <pre><code>Description:  IAM role and instance profile for the Worker instances\n\nParameters:\n  Prefix:\n    Description: An environment name that is prefixed to resource names\n    Type: String\n\n# Permissions for the Worker instance(s)\nResources:\n  Role:\n    Type: AWS::IAM::Role\n    Properties:\n      # categories:\n        - Key: Name\n          Value: !Sub ${Prefix}-iam-role-worker\n      AssumeRolePolicyDocument:\n        Version: 2012-10-17\n        Statement:\n          - Effect: Allow\n            Principal:\n              Service: ec2.amazonaws.com\n            Action: sts:AssumeRole\n      ManagedPolicyArns:\n        - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly\n      Policies:\n        - PolicyName: root\n          PolicyDocument:\n            Version: 2012-10-17\n            Statement:\n              - Effect: Allow\n                Action: \n                  - ec2:DescribeTags\n                  - ec2:AttachVolume\n                  - ec2:DetachVolume\n                  - ecr:DescribeRegistry\n                  - route53:*\n                Resource: '*'\n\n  InstanceProfile:\n    Type: AWS::IAM::InstanceProfile\n    Properties:\n      Roles:\n        - !Ref Role\n\nOutputs:\n  InstanceProfile:\n    Description: A reference to the created InstanceProfile\n    Value: !Ref InstanceProfile\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-3-roles/#scripts","title":"Scripts","text":""},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-3-roles/#manager_1","title":"Manager","text":"<p>Add a script <code>iam/deploy-iam-manager.sh</code> and paste this code in it:</p> <pre><code>#!/usr/bin/env bash\n\n# switch to parent directory\nscript_path=`dirname ${BASH_SOURCE[0]}`\npushd $script_path/..\n\nsource config/names.sh\n\necho\necho \"Deploying $stack_iam_manager stack via cloud-formation:\"\necho 'https://us-west-2.console.aws.amazon.com/cloudformation/home'\necho\n\nset -x\n\n# NOTE: `--capabilities CAPABILITY_IAM` is needed because the `iam.yml` cloud-formation template creates roles and instance profiles.\n\naws cloudformation deploy \\\n    --capabilities CAPABILITY_IAM \\\n    --template-file iam/iam-manager.yml \\\n    --stack-name $stack_iam_manager \\\n    --parameter-overrides Prefix=$prefix\n\npopd\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-3-roles/#worker_1","title":"Worker","text":"<p>Add a script <code>iam/deploy-iam-worker.sh</code> and paste this code in it:</p> <pre><code>#!/usr/bin/env bash\n\n# switch to parent directory\nscript_path=`dirname ${BASH_SOURCE[0]}`\npushd $script_path/..\n\nsource config/names.sh\n\necho\necho \"Deploying $stack_iam_worker stack via cloud-formation:\"\necho 'https://us-west-2.console.aws.amazon.com/cloudformation/home'\necho\n\nset -x\n\n# NOTE: `--capabilities CAPABILITY_IAM` is needed because the `iam.yml` cloud-formation template creates roles and instance profiles.\n\naws cloudformation deploy \\\n    --capabilities CAPABILITY_IAM \\\n    --template-file iam/iam-worker.yml \\\n    --stack-name $stack_iam_worker \\\n    --parameter-overrides Prefix=$prefix\n\npopd\n</code></pre> <p>Let's also add clean up scripts. First the <code>rm-iam-manager.sh</code>:</p> <pre><code>#!/usr/bin/env bash\n\n# switch to parent directory\nscript_path=`dirname ${BASH_SOURCE[0]}`\npushd $script_path/..\n\nsource config/names.sh\n\necho\necho \"Removing $stack_iam_manager stack via cloud-formation:\"\necho 'https://us-west-2.console.aws.amazon.com/cloudformation/home'\necho\n\nset -x\n\naws cloudformation delete-stack \\\n    --stack-name $stack_iam_manager \n\naws cloudformation wait stack-delete-complete \\\n    --stack-name $stack_iam_manager\n\npopd\n</code></pre> <p>and another one for the worker - <code>rm-iam-worker.sh</code>:</p> <pre><code>#!/usr/bin/env bash\n\n# switch to parent directory\nscript_path=`dirname ${BASH_SOURCE[0]}`\npushd $script_path/..\n\nsource config/names.sh\n\necho\necho \"Removing $stack_iam_worker stack via cloud-formation:\"\necho 'https://us-west-2.console.aws.amazon.com/cloudformation/home'\necho\n\nset -x\n\naws cloudformation delete-stack \\\n    --stack-name $stack_iam_worker \n\naws cloudformation wait stack-delete-complete \\\n    --stack-name $stack_iam_worker\n\npopd\n</code></pre> <p>Make all scripts executable:</p> <pre><code>chmod +x iam/deploy-iam-manager.sh \nchmod +x iam/rm-iam-manager.sh\n\nchmod +x iam/deploy-iam-worker.sh \nchmod +x iam/rm-iam-worker.sh\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-3-roles/#deploy","title":"Deploy","text":"<p>Finally let's run the \"deploy\" scripts to create the IAM roles. First for the Manager:</p> <pre><code>./iam/deploy-iam-manager.sh\n</code></pre> <p>You should see output similar to this:</p> <pre><code>Deploying swift-swarm-iam-manager stack via cloud-formation:\nhttps://us-west-2.console.aws.amazon.com/cloudformation/home\n\n+ aws cloudformation deploy --capabilities CAPABILITY_IAM --template-file iam/iam-manager.yml --stack-name swift-swarm-iam-manager --parameter-overrides Prefix=swift-swarm\n\nWaiting for changeset to be created..\nWaiting for stack create/update to complete\nSuccessfully created/updated stack - swift-swarm-iam-manager\n</code></pre> <p>then for the Worker:</p> <pre><code>./iam/deploy-iam-worker.sh\n</code></pre> <p>You should see output similar to this:</p> <pre><code>Deploying swift-swarm-iam-worker stack via cloud-formation:\nhttps://us-west-2.console.aws.amazon.com/cloudformation/home\n\n+ aws cloudformation deploy --capabilities CAPABILITY_IAM --template-file iam/iam-worker.yml --stack-name swift-swarm-iam-worker --parameter-overrides Prefix=swift-swarm\n\nWaiting for changeset to be created..\nWaiting for stack create/update to complete\nSuccessfully created/updated stack - swift-swarm-iam-worker\n</code></pre> <p>At this point your project structure should look like this:</p> <pre><code>.\n\u251c\u2500\u2500 config\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 names.sh\n\u251c\u2500\u2500 ebs\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 deploy-ebs.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ebs.yml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 rm-ebs.sh\n\u251c\u2500\u2500 iam\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 deploy-iam-manager.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 deploy-iam-worker.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 iam-manager.yml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 iam-worker.yml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 rm-iam-manager.sh\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 rm-iam-worker.sh\n\u2514\u2500\u2500 vpc\n    \u251c\u2500\u2500 deploy-vpc.sh\n    \u251c\u2500\u2500 rm-vpc.sh\n    \u2514\u2500\u2500 vpc.yml\n</code></pre> <p>Congratulations! </p> <p>We are done with <code>Step 3. Roles</code>. </p> <p>Next step is: Step 4. Manager Instance</p>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-4-manager-instance/","title":"Deploy Docker Swarm on AWS EC2 via cloud-formation templates - Step 4 - Manager Instance","text":"<p>In this step we will configure and launch the Manager EC2 instance.</p> <p>This post is part of a thread that includes these steps:</p> <ol> <li>Network Setup</li> <li>Storage</li> <li>Roles</li> <li>Manager Instance (this post)</li> <li>Worker Launch Template</li> <li>Worker Instances</li> <li>Docker Swarm</li> <li>Cleanup</li> </ol>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-4-manager-instance/#manager-instance-aws-ec2","title":"Manager Instance (AWS EC2)","text":"<p>Start in the project directory:</p> <pre><code>cd ~/swift-aws-ec2-swarm\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-4-manager-instance/#cloud-formation-template","title":"cloud-formation Template","text":"<p>Create a folder <code>ec2-manager</code> and a <code>ec2-manager.yml</code> file in it. </p> <pre><code>mkdir -p ec2-manager\ntouch ec2-manager/ec2-manager.yml\nnano ec2-manager/ec2-manager.yml\n</code></pre> <p>Copy and paste this code into <code>ec2-manager.yml</code>:</p> <pre><code>Description: Docker Swarm Manager instance\n\nParameters:\n  KeyPair:\n    Type: AWS::EC2::KeyPair::KeyName\n    Description: Key pair that will be used to launch instances\n\n  SubnetId:\n    Type: AWS::EC2::Subnet::Id\n    Description: Subnet in the VPC where the instance will be launched\n\n  SecurityGroupId:\n    Type: AWS::EC2::SecurityGroup::Id\n    Description: Security group for the instance\n\n  InstanceProfile:\n    Type: String\n    Description: Instance profile to use for the instance\n\n  InstanceType:\n    Type: String\n    Default: c5.large\n    Description: Instance type to use for the instance\n\n  LatestAmiId:\n    Type: AWS::SSM::Parameter::Value&lt;AWS::EC2::Image::Id&gt;\n    Default: /aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2\n\n  HostedZoneId:\n    Type: AWS::Route53::HostedZone::Id\n    Description: ID of the Route53 HostedZone\n\n  HomeVolumeId:\n    Type: AWS::EC2::Volume::Id\n    Description: ID of the volume to be mounted as /home\n\nResources:\n  Instance:\n    Type: AWS::EC2::Instance\n    Properties: \n      KeyName: !Ref KeyPair\n\n      SubnetId: !Ref SubnetId\n      SecurityGroupIds:\n        - !Ref SecurityGroupId      \n\n      IamInstanceProfile: !Ref InstanceProfile\n\n      InstanceType: !Ref InstanceType\n\n      ImageId: !Ref LatestAmiId\n\n      BlockDeviceMappings: \n        # Docker volume\n        - DeviceName: /dev/sdi\n          Ebs: \n            Encrypted: true\n            DeleteOnTermination: true\n            VolumeSize: 100\n            VolumeType: gp2          \n\n      # categories:\n        - Key: Name\n          Value: manager\n\n      UserData:\n        Fn::Base64:\n          !Sub |\n            #!/bin/bash -xe\n\n            # see: https://aws.amazon.com/premiumsupport/knowledge-center/ec2-linux-log-user-data/\n            exec &gt; &gt;(tee /var/log/user-data.log|logger -t user-data -s 2&gt;/dev/console) 2&gt;&amp;1\n\n            EC2_INSTANCE_ID=$(ec2-metadata --instance-id | awk '{print $2}')\n            EC2_REGION=$(ec2-metadata --availability-zone | awk '{print $2}' | sed 's/.$//')\n\n            ## Timezone\n            # see: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/set-time.html#change_time_zone\n            timedatectl set-timezone America/Los_Angeles\n\n            ## DNS\n            PRIVATE_IP=$(curl -s http://169.254.169.254/latest/meta-data/local-ipv4)\n            DNS_NAME=$(aws ec2 describe-categories --filters \"Name=resource-id,Values=$EC2_INSTANCE_ID\" \"Name=key,Values=Name\" --region $EC2_REGION --output=text | cut -f5)\n            aws route53 change-resource-record-sets --hosted-zone-id ${HostedZoneId} --change-batch '{\n              \"Changes\": [\n                {\n                  \"Action\": \"UPSERT\",\n                  \"ResourceRecordSet\": {\n                    \"Name\": \"'$DNS_NAME'.swift.internal.\",\n                    \"Type\": \"A\",\n                    \"TTL\": 60,\n                    \"ResourceRecords\": [\n                      {\n                        \"Value\": \"'$PRIVATE_IP'\"\n                      }\n                    ]\n                  }\n                }\n              ]\n            }'\n\n            # Add the .swift.internal domain to the list of searchable domains\n            echo search swift.internal &gt;&gt; /etc/resolv.conf\n\n            # Amazon Linux specific hack to preserve the domain search config between reboots\n            echo 'prepend domain-search \"swift.internal\";' &gt;&gt; /etc/dhcp/dhclient.conf\n\n            ## Hostname\n            # Change hostname to the DNS NAME, which in turn is the name tag of the instance \n            hostnamectl set-hostname $DNS_NAME.swift.internal\n\n            # Amazon EC2 specific hack to preserve hostname between reboots\n            echo 'preserve_hostname: true' &gt;&gt; /etc/cloud/cloud.cfg\n\n\n            ## Attach the EBS volumes\n            # see: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-using-volumes.html\n            # home\n            aws ec2 attach-volume --region $EC2_REGION --instance-id $EC2_INSTANCE_ID --volume-id ${HomeVolumeId} --device /dev/sdh\n            while [ ! -e /dev/sdh ]; do \n              echo Waiting for Home EBS volume to attach\n              sleep 30\n            done\n\n            # docker\n            # Docker volume is not shared. Each instance has its own Docker volume \n\n\n            ## Format EBS volumes\n            # Check if formatted and if not, format using ext4\n            # home\n            device_fs_type=`file -sL /dev/sdh`\n            if [[ $device_fs_type != *\"ext4\"* ]]; then\n                mkfs --type ext4 /dev/sdh\n            fi\n\n            # docker\n            device_fs_type=`file -sL /dev/sdi`\n            if [[ $device_fs_type != *\"ext4\"* ]]; then\n                mkfs --type ext4 /dev/sdi\n            fi\n\n\n            ## Mount EBS file systems\n            # home\n            mkdir -p /ebs/home\n            echo '/dev/sdh /ebs/home ext4 defaults,nofail 0 2' | tee -a /etc/fstab\n\n            # docker\n            mkdir -p /ebs/docker\n            echo '/dev/sdi /ebs/docker ext4 defaults,nofail 0 2' | tee -a /etc/fstab\n\n            mount --all\n\n\n            ## Users\n            # add users\n            # runner\n            groupadd --gid 200000 runner \n            useradd --gid runner --uid 200000  runner\n\n            # worker\n            useradd --create-home --home-dir /ebs/home/worker worker\n\n\n            ## Install Software\n            yum update -y\n            yum install docker git jq htop -y\n\n\n            ## Docker config\n            #see: https://docs.docker.com/engine/security/userns-remap/\n\n            # - Use `/ebs/docker` as data-root (for containers and volumes)\n            # - Map container `root` user to host `runner` user             \n            cat &gt; /etc/docker/daemon.json &lt;&lt;EOF\n            {\n              \"data-root\": \"/ebs/docker\",\n              \"userns-remap\": \"runner\"\n            }            \n            EOF\n\n            # additional config needed for the Docker user namespace mapping\n            touch /etc/subuid /etc/subgid\n            echo \"runner:$(id -u runner):65536\" | sudo tee -a /etc/subuid\n            echo \"runner:$(id -g runner):65536\" | sudo tee -a /etc/subgid\n\n            # Enable Docker to run at boot and start it\n            systemctl enable docker\n            systemctl start docker\n\n            # add users to the docker group\n            usermod --append --groups docker ec2-user\n            usermod --append --groups docker worker\n\n\n            ## SSH\n\n            # enable ssh login for the worker account\n            user_home=/ebs/home/worker\n            if [ ! -f \"$user_home/.ssh/id_rsa\" ]; then\n              sudo -iu worker sh -c \"ssh-keygen -t rsa -f $user_home/.ssh/id_rsa -q -P ''\" \n              sudo -iu worker sh -c \"cat $user_home/.ssh/id_rsa.pub &gt; $user_home/.ssh/authorized_keys\"\n              sudo -iu worker sh -c \"chmod 700 $user_home/.ssh\"\n              sudo -iu worker sh -c \"chmod 600 $user_home/.ssh/authorized_keys\"\n            fi\n\n            # download and install docker compose (optional)\n            # platform=$(uname -s)-$(uname -m)\n            # wget https://github.com/docker/compose/releases/latest/download/docker-compose-$platform \n            # mv docker-compose-$platform /usr/local/bin/docker-compose\n            # chmod -v +x /usr/local/bin/docker-compose\n\n\n            ## Install AWS CLI v2\n            curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n            unzip awscliv2.zip\n            ./aws/install\n\n\n            # signal that we are done\n            /opt/aws/bin/cfn-signal -e $? --region ${AWS::Region} --stack ${AWS::StackName} --resource Instance \n    CreationPolicy:\n      ResourceSignal:\n        Timeout: PT15M\n\nOutputs:\n  InstanceId:\n    Description: ID of the launched instance\n    Value: !Ref Instance\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-4-manager-instance/#scripts","title":"Scripts","text":"<p>Add a script <code>deploy-ec2-manager.sh</code> and paste this code in it:</p> <pre><code>#!/usr/bin/env bash\n\n# switch to parent directory\nscript_path=`dirname ${BASH_SOURCE[0]}`\npushd $script_path/..\n\nsource config/names.sh\n\necho\necho \"Deploying $stack_ec2_manager stack via cloud-formation:\"\necho 'https://us-west-2.console.aws.amazon.com/cloudformation/home'\necho\n\nsubnet_id=$(aws ec2 describe-subnets --filters Name=tag:Name,Values=$subnet_pub_1 | jq -r '.Subnets[0].SubnetId')\nsecurity_group_id=$(aws ec2  describe-security-groups --filters Name=tag:Name,Values=$security_group_pub_1 | jq -r '.SecurityGroups[0].GroupId')\n\ninstance_profile=$(aws cloudformation describe-stacks --stack-name $stack_iam_manager | jq -r '.Stacks[0].Outputs[] | select(.OutputKey == \"InstanceProfile\") | .OutputValue')\n\nhosted_zone_id=$(aws cloudformation describe-stacks --stack-name $stack_vpc | jq -r '.Stacks[0].Outputs[] | select(.OutputKey == \"HostedZoneId\") | .OutputValue')\n\n# home volume is shared between manager and worker(s)\nhome_volume_id=$(aws cloudformation describe-stacks --stack-name $stack_ebs | jq -r '.Stacks[0].Outputs[] | select(.OutputKey == \"HomeVolumeId\") | .OutputValue')\n\nset -x\n\naws cloudformation deploy \\\n    --template-file ec2-manager/ec2-manager.yml \\\n    --stack-name $stack_ec2_manager \\\n    --parameter-overrides \\\n        KeyPair=$ec2_key_pair \\\n        SubnetId=$subnet_id \\\n        SecurityGroupId=$security_group_id \\\n        InstanceProfile=$instance_profile \\\n        HostedZoneId=$hosted_zone_id \\\n        HomeVolumeId=$home_volume_id\n\npopd\n</code></pre> <p>Let's also add a clean up script <code>rm-ec2-manager.sh</code>:</p> <pre><code>#!/usr/bin/env bash\n\n# switch to parent directory\nscript_path=`dirname ${BASH_SOURCE[0]}`\npushd $script_path/..\n\nsource config/names.sh\n\necho\necho \"Destroying $stack_ec2_manager stack via cloud-formation:\"\necho 'https://us-west-2.console.aws.amazon.com/cloudformation/home'\necho\n\nset -x\n\naws cloudformation delete-stack \\\n    --stack-name $stack_ec2_manager \n\naws cloudformation wait stack-delete-complete \\\n    --stack-name $stack_ec2_manager\n\npopd\n</code></pre> <p>Make the scripts executable:</p> <pre><code>chmod +x ec2-manager/deploy-ec2-manager.sh \nchmod +x ec2-manager/rm-ec2-manager.sh\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-4-manager-instance/#deploy","title":"Deploy","text":"<p>Finally let's run the \"deploy\" script to create the Manager instance:</p> <pre><code>./ec2-manager/deploy-ec2-manager.sh\n</code></pre> <p>You should see output similar to this:</p> <pre><code>Deploying swift-swarm-ec2-manager stack via cloud-formation:\nhttps://us-west-2.console.aws.amazon.com/cloudformation/home\n\n+ aws cloudformation deploy --template-file ec2-manager/ec2-manager.yml --stack-name swift-swarm-ec2-manager --parameter-overrides KeyPair=aws-ec2-key SubnetId=subnet-008f06da59b0f682a SecurityGroupId=sg-0668991ca731a2201 InstanceProfile=swift-swarm-iam-manager-InstanceProfile-qeqXudscgUtM HostedZoneId=Z07362313E0WMP6Y4DBYT HomeVolumeId=vol-08b4fb87713440e48\n\nWaiting for changeset to be created..\nWaiting for stack create/update to complete\nSuccessfully created/updated stack - swift-swarm-ec2-manager\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-4-manager-instance/#login","title":"Login","text":"<p>Create a directory <code>ssh</code> and in it a script named <code>ssh-manager.sh</code></p> <pre><code>mkdir -p ssh\ntouch ssh/ssh-manager.sh\nchmod +x ssh/ssh-manager.sh\nnano ssh/ssh-manager.sh\n</code></pre> <p>Copy and paste this code in the <code>ssh-manager.sh</code> file:</p> <pre><code>#!/usr/bin/env bash\n\n# switch to parent directory\nscript_path=`dirname ${BASH_SOURCE[0]}`\npushd $script_path/..\n\nsource config/names.sh\n\npopd\n\nec2_key=\"~/.ssh/aws-ec2-key\"\nec2_instance=$( aws cloudformation describe-stacks --stack-name $stack_ec2_manager | jq -r '.Stacks[0].Outputs[] | select(.OutputKey == \"InstanceId\") | .OutputValue' )\nec2_ip=$( aws ec2 describe-instances --instance-ids $ec2_instance | jq -r '.Reservations[0].Instances[0].PublicIpAddress' )\n\nssh -i $ec2_key ec2-user@$ec2_ip\n</code></pre> <p>You should be able to connect to the Manager machine via ssh now:</p> <pre><code>./ssh/ssh-manager.sh\n</code></pre> <p>At this point your project structure should look like this:</p> <pre><code>.\n\u251c\u2500\u2500 config\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 names.sh\n\u251c\u2500\u2500 ebs\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 deploy-ebs.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ebs.yml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 rm-ebs.sh\n\u251c\u2500\u2500 ec2-manager\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 deploy-ec2-manager.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ec2-manager.yml\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 rm-ec2-manager.sh\n\u251c\u2500\u2500 iam\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 deploy-iam-manager.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 deploy-iam-worker.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 iam-manager.yml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 iam-worker.yml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 rm-iam-manager.sh\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 rm-iam-worker.sh\n\u251c\u2500\u2500 ssh\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ssh-manager.sh\n\u2514\u2500\u2500 vpc\n    \u251c\u2500\u2500 deploy-vpc.sh\n    \u251c\u2500\u2500 rm-vpc.sh\n    \u2514\u2500\u2500 vpc.yml\n</code></pre> <p>Congratulations! </p> <p>We are done with <code>Step 4. Manager Instance</code>. </p> <p>Next step is: Step 5. Worker Launch Template</p>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-5-worker-launch-template/","title":"Deploy Docker Swarm on AWS EC2 via cloud-formation templates - Step 5 - Worker Launch Template","text":"<p>In this step we will create the a launch templat for the  EC2 Worker instances.</p> <p>This post is part of a thread that includes these steps:</p> <ol> <li>Network Setup</li> <li>Storage</li> <li>Roles</li> <li>Manager Instance </li> <li>Worker Launch Template (this post)</li> <li>Worker Instances</li> <li>Docker Swarm</li> <li>Cleanup</li> </ol>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-5-worker-launch-template/#worker-launch-template","title":"Worker Launch Template","text":"<p>Start in the project directory:</p> <pre><code>cd ~/swift-aws-ec2-swarm\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-5-worker-launch-template/#cloud-formation-template","title":"cloud-formation Template","text":"<p>Create a folder <code>ec2-worker-lt</code> and a <code>ec2-worker-lt.yml</code> file in it. </p> <pre><code>mkdir -p ec2-worker-lt\ntouch ec2-worker-lt/ec2-worker-lt.yml\nnano ec2-worker-lt/ec2-worker-lt.yml\n</code></pre> <p>Copy and paste this code into <code>ec2-worker-lt.yml</code>:</p> <pre><code>Description: Launch template for Docker Swarm worker instances\n\nParameters:\n  LatestAmiId:\n    Type: AWS::SSM::Parameter::Value&lt;AWS::EC2::Image::Id&gt;\n    Default: /aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-x86_64-gp2\n\n  HostedZoneId:\n    Type: AWS::Route53::HostedZone::Id\n    Description: ID of the Route53 HostedZone\n\n  HomeVolumeId:\n    Type: AWS::EC2::Volume::Id\n    Description: ID of the volume to be mounted as /home\n\nResources:\n  LaunchTemplate:\n    Type: AWS::EC2::LaunchTemplate\n    Properties:\n      LaunchTemplateData:\n        ImageId: !Ref LatestAmiId\n\n        BlockDeviceMappings: \n          # Docker volume\n          - DeviceName: /dev/sdi\n            Ebs: \n              Encrypted: true\n              DeleteOnTermination: true\n              VolumeSize: 100\n              VolumeType: gp2          \n\n        UserData:\n          Fn::Base64:\n            !Sub |\n              #!/bin/bash -x\n\n              # !!! DO NOT ENABLE THIS !!! Use in case of boot problems only\n              # usermod --password $(echo test123 | openssl passwd -1 -stdin) ec2-user\n\n              # see: https://aws.amazon.com/premiumsupport/knowledge-center/ec2-linux-log-user-data/\n              exec &gt; &gt;(tee /var/log/user-data.log|logger -t user-data -s 2&gt;/dev/console) 2&gt;&amp;1\n\n              EC2_INSTANCE_ID=$(ec2-metadata --instance-id | awk '{print $2}')\n              EC2_REGION=$(ec2-metadata --availability-zone | awk '{print $2}' | sed 's/.$//')\n\n              ## Timezone\n              # see: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/set-time.html#change_time_zone\n              timedatectl set-timezone America/Los_Angeles\n\n              ## DNS\n              PRIVATE_IP=$(curl -s http://169.254.169.254/latest/meta-data/local-ipv4)\n              DNS_NAME=$(aws ec2 describe-categories --filters \"Name=resource-id,Values=$EC2_INSTANCE_ID\" \"Name=key,Values=Name\" --region $EC2_REGION --output=text | cut -f5)\n              aws route53 change-resource-record-sets --hosted-zone-id ${HostedZoneId} --change-batch '{\n                \"Changes\": [\n                  {\n                    \"Action\": \"UPSERT\",\n                    \"ResourceRecordSet\": {\n                      \"Name\": \"'$DNS_NAME'.swift.internal.\",\n                      \"Type\": \"A\",\n                      \"TTL\": 60,\n                      \"ResourceRecords\": [\n                        {\n                          \"Value\": \"'$PRIVATE_IP'\"\n                        }\n                      ]\n                    }\n                  }\n                ]\n              }'\n\n              # Add the .swift.internal domain to the list of searchable domains\n              echo search swift.internal &gt;&gt; /etc/resolv.conf\n\n              # Amazon Linux specific hack to preserve the domain search config between reboots\n              echo 'prepend domain-search \"swift.internal\";' &gt;&gt; /etc/dhcp/dhclient.conf\n\n              ## Hostname\n              # Change hostname to the DNS NAME, which in turn is the name tag of the instance \n              hostnamectl set-hostname $DNS_NAME.swift.internal\n\n              # Amazon EC2 specific hack to preserve hostname between reboots\n              echo 'preserve_hostname: true' &gt;&gt; /etc/cloud/cloud.cfg\n\n\n              ## Attach the EBS volumes\n              # see: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-using-volumes.html\n\n              # Home\n              aws ec2 attach-volume --region $EC2_REGION --instance-id $EC2_INSTANCE_ID --volume-id ${HomeVolumeId} --device /dev/sdh\n              while [ ! -e /dev/sdh ]; do \n                echo Waiting for Home EBS volume to attach\n                sleep 30\n              done\n\n              # Docker\n              # Docker volume is already attached as /dev/sdi\n\n\n              ## Format EBS volumes\n              # Check if formatted and if not, format using ext4\n\n              # Home\n              # Home volume is shared between manager and worker nodes\n\n              # Docker\n              # Docker volume is not shared. Each instance has its own Docker volume \n              device_fs_type=`file -sL /dev/sdi`\n              if [[ $device_fs_type != *\"ext4\"* ]]; then\n                  mkfs --type ext4 /dev/sdi\n              fi              \n\n\n              ## Mount EBS file systems\n\n              # home\n              mkdir -p /ebs/home\n              echo '/dev/sdh /ebs/home ext4 defaults,nofail 0 2' | tee -a /etc/fstab\n\n              # docker\n              mkdir -p /ebs/docker\n              echo '/dev/sdi /ebs/docker ext4 defaults,nofail 0 2' | tee -a /etc/fstab\n\n              mount --all\n\n\n              ## Users\n\n              # add users\n              # runner\n              groupadd --gid 200000 runner \n              useradd --gid runner --uid 200000  runner\n\n              # worker\n              useradd --create-home --home-dir /ebs/home/worker worker\n\n              # install software\n              yum update -y\n              yum install docker git jq htop -y\n\n\n              ## Docker config\n              #see: https://docs.docker.com/engine/security/userns-remap/\n\n              # - Use `/ebs/docker` as data-root (for containers and volumes)\n              # - Map container `root` user to host `runner` user             \n              cat &gt; /etc/docker/daemon.json &lt;&lt;EOF\n              {\n                \"data-root\": \"/ebs/docker\",\n                \"userns-remap\": \"runner\"\n              }            \n              EOF\n\n              # additional config needed for the Docker user namespace mapping\n              touch /etc/subuid /etc/subgid\n              echo \"runner:$(id -u runner):65536\" | sudo tee -a /etc/subuid\n              echo \"runner:$(id -g runner):65536\" | sudo tee -a /etc/subgid\n\n              # Enable Docker to run at boot and start it\n              systemctl enable docker\n              systemctl start docker\n\n              # add users to the docker group\n              usermod --append --groups docker ec2-user\n              usermod --append --groups docker worker\n\n              # download and install docker compose (optional)\n              # platform=$(uname -s)-$(uname -m)\n              # wget https://github.com/docker/compose/releases/latest/download/docker-compose-$platform \n              # mv docker-compose-$platform /usr/local/bin/docker-compose\n              # chmod -v +x /usr/local/bin/docker-compose \n\n              ## Install AWS CLI v2\n              curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n              unzip awscliv2.zip\n              ./aws/install\n\nOutputs:\n  LaunchTemplateId:\n    Description: Launch template ID\n    Value: !Ref LaunchTemplate\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-5-worker-launch-template/#scripts","title":"Scripts","text":"<p>Add a script <code>deploy-ec2-worker-lt.sh</code> and paste this code in it:</p> <pre><code>#!/usr/bin/env bash\n\n# switch to parent directory\nscript_path=`dirname ${BASH_SOURCE[0]}`\npushd $script_path/..\n\nsource config/names.sh\n\necho\necho \"Deploying $stack_ec2_worker_lt stack via cloud-formation:\"\necho 'https://us-west-2.console.aws.amazon.com/cloudformation/home'\necho\n\nhosted_zone_id=$(aws cloudformation describe-stacks --stack-name $stack_vpc | jq -r '.Stacks[0].Outputs[] | select(.OutputKey == \"HostedZoneId\") | .OutputValue')\n\n# home volume is shared between manager and worker(s)\nhome_volume_id=$(aws cloudformation describe-stacks --stack-name $stack_ebs | jq -r '.Stacks[0].Outputs[] | select(.OutputKey == \"HomeVolumeId\") | .OutputValue')\n\nset -x\n\naws cloudformation deploy \\\n    --template-file ec2-worker-lt/ec2-worker-lt.yml \\\n    --stack-name $stack_ec2_worker_lt \\\n    --parameter-overrides \\\n        HostedZoneId=$hosted_zone_id \\\n        HomeVolumeId=$home_volume_id\n\npopd\n</code></pre> <p>Let's also add a clean up script <code>rm-ec2-worker-lt.sh</code>:</p> <pre><code>#!/usr/bin/env bash\n\n# switch to parent directory\nscript_path=`dirname ${BASH_SOURCE[0]}`\npushd $script_path/..\n\nsource config/names.sh\n\necho\necho \"Destroying $stack_ec2_worker_lt stack via cloud-formation:\"\necho 'https://us-west-2.console.aws.amazon.com/cloudformation/home'\necho\n\nset -x\n\naws cloudformation delete-stack \\\n    --stack-name $stack_ec2_worker_lt\n\naws cloudformation wait stack-delete-complete \\\n    --stack-name $stack_ec2_worker_lt\n\npopd\n</code></pre> <p>Make the scripts executable:</p> <pre><code>chmod +x ec2-worker-lt/deploy-ec2-worker-lt.sh \nchmod +x ec2-worker-lt/rm-ec2-worker-lt.sh\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-5-worker-launch-template/#deploy","title":"Deploy","text":"<p>Finally let's run the \"deploy\" script to create the Worker launch template:</p> <pre><code>./ec2-worker-lt/deploy-ec2-worker-lt.sh\n</code></pre> <p>You should see output similar to this:</p> <pre><code>Deploying swift-swarm-ec2-worker-lt stack via cloud-formation:\nhttps://us-west-2.console.aws.amazon.com/cloudformation/home\n\n+ aws cloudformation deploy --profile swift --template-file ec2-worker/ec2-worker-lt.yml --stack-name swift-swarm-ec2-worker-lt --parameter-overrides HostedZoneId=Z07362313E0WMP6Y4DBYT HomeVolumeId=vol-08b4fb87713440e48\n\nWaiting for changeset to be created..\nWaiting for stack create/update to complete\nSuccessfully created/updated stack - swift-swarm-ec2-worker-lt\n</code></pre> <p>At this point your project structure should look like this:</p> <pre><code>.\n\u251c\u2500\u2500 config\n\u2502   \u2514\u2500\u2500 names.sh\n\u251c\u2500\u2500 ebs\n\u2502   \u251c\u2500\u2500 deploy-ebs.sh\n\u2502   \u251c\u2500\u2500 ebs.yml\n\u2502   \u2514\u2500\u2500 rm-ebs.sh\n\u251c\u2500\u2500 ec2-manager\n\u2502   \u251c\u2500\u2500 deploy-ec2-manager.sh\n\u2502   \u251c\u2500\u2500 ec2-manager.yml\n\u2502   \u2514\u2500\u2500 rm-ec2-manager.sh\n\u251c\u2500\u2500 ec2-worker-lt\n\u2502   \u251c\u2500\u2500 deploy-ec2-worker-lt.sh\n\u2502   \u251c\u2500\u2500 ec2-worker-lt.yml\n\u2502   \u2514\u2500\u2500 rm-ec2-worker-lt.sh\n\u251c\u2500\u2500 iam\n\u2502   \u251c\u2500\u2500 deploy-iam-manager.sh\n\u2502   \u251c\u2500\u2500 deploy-iam-worker.sh\n\u2502   \u251c\u2500\u2500 iam-manager.yml\n\u2502   \u251c\u2500\u2500 iam-worker.yml\n\u2502   \u251c\u2500\u2500 rm-iam-manager.sh\n\u2502   \u2514\u2500\u2500 rm-iam-worker.sh\n\u251c\u2500\u2500 ssh\n\u2502   \u2514\u2500\u2500 ssh-manager.sh\n\u2514\u2500\u2500 vpc\n    \u251c\u2500\u2500 deploy-vpc.sh\n    \u251c\u2500\u2500 rm-vpc.sh\n    \u2514\u2500\u2500 vpc.yml\n</code></pre> <p>Congratulations! </p> <p>We are done with <code>Step 5. Worker Launch Template</code>. </p> <p>Next step is: Step 6. Worker Instances</p>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-6-worker-instances/","title":"Deploy Docker Swarm on AWS EC2 via cloud-formation templates - Step 6 - Worker Instances","text":"<p>In this step we will launch the Worker EC2 instances.</p> <p>This post is part of a thread that includes these steps:</p> <ol> <li>Network Setup</li> <li>Storage</li> <li>Roles</li> <li>Manager Instance </li> <li>Worker Launch Template</li> <li>Worker Instances (this post)</li> <li>Docker Swarm</li> <li>Cleanup</li> </ol>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-6-worker-instances/#worker-instances-aws-ec2","title":"Worker Instances (AWS EC2)","text":"<p>Start in the project directory:</p> <pre><code>cd ~/swift-aws-ec2-swarm\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-6-worker-instances/#cloud-formation-template","title":"cloud-formation Template","text":"<p>Create a folder <code>ec2-worker</code> and a <code>ec2-worker.yml</code> file in it. </p> <pre><code>mkdir -p ec2-worker\ntouch ec2-worker/ec2-worker.yml\nnano ec2-worker/ec2-worker.yml\n</code></pre> <p>Copy and paste this code into <code>ec2-worker.yml</code>:</p> <pre><code>Description: Launch Docker Swarm Worker instances\n\nParameters:\n  KeyPair:\n    Type: AWS::EC2::KeyPair::KeyName\n    Description: Key pair that will be used to launch instances\n\n  SubnetId:\n    Type: AWS::EC2::Subnet::Id\n    Description: Subnet in the VPC where the instance will be launched\n\n  SecurityGroupId:\n    Type: AWS::EC2::SecurityGroup::Id\n    Description: Security group for the instance\n\n  InstanceProfile:\n    Type: String\n    Description: Instance profile to use for the instance\n\n  InstanceType:\n    Type: String\n    Default: c5.large\n    Description: Instance type to use for the instance\n\n  LaunchTemplateId:\n    Type: String\n    Description: The ID of the launch template.\n\nResources:\n  Worker1Instance:\n    Type: 'AWS::EC2::Instance'\n    Properties:\n      KeyName: !Ref KeyPair\n\n      SubnetId: !Ref SubnetId\n      SecurityGroupIds:\n        - !Ref SecurityGroupId      \n\n      IamInstanceProfile: !Ref InstanceProfile\n\n      InstanceType: !Ref InstanceType\n\n      LaunchTemplate:\n        LaunchTemplateId: !Ref LaunchTemplateId\n        Version: \"1\"\n\n      # categories:\n        - Key: \"Name\"\n          Value: \"worker-1\"\n\n  Worker2Instance:\n    Type: 'AWS::EC2::Instance'\n    Properties:\n    Properties:\n      KeyName: !Ref KeyPair\n\n      SubnetId: !Ref SubnetId\n      SecurityGroupIds:\n        - !Ref SecurityGroupId      \n\n      IamInstanceProfile: !Ref InstanceProfile\n\n      InstanceType: !Ref InstanceType\n\n      LaunchTemplate:\n        LaunchTemplateId: !Ref LaunchTemplateId\n        Version: \"1\"\n\n      # categories:\n        - Key: \"Name\"\n          Value: \"worker-2\"\n\nOutputs:\n  Worker1InstanceId:\n    Description: ID of the launched worker-1 instance\n    Value: !Ref Worker1Instance\n  Worker2InstanceId:\n    Description: ID of the launched worker-2 instance\n    Value: !Ref Worker2Instance\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-6-worker-instances/#scripts","title":"Scripts","text":"<p>Add a script <code>deploy-ec2-worker.sh</code> and paste this code in it:</p> <pre><code>#!/usr/bin/env bash\n\n# switch to parent directory\nscript_path=`dirname ${BASH_SOURCE[0]}`\npushd $script_path/..\n\nsource config/names.sh\n\necho\necho \"Deploying $stack_ec2_worker stack via cloud-formation:\"\necho 'https://us-west-2.console.aws.amazon.com/cloudformation/home'\necho\n\nsubnet_id=$(aws ec2 describe-subnets --filters Name=tag:Name,Values=$subnet_priv_1 | jq -r '.Subnets[0].SubnetId')\nsecurity_group_id=$(aws ec2  describe-security-groups --filters Name=tag:Name,Values=$security_group_priv_1 | jq -r '.SecurityGroups[0].GroupId')\n\ninstance_profile=$(aws cloudformation describe-stacks --stack-name $stack_iam_worker | jq -r '.Stacks[0].Outputs[] | select(.OutputKey == \"InstanceProfile\") | .OutputValue')\n\nlaunch_template_id=$(aws cloudformation describe-stacks --stack-name $stack_ec2_worker_lt | jq -r '.Stacks[0].Outputs[] | select(.OutputKey == \"LaunchTemplateId\") | .OutputValue')\n\nset -x\n\naws cloudformation deploy \\\n    --template-file ec2-worker/ec2-worker.yml \\\n    --stack-name $stack_ec2_worker \\\n    --parameter-overrides \\\n        KeyPair=$ec2_key_pair \\\n        SubnetId=$subnet_id \\\n        SecurityGroupId=$security_group_id \\\n        InstanceProfile=$instance_profile \\\n        LaunchTemplateId=$launch_template_id\n\npopd\n</code></pre> <p>Let's also add a clean up script <code>rm-ec2-worker.sh</code>:</p> <pre><code>#!/usr/bin/env bash\n\n# switch to parent directory\nscript_path=`dirname ${BASH_SOURCE[0]}`\npushd $script_path/..\n\nsource config/names.sh\necho\necho \"Destroying $stack_ec2_worker stack via cloud-formation:\"\necho 'https://us-west-2.console.aws.amazon.com/cloudformation/home'\necho\n\nset -x\n\naws cloudformation delete-stack \\\n    --stack-name $stack_ec2_worker\n\naws cloudformation wait stack-delete-complete \\\n    --stack-name $stack_ec2_worker\n\npopd\n</code></pre> <p>Make the scripts executable:</p> <pre><code>chmod +x ec2-worker/deploy-ec2-worker.sh \nchmod +x ec2-worker/rm-ec2-worker.sh\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-6-worker-instances/#deploy","title":"Deploy","text":"<p>Finally let's run the \"deploy\" script to create the Worker launch template:</p> <pre><code>./ec2-worker/deploy-ec2-worker.sh\n</code></pre> <p>You should see output similar to this:</p> <pre><code>Deploying swift-swarm-ec2-worker stack via cloud-formation:\nhttps://us-west-2.console.aws.amazon.com/cloudformation/home\n\n+ aws cloudformation deploy --profile swift --template-file ec2-worker/ec2-worker.yml --stack-name swift-swarm-ec2-worker --parameter-overrides KeyPair=aws-ec2-key SubnetId=subnet-0b019a9e1c3f56adb SecurityGroupId=sg-07c3b321f35b08b18 InstanceProfile=swift-swarm-iam-worker-InstanceProfile-qF4QqiJApx6p LaunchTemplateId=lt-06f34a0e6c33a503a\n\nWaiting for changeset to be created..\nWaiting for stack create/update to complete\nSuccessfully created/updated stack - swift-swarm-ec2-worker\n</code></pre> <p>At this point your project structure should look like this:</p> <pre><code>.\n\u251c\u2500\u2500 config\n\u2502   \u2514\u2500\u2500 names.sh\n\u251c\u2500\u2500 ebs\n\u2502   \u251c\u2500\u2500 deploy-ebs.sh\n\u2502   \u251c\u2500\u2500 ebs.yml\n\u2502   \u2514\u2500\u2500 rm-ebs.sh\n\u251c\u2500\u2500 ec2-manager\n\u2502   \u251c\u2500\u2500 deploy-ec2-manager.sh\n\u2502   \u251c\u2500\u2500 ec2-manager.yml\n\u2502   \u2514\u2500\u2500 rm-ec2-manager.sh\n\u251c\u2500\u2500 ec2-worker\n\u2502   \u251c\u2500\u2500 deploy-ec2-worker.sh\n\u2502   \u251c\u2500\u2500 ec2-worker.yml\n\u2502   \u2514\u2500\u2500 rm-ec2-worker.sh\n\u251c\u2500\u2500 ec2-worker-lt\n\u2502   \u251c\u2500\u2500 deploy-ec2-worker-lt.sh\n\u2502   \u251c\u2500\u2500 ec2-worker-lt.yml\n\u2502   \u2514\u2500\u2500 rm-ec2-worker-lt.sh\n\u251c\u2500\u2500 iam\n\u2502   \u251c\u2500\u2500 deploy-iam-manager.sh\n\u2502   \u251c\u2500\u2500 deploy-iam-worker.sh\n\u2502   \u251c\u2500\u2500 iam-manager.yml\n\u2502   \u251c\u2500\u2500 iam-worker.yml\n\u2502   \u251c\u2500\u2500 rm-iam-manager.sh\n\u2502   \u2514\u2500\u2500 rm-iam-worker.sh\n\u251c\u2500\u2500 ssh\n\u2502   \u2514\u2500\u2500 ssh-manager.sh\n\u2514\u2500\u2500 vpc\n    \u251c\u2500\u2500 deploy-vpc.sh\n    \u251c\u2500\u2500 rm-vpc.sh\n    \u2514\u2500\u2500 vpc.yml\n</code></pre> <p>Congratulations! </p> <p>We are done with <code>Step 6. Worker Instances</code>. </p> <p>Next step is: Step 7. Docker Swarm</p>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-7-docker-swarm/","title":"Deploy Docker Swarm on AWS EC2 via cloud-formation templates - Step 7 - Docker Swarm","text":"<p>In this step we will create a Docker Swarm cluster.</p> <p>This post is part of a thread that includes these steps:</p> <ol> <li>Network Setup</li> <li>Storage</li> <li>Roles</li> <li>Manager Instance </li> <li>Worker Launch Template</li> <li>Worker Instances</li> <li>Docker Swarm (this post)</li> <li>Cleanup</li> </ol>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-7-docker-swarm/#docker-swarm","title":"Docker Swarm","text":""},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-7-docker-swarm/#manager-machine","title":"Manager Machine","text":"<p>IMPORTANT: On the manager machine port 2377 (Docker Swarm)  must be open / accessible from other nodes in order for them to be able to join the swarm</p> <p>We are using Docker Swarm. At least one machine should be designated as a \"manager\". The \"manager\" machine is where all cluster managment operations will be done from, including also all the stack deployments.</p> <p>The manager machine on AWS is named  <code>manager</code>.</p>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-7-docker-swarm/#login-to-manager-machine","title":"Login to manager machine","text":"<pre><code>./ssh/ssh-manager.sh\n</code></pre> <p>Switch user to the <code>worker</code> user:</p> <pre><code>sudo su - worker\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-7-docker-swarm/#clean-slate","title":"Clean Slate","text":"<p>It is recommended to start from clean Docker installation.</p> <p>Warning: This will destroy all your images and containers. There is no way to restore them!</p> <pre><code>docker stop $(docker ps --all --quiet)\ndocker rm $(docker ps --all --quiet)\ndocker rmi $(docker images --quiet)\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-7-docker-swarm/#docker-swarm_1","title":"Docker Swarm","text":""},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-7-docker-swarm/#init","title":"Init","text":"<p>Initialize Docker Swarm. This will make the machine Swarm manager:</p> <pre><code>export dev=eth0\nexport host_ip=`ip -4 -o addr show $dev | perl -lane 'print $F[3]' | cut -d/ -f1`\ndocker swarm init --advertise-addr $host_ip --default-addr-pool 192.168.0.0/16\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-7-docker-swarm/#manager-node","title":"Manager Node","text":"<p>The node on which we ran  <code>docker swarm init</code> is now the manager node. The manager node is also the first worker node.  </p>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-7-docker-swarm/#worker-nodes","title":"Worker Nodes","text":"<p>To add another worker to the swarm, run this and follow the instructions: </p> <pre><code>docker swarm join-token worker\n</code></pre> <p>To remove node from the swarm, login to the node and run:</p> <pre><code>docker swarm leave\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-7-docker-swarm/#pssh","title":"pssh","text":"<pre><code>mkdir -p ~/nodes\ncd ~/nodes\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-7-docker-swarm/#install-parallel-ssh","title":"Install parallel-ssh","text":"<pre><code>cd ~/nodes\ngit clone https://github.com/nplanel/parallel-ssh\ncd parallel-ssh\npython3 setup.py install --user\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-7-docker-swarm/#install-pssh","title":"Install pssh","text":"<pre><code>cd ~/nodes\ngit clone https://github.com/lilydjwg/pssh\ncd pssh\npip3 install --user .\n</code></pre> <p>Simple test:</p> <pre><code>pssh \\\n  --host=worker-1.swift.internal --option=\"StrictHostKeyChecking=no\" \\\n  --user=$USER --inline 'uptime'\n</code></pre> <p>Test that you can execute a simple command on all hosts:</p> <pre><code>cd ~/nodes\n\n# for all nodes\nprintf \"%s\\n\" worker-{1..2} &gt; hosts\n</code></pre> <pre><code>pssh \\\n  --hosts=$HOME/nodes/hosts --option=\"StrictHostKeyChecking=no\" \\\n  --user=$USER 'echo hi'\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-7-docker-swarm/#add-nodes-to-swarm","title":"Add Nodes to Swarm","text":"<p>Run this on the manager machine. Copy the join command from the output:</p> <pre><code>docker swarm join-token worker\n</code></pre> <p>Paste the join command which should look similar to this:</p> <pre><code>docker swarm join --token &lt;very-long-token&gt; &lt;ip-address&gt;:2377\n</code></pre> <p>Use <code>pssh</code> (parallel ssh) to execute the join command on large number of nodes: </p> <pre><code>pssh --hosts=$HOME/nodes/hosts --inline \\\n'docker swarm join --token &lt;very-long-token&gt; &lt;ip-address&gt;:2377'    \n</code></pre> <p>Example (but note that your token will be different):</p> <pre><code>pssh --hosts=$HOME/nodes/hosts --option=\"StrictHostKeyChecking=no\" --inline \\\n'docker swarm join --token SWMTKN-1-0nvgk6xtg0lcdcrb7a4mow6978g5tftb4wu5big52bbcpajq82-bq2j7uh6kos1s192h42a853so 10.0.10.175:2377'\n</code></pre> <p>Verify:</p> <pre><code>docker node ls\n</code></pre> <p>Congratulations! </p> <p>We are done with <code>Step 7. Docker Swarm</code>. </p> <p>Next step is: Step 8. Cleanup</p>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/","title":"Deploy Docker Swarm on AWS EC2 via cloud-formation templates - Step 8 - Cleanup","text":"<p>In this step we cleanup the resources that we creater for the Docker Swarm cluster on EC2.</p> <p>This post is part of a thread that includes these steps:</p> <ol> <li>Network Setup</li> <li>Storage</li> <li>Roles</li> <li>Manager Instance </li> <li>Worker Launch Template</li> <li>Worker Instances</li> <li>Docker Swarm</li> <li>Cleanup (this post)</li> </ol>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#cleanup","title":"Cleanup","text":""},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#docker-swarm","title":"Docker Swarm","text":""},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#login-to-manager-machine","title":"Login to manager machine","text":"<pre><code>./ssh/ssh-manager.sh\n</code></pre> <p>Switch user to the <code>worker</code> user:</p> <pre><code>sudo su - worker\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#remove-all-nodes-from-swarm","title":"Remove all nodes from Swarm","text":"<pre><code>pssh --hosts=$HOME/nodes/hosts --inline 'docker swarm leave'\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#destroy-swarm","title":"Destroy Swarm","text":"<p>On manager machine:</p> <pre><code>docker swarm leave --force \n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#clean-up-dangling-networks","title":"Clean up dangling networks","text":"<p>After destroying the Swarm make sure that you do not have dangling networks <code>ingress</code> and <code>docker_gwbridge</code>:</p> <pre><code>docker network ls\n</code></pre> <p>If you see <code>ingress</code> or <code>docker_gwbridge</code>, force remove them:</p> <pre><code>docker network disconnect --force docker_gwbridge\ndocker network rm docker_gwbridge\n</code></pre> <pre><code>docker network disconnect --force ingress\ndocker network rm ingress\n</code></pre> <p>Also you have to do the same for all nodes:</p> <pre><code>pssh --hosts=$HOME/nodes/hosts --inline 'docker network rm docker_gwbridge'\npssh --hosts=$HOME/nodes/hosts --inline 'docker network rm ingress'\n</code></pre> <p>Remove <code>swift_default</code> network:</p> <pre><code>docker network rm swift_default\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#docker-cleanup","title":"Docker Cleanup","text":"<p>These commands will remove all stopped containers and all images that do not have a running container on all nodes: </p> <pre><code># stop and femove containers\npssh --timeout 300 --hosts=$HOME/nodes/hosts --inline \\\n  'docker container prune --force'\n\n# delete unused images\npssh --timeout 300 --hosts=$HOME/nodes/hosts --inline \\\n  'docker image prune --all --force'\n\n# check root file system\npssh --timeout 300 --hosts=$HOME/nodes/hosts --inline \\\n  'df --human-readable /ebs/docker'  \n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#route-53-cleanup-script","title":"Route 53 Cleanup Script","text":"<p>Start in the project directory:</p> <pre><code>cd ~/swift-aws-ec2-swarm\n</code></pre> <p>Create a folder <code>route53</code> and a <code>route53-delete-record.sh</code> file in it. </p> <pre><code>mkdir -p route53\ntouch route53/route53-delete-record.sh\nnano route53/route53-delete-record.sh\n</code></pre> <p>Copy and paste this code into <code>route53-delete-record.sh</code>:</p> <pre><code>#!/usr/bin/env bash\n\n# =============================================================================================================\n# Usage:\n#   ./route53-delete-record.sh [HostedZoneName] [Hostname] [Type]\n#\n# Example:\n#   ./route53-delete-record.sh example.org dummy.example.org\n#   ./route53-delete-record.sh example.org dummy.example.org TXT\n#   ./route53-delete-record.sh example.org dummy.example.org txt\n#   ./route53-delete-record.sh example.org dummy.example.org CNAME\n# =============================================================================================================\n\n# output coloring\nRED=$(tput setaf 1)\nGREEN=$(tput setaf 2)\nYELLOW=$(tput setaf 3)\nCLEAR=$(tput sgr0)\n\n# put your value here\n# note that jq can work with env var\nHOSTED_ZONE=${1:-example.org}\nDNS_NAME=${2:-test.example.org}\nDNS_TYPE=${3:-A}\n\n[[ -z \"$HOSTED_ZONE\" ]] &amp;&amp; HOSTED_ZONE=example.org\n\n# add . to the end\nDNS_NAME=\"$DNS_NAME.\"\n\n# capitalize\nDNS_TYPE=${DNS_TYPE^^}\n\necho Deleting record: \\'$DNS_TYPE\\' \\'$DNS_NAME\\' from hosted zone \\'$HOSTED_ZONE\\' ... \n\n# find Zone ID\nZONE_ID=$(aws route53 list-hosted-zones-by-name --dns-name $HOSTED_ZONE --output json \\\n  | jq .HostedZones[].Id --raw-output \\\n  | awk -F / '{print $3}')\n\nif [[ -z \"$ZONE_ID\" ]]; then\n  echo ${RED}$HOSTED_ZONE hosted zone not found!$CLEAR\n  exit 1\nfi\n\necho Zone ID: $YELLOW$ZONE_ID$CLEAR\necho\n\n# find resource record set\nRECORD_SETS=$(aws route53 list-resource-record-sets --hosted-zone-id=$ZONE_ID --output json \\\n  | jq '.ResourceRecordSets[] | select ((.Name == '\\\"$DNS_NAME\\\"') and (.Type=='\\\"$DNS_TYPE\\\"'))')\n\nif [[ -z \"$RECORD_SETS\" ]]; then\n  echo ${RED}$DNS_NAME $DNS_TYPE record not found!$CLEAR\n  exit 1\nfi\n\necho Resource Record Sets:\njq &lt;&lt;&lt; \"$RECORD_SETS\"\necho\n\n# prepare the change batch value\nCHANGE_BATCH=$(cat &lt;&lt; EOF\n{\n    \"Comment\": \"delete this record\",\n    \"Changes\": [\n        {\n            \"Action\": \"DELETE\",\n            \"ResourceRecordSet\":\n              $RECORD_SETS\n\n        }\n    ]\n}\nEOF\n)\n\necho Change batch:\njq &lt;&lt;&lt; \"$CHANGE_BATCH\"\necho\n\n# perform the deletion\naws route53 change-resource-record-sets --hosted-zone-id=$ZONE_ID --change-batch \"$CHANGE_BATCH\"\n</code></pre> <p>Make the script executable:</p> <pre><code>chmod +x route53/route53-delete-record.sh\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#delete-aws-resources","title":"Delete AWS resources","text":""},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#instances","title":"Instances","text":""},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#worker","title":"Worker","text":"<pre><code>./ec2-worker/rm-ec2-worker.sh\n./ec2-worker-lt/rm-ec2-worker-lt.sh\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#manager","title":"Manager","text":"<pre><code>./ec2-manager/rm-ec2-manager.sh\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#iam-roles-instance-profiles","title":"IAM Roles / Instance Profiles","text":""},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#worker_1","title":"Worker","text":"<pre><code>./iam/rm-iam-worker.sh\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#manager_1","title":"Manager","text":"<pre><code>./iam/rm-iam-manager.sh\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#elastic-block-storage-ebs","title":"Elastic Block Storage (EBS)","text":"<pre><code>./ebs/rm-ebs.sh\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#route-53","title":"Route 53","text":"<pre><code>./route53/route53-delete-record.sh swift.internal manager.swift.internal\n\n./route53/route53-delete-record.sh swift.internal worker-1.swift.internal\n./route53/route53-delete-record.sh swift.internal worker-2.swift.internal\n</code></pre>"},{"location":"deploy-docker-swarm-aws-ec2-cloudformation-step-8-cleanup/#vpc","title":"VPC","text":"<pre><code>./vpc/rm-vpc.sh\n</code></pre> <p>Congratulations! </p> <p>We are done with <code>Step 8. Cleanup</code>. This is the final step of this series. </p> <p>Here are all the steps again for reference:</p> <ol> <li>Network Setup</li> <li>Storage</li> <li>Roles</li> <li>Manager Instance </li> <li>Worker Launch Template</li> <li>Worker Instances</li> <li>Docker Swarm</li> <li>Cleanup (this post)</li> </ol>"},{"location":"setup-podman-macos/","title":"Setup Podman on macOS","text":"<p>Podman is a utility that can be used to create and maintain containers. This post will teach you how to set up Podman on macOS and perform some basic commands.</p>"},{"location":"setup-podman-macos/#preparation","title":"Preparation","text":""},{"location":"setup-podman-macos/#homebrew","title":"Homebrew","text":"<p>Install Homebrew:</p> <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre>"},{"location":"setup-podman-macos/#bash-5","title":"bash 5","text":"<p>Install via Homebrew:</p> <pre><code>brew install bash\n</code></pre>"},{"location":"setup-podman-macos/#podman","title":"Podman","text":"<p>Install via Homebrew:</p> <pre><code>brew install podman\n</code></pre>"},{"location":"setup-podman-macos/#podman-machine","title":"Podman Machine","text":"<p>Create and start your first Podman machine (2 CPUs, 100GB disk, 4GB memory). Podman machines are backed by QEMU. This will become the default Podman machine:</p> <pre><code>podman machine init --cpus 2 --disk-size 100 --memory 4096\n</code></pre> <p>List all machines:</p> <pre><code>podman machine ls\n</code></pre> <pre><code>NAME                     VM TYPE     CREATED             LAST UP             CPUS        MEMORY      DISK SIZE\npodman-machine-default*  qemu        About a minute ago  About a minute ago  2           4.295GB     107.4GB\n</code></pre> <p>Start the default machine:</p> <pre><code>podman machine start\n</code></pre> <p>Verify the installation:</p> <pre><code>podman info\n</code></pre> <p>The machine will be configured in rootless mode. If your containers require root permissions (e.g. ports &lt; 1024), or if you run into compatibility issues with non-podman clients, you can switch using the following command: </p> <pre><code>podman machine set --rootful\n</code></pre>"},{"location":"setup-podman-macos/#test","title":"Test","text":"<p>Run the <code>Hello World</code> container:</p> <pre><code>podman run hello-world\n</code></pre>"},{"location":"setup-podman-macos/#podman-desktop","title":"Podman Desktop","text":"<p>To start a podman machine automatically at login, also install the Podman Desktop:</p> <pre><code>brew install --cask podman-desktop\n</code></pre>"},{"location":"run-mongodb-with-podman/","title":"Run MongoDB with Podman","text":"<p>Before you start install Podman.</p>"},{"location":"run-mongodb-with-podman/#set-machine-to-rootful","title":"Set machine to <code>rootful</code>","text":"<pre><code>podman machine stop\npodman machine set --rootful\npodman machine start\n</code></pre>"},{"location":"run-mongodb-with-podman/#create-a-data-directory","title":"Create a data directory","text":"<pre><code>rm -rf ~/podman/mongo/data/db\nmkdir -p ~/podman/mongo/data/db\nchmod -R a+wxr ~/podman\n</code></pre>"},{"location":"run-mongodb-with-podman/#setup-mongodb-authentication","title":"Setup MongoDB Authentication","text":"<p>First run the MongoDb container without authentication:</p> <pre><code>podman run \\\n    --detach \\\n    --tty \\\n    --user $(id --user):$(id --group) \\\n    --userns keep-id \\\n    --name mongo-dev \\\n    --publish 27017:27017 \\\n    --volume ~/podman/mongo/data/db:/data/db \\\n    mongo\n</code></pre> <p>Start a shell in the container:</p> <pre><code>podman exec -it mongo-dev bash\n</code></pre> <p>In the container:</p> <pre><code>mongosh\n\n# in mongo shell now\nuse admin\ndb.createUser({user:\"test\", pwd:\"test\", roles:[{role:\"root\", db:\"admin\"}]})\nexit\n\nexit\n</code></pre>"},{"location":"run-mongodb-with-podman/#restart-mongodb-with-authentication","title":"Restart MongoDB with Authentication","text":"<p>Stop and remove the container:</p> <pre><code>podman stop mongo-dev\npodman rm mongo-dev\n</code></pre> <p>Start the container with authentication:</p> <pre><code>podman run \\\n    --detach \\\n    --tty \\\n    --user $(id --user):$(id --group) \\\n    --name mongo-dev \\\n    --userns keep-id \\\n    --publish 27017:27017 \\\n    --volume ~/podman/mongo/data/db:/data/db \\\n    mongo --auth\n</code></pre>"},{"location":"configure-ruby-environment-windows/","title":"Configure Ruby Environment on Windows","text":"<p>This is a simple guide for configuring a Ruby 2 environment on Windows 11. All scripts are PowerShell.</p>"},{"location":"configure-ruby-environment-windows/#powershell","title":"PowerShell","text":"<p>This will allow you to execute PowerShell scripts locally on your machine. In PowerShell as Administrator:</p> <pre><code>Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope LocalMachine\n</code></pre>"},{"location":"configure-ruby-environment-windows/#chocolatey","title":"Chocolatey","text":"<p>In PowerShell as Administrator:</p> <pre><code>Set-ExecutionPolicy AllSigned\nSet-ExecutionPolicy Bypass -Scope Process -Force\niex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))\n</code></pre> <p>Close and reopen PowerShell after that.</p>"},{"location":"configure-ruby-environment-windows/#set-cache-directory","title":"Set cache directory","text":"<p>In PowerShell as Administrator:</p> <pre><code>choco config set cacheLocation C:/ChocoCache\n</code></pre>"},{"location":"configure-ruby-environment-windows/#upgrade","title":"Upgrade","text":"<pre><code>choco upgrade chocolatey\n</code></pre>"},{"location":"configure-ruby-environment-windows/#ruby","title":"Ruby","text":"<p>In PowerShell as Administrator:</p> <pre><code>choco install ruby -version 2.7.2.1 -m\n</code></pre>"},{"location":"configure-ruby-environment-windows/#ruby-devkit-20","title":"Ruby DevKit (2.0+)","text":""},{"location":"configure-ruby-environment-windows/#install","title":"Install","text":"<p>Open PowerShell as Administrator and run the following command:</p> <pre><code>choco install ruby2.devkit\n</code></pre> <p>This will install Ruby DevKit 2.0+ and its dependencies- in <code>C:\\tools\\DevKit2</code>.  </p>"},{"location":"configure-ruby-environment-windows/#configure","title":"Configure","text":"<p>Open <code>C:\\tools\\DevKit2\\config.yml</code>and add <code>C:\\tools\\ruby27</code> path at the end. The complete <code>config.yml</code> should look like this:</p> <pre><code># This configuration file contains the absolute path locations of all\n# installed Rubies to be enhanced to work with the DevKit. This config\n# file is generated by the 'ruby dk.rb init' step and may be modified\n# before running the 'ruby dk.rb install' step. To include any installed\n# Rubies that were not automagically discovered, simply add a line below\n# the triple hyphens with the absolute path to the Ruby root directory.\n#\n# Example:\n#\n# ---\n# - C:/ruby19trunk\n# - C:/ruby192dev\n#\n---\n - C:/tools/ruby27\n</code></pre> <p>Run the DevKit installer:</p> <pre><code>cd C:/tools/DevKit2\nruby dk.rb install\n</code></pre>"},{"location":"configure-ruby-environment-windows/#ruby-version-manager","title":"Ruby Version Manager","text":"<p>Download latest uru.x.y.z.nupkg from uru's downloads. This was <code>uru.0.8.5.nupkg</code> at the time of writing.</p> <p>In PowerShell as Administrator:</p> <pre><code>cd ~/Downloads\nInvoke-WebRequest -Uri \"https://bitbucket.org/jonforums/uru/downloads/uru.0.8.5.nupkg\" -outfile \"uru.0.8.5.nupkg\"\nchoco install uru.0.8.5.nupkg\n</code></pre>"},{"location":"configure-ruby-environment-windows/#register-ruby-versions","title":"Register Ruby Versions","text":"<p>This will work only if you previously have installed Ruby via Chocolatey.</p> <p>In PowerShell:</p> <pre><code>uru admin rm --all\nuru admin add --recurse C:\\tools\n</code></pre> <p>Test:</p> <pre><code>uru ls\n</code></pre>"},{"location":"configure-ruby-environment-windows/#install-ruby-native-environment","title":"Install Ruby Native Environment","text":"<p>This is needed for gems that requre antive compilation. </p> <pre><code># activate Ruby 2.7\nuru 2.7.2\n\n# use a recent MSYS2 version\n$env:MSYS2_VERSION=\"20230526\"\n\n# install\nridk install\n</code></pre> <p>A list of the available MSYS2 versions is available here. </p>"},{"location":"setup-cpp-development-environment-macos/","title":"Setup C++ development environment on macOS","text":""},{"location":"setup-cpp-development-environment-macos/#homebrew","title":"Homebrew","text":"<p>Install Homebrew:</p> <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre>"},{"location":"setup-cpp-development-environment-macos/#development-tools","title":"Development Tools","text":""},{"location":"setup-cpp-development-environment-macos/#xcode","title":"Xcode","text":"<p>Install Command Line Tools (CLT) for Xcode:</p> <pre><code>xcode-select --install\n</code></pre>"},{"location":"setup-cpp-development-environment-macos/#cmake","title":"CMake","text":"<pre><code>brew install cmake\n</code></pre>"},{"location":"setup-cpp-development-environment-macos/#ninja","title":"ninja","text":"<pre><code>brew install ninja\n</code></pre>"},{"location":"setup-cpp-development-environment-macos/#misc","title":"Misc","text":""},{"location":"setup-cpp-development-environment-macos/#finder","title":"Finder","text":"<p>Show hidden files:</p> <pre><code>defaults write com.apple.finder AppleShowAllFiles YES\n</code></pre> <p>Hold the 'Option/alt' key, then right click on the Finder icon in the dock and click Relaunch</p>"},{"location":"setup-cpp-development-environment-macos/#troubleshooting","title":"Troubleshooting","text":"<p>If you get:</p> <pre><code>xcode-select: error: command line tools are already installed, use \"Software Update\" to install updates\n</code></pre> <p>Try this:</p> <pre><code>softwareupdate --all --install --force\n</code></pre> <p>If that doesn't show you any updates, run:</p> <pre><code> sudo rm -rf /Library/Developer/CommandLineTools\n sudo xcode-select --install\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-macos/","title":"Getting Started with C++ and Visual Studio Code on macOS","text":"<p>Before going through these steps make sure you have done Setup C++ development environment on macOS</p>"},{"location":"getting-started-cpp-visual-studio-code-macos/#visual-studio-code","title":"Visual Studio Code","text":"<p>Download and install from Visual Studio Code site.</p> <p>Open Visual Studio Code and press <code>Cmd + Shift + p</code>. Select <code>Shell Command: Install 'code' command in PATH</code>. </p>"},{"location":"getting-started-cpp-visual-studio-code-macos/#c-project","title":"C++ Project","text":"<p>Create a directory called simple in <code>~/cpp/simple</code></p> <pre><code>mkdir -p ~/cpp/simple\n</code></pre> <p>Open the directory in Visual Studio Code:</p> <pre><code>cd ~/cpp/simple\ncode .\n</code></pre> <p>Install the C/C++ extension.</p>"},{"location":"getting-started-cpp-visual-studio-code-macos/#project-files","title":"Project Files","text":"<p>Add the following files:</p>"},{"location":"getting-started-cpp-visual-studio-code-macos/#srcmaincpp","title":"<code>src/main.cpp</code>","text":"<pre><code>#include &lt;iostream&gt;\n\nint main() {\n  std::cout &lt;&lt; \"Hello CMake!\\n\";\n}\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-macos/#cmakeliststxt","title":"<code>CMakeLists.txt</code>","text":"<pre><code>cmake_minimum_required(VERSION 3.20)\n\nproject(simple)\n\nadd_executable(simple src/main.cpp)\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-macos/#buildsh","title":"<code>build.sh</code>","text":"<pre><code>#!/usr/bin/env bash\n\nmkdir -p ./build/debug\npushd ./build/debug\n    cmake -G 'Ninja' -DCMAKE_BUILD_TYPE=Debug  ../.. &amp;&amp; \\\n    ninja\n    ret=$?\npopd  \n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-macos/#gitignore","title":"<code>.gitignore</code>","text":"<pre><code>.cache/\nbuild/\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-macos/#test-the-build","title":"Test the build","text":"<p>Open Terminal in Visual Studio Code and test the build from command line:</p> <pre><code>./build.sh\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-macos/#automate-the-build","title":"Automate the build","text":"<p>Add the following Visual Studio Code specific files to the <code>.vscode</code> subdir:</p>"},{"location":"getting-started-cpp-visual-studio-code-macos/#vscodetasksjson","title":"<code>.vscode/tasks.json</code>","text":"<pre><code>{\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"label\": \"Build\",\n            \"type\": \"shell\",\n            \"osx\": {\n                \"command\": \"${workspaceFolder}/build.sh\",\n            },\n            \"group\": {\n                \"kind\": \"build\",\n                \"isDefault\": true\n            }\n        }\n    ]\n}\n</code></pre> <p>Test the build by pressing <code>Cmd + B</code>. Visual Studio Code should execute the <code>build.sh</code> script automatically.</p>"},{"location":"getting-started-cpp-visual-studio-code-macos/#setup-debugging","title":"Setup Debugging","text":"<p>Add the following Visual Studio Code specific files to the <code>.vscode</code> subdir:</p>"},{"location":"getting-started-cpp-visual-studio-code-macos/#vscodelaunchjson","title":"<code>.vscode/launch.json</code>","text":"<pre><code>{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Launch (gdb)\",\n            \"type\": \"cppdbg\",\n            \"request\": \"launch\",\n            \"cwd\": \"${workspaceFolder}\",\n            \"osx\": {\n                \"program\": \"${workspaceFolder}/build/debug/simple\",\n                \"MIMode\": \"lldb\",\n            },\n        }    \n    ]\n}\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-macos/#test-the-debugging","title":"Test the debugging","text":"<p>Set a breakpoint on the first line of <code>int main()</code> inside <code>src/main.cpp</code>. Press <code>F5</code> to launch the debugger. It should stop at the breakpoint.</p>"},{"location":"configure-ruby-environment-ubuntu/","title":"Configure Ruby Environment on Ubuntu","text":"<p>This is a simple guide for configuring a Ruby 2 environment on Ubuntu. This was tested for Ruby 2.7.2 on Ubuntu 22.04.3. All scripts are <code>bash</code>.</p>"},{"location":"configure-ruby-environment-ubuntu/#compilers","title":"Compilers","text":"<pre><code>sudo apt install build-essential\n</code></pre>"},{"location":"configure-ruby-environment-ubuntu/#rvm","title":"rvm","text":"<p><code>rvm</code> is a Ruby version manager</p> <p>Install:</p> <pre><code>gpg --keyserver hkp://keyserver.ubuntu.com --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB\ncurl -sSL https://get.rvm.io | bash -s -- stable --ignore-dotfiles\n</code></pre> <p>Test:</p> <pre><code>source ~/.rvm/scripts/rvm\nrvm info\n</code></pre>"},{"location":"configure-ruby-environment-ubuntu/#ruby","title":"Ruby","text":"<p>Install via <code>rvm</code>:</p> <pre><code>source ~/.rvm/scripts/rvm\nrvm pkg install openssl\nrvm install 2.7.2 --with-openssl-dir=$HOME/.rvm/usr\n</code></pre> <p>Test:</p> <pre><code>rvm use\nruby --version\n\n# you should get output similar to this:\n# ruby 2.7.2p137 (2020-10-01 revision 5445e04352) [x86_64-linux]\n</code></pre>"},{"location":"setup-net-development-environment-macos/","title":"Setup .NET development environment on macOS","text":""},{"location":"setup-net-development-environment-macos/#setup-for-macos","title":"Setup for macOS","text":"<p>Download the <code>dotnet-install.sh</code> script</p> <pre><code>cd\ncurl -sSL https://dot.net/v1/dotnet-install.sh &gt; dotnet-install.sh\nchmod +x dotnet-install.sh\n</code></pre>"},{"location":"setup-net-development-environment-macos/#net-runtime","title":".NET Runtime","text":""},{"location":"setup-net-development-environment-macos/#net-runtime-60-lts","title":".NET Runtime 6.0 (LTS)","text":"<pre><code>./dotnet-install.sh --runtime dotnet --channel 6.0 --version latest\n</code></pre> <p>or download and install from Microsoft</p>"},{"location":"setup-net-development-environment-macos/#net-runtime-70","title":".NET Runtime 7.0","text":"<pre><code>./dotnet-install.sh --runtime dotnet --channel 7.0 --version latest\n</code></pre> <p>or download and install from Microsoft</p>"},{"location":"setup-net-development-environment-macos/#net-runtime-80-lts","title":".NET Runtime 8.0 (LTS)","text":"<pre><code>./dotnet-install.sh --runtime dotnet --channel 8.0 --version latest\n</code></pre> <p>or download and install from Microsoft</p>"},{"location":"setup-net-development-environment-macos/#net-sdk","title":".NET SDK","text":""},{"location":"setup-net-development-environment-macos/#net-sdk-60","title":".NET SDK 6.0","text":"<p>This is needed by the Visual Studio Code C# extension. Install with <code>dotnet-install.sh</code> script:</p> <pre><code>./dotnet-install.sh --channel 6.0\n</code></pre>"},{"location":"setup-net-development-environment-macos/#net-sdk-70","title":".NET SDK 7.0","text":"<p>This is needed by the Visual Studio Code C# extension. Install with <code>dotnet-install.sh</code> script:</p> <pre><code>./dotnet-install.sh --channel 7.0\n</code></pre>"},{"location":"setup-net-development-environment-macos/#net-sdk-80","title":".NET SDK 8.0","text":"<p>Install with <code>dotnet-install.sh</code> script:</p> <pre><code>./dotnet-install.sh --channel 8.0\n</code></pre>"},{"location":"setup-net-development-environment-macos/#test","title":"Test","text":"<p>Test that you can run the <code>dotnet</code> CLI (command line interface)</p> <pre><code>~/.dotnet/dotnet --version\n~/.dotnet/dotnet new console --help\n</code></pre>"},{"location":"getting-started-net-visual-studio-code-macos/","title":"Getting Started with .NET and Visual Studio Code on macOS","text":"<p>Before going through these steps make sure you have done Setup .NET development environment on macOS</p>"},{"location":"getting-started-net-visual-studio-code-macos/#visual-studio-code","title":"Visual Studio Code","text":"<p>Download and install from Visual Studio Code site.   </p> <p>Open Visual Studio Code and press <code>Cmd + Shift + p</code>. Select <code>Shell Command: Install 'code' command in PATH</code>.   </p> <p>Close Visual Studio Code.</p>"},{"location":"getting-started-net-visual-studio-code-macos/#project-directory","title":"Project Directory","text":"<p>Create a directory called <code>simple</code> in <code>~/net/simple</code></p> <pre><code>mkdir -p ~/net/simple\n</code></pre>"},{"location":"getting-started-net-visual-studio-code-macos/#net-project-files","title":".NET Project Files","text":"<p>Create the project files:</p> <pre><code>export PATH=\"$HOME/.dotnet:$PATH\"\n\ncd ~/net/simple\n\n# Switch to use .NET SDK 6.0, 7.0 or 8.0. We do 8.0 here but give the commands for other versions \n# dotnet new globaljson --sdk-version 6.0.417 --roll-forward latestPatch\n# dotnet new globaljson --sdk-version 7.0.404 --roll-forward latestPatch\ndotnet new globaljson --sdk-version 8.0.100 --roll-forward latestPatch\n\n# create new console application and project\ndotnet new console --framework net6.0\n\n# create new solution and add the project to it\ndotnet new sln\ndotnet sln add simple.csproj\n\n# add .gitignore\ndotnet new gitignore\n</code></pre> <p>Open the directory in Visual Studio Code:</p> <pre><code>export PATH=\"$HOME/.dotnet:$PATH\"\n\ncd ~/net/simple\ncode .\n</code></pre> <p>Install the C# Dev Kit extension for Visual Studio Code.</p>"},{"location":"getting-started-net-visual-studio-code-macos/#automate-the-build","title":"Automate the build","text":"<p>Add the following Visual Studio Code specific files to the <code>.vscode</code> subdir:</p>"},{"location":"getting-started-net-visual-studio-code-macos/#vscodetasksjson","title":"<code>.vscode/tasks.json</code>","text":"<pre><code>{\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"type\": \"dotnet\",\n            \"task\": \"build\",\n            \"group\": \"build\",\n            \"problemMatcher\": [],\n            \"label\": \"dotnet: build\"\n        }\n    ]\n}\n</code></pre> <p>Test the build by pressing <code>Cmd + B</code>. Visual Studio Code should execute the <code>build.sh</code> script automatically.</p>"},{"location":"getting-started-net-visual-studio-code-macos/#setup-debugging","title":"Setup Debugging","text":"<p>Add the following Visual Studio Code specific files to the <code>.vscode</code> subdir:</p>"},{"location":"getting-started-net-visual-studio-code-macos/#vscodelaunchjson","title":"<code>.vscode/launch.json</code>","text":"<pre><code>{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \".NET Core Launch (console)\",\n            \"type\": \"coreclr\",\n            \"request\": \"launch\",\n            \"preLaunchTask\": \"dotnet: build\",\n            \"program\": \"${workspaceFolder}/bin/Debug/net6.0/simple.dll\",\n            \"args\": [],\n            \"cwd\": \"${workspaceFolder}\",\n            \"console\": \"internalConsole\",\n            \"stopAtEntry\": false\n        }\n    ]\n}\n</code></pre>"},{"location":"getting-started-net-visual-studio-code-macos/#test-the-debugging","title":"Test the debugging","text":"<p>Set a breakpoint at the <code>Console.WriteLine(\"Hello, World!\");</code> line in <code>Programs.cs</code>: </p> <pre><code>// See https://aka.ms/new-console-template for more information\nConsole.WriteLine(\"Hello, World!\");\n</code></pre> <p>Press <code>F5</code> to launch the debugger. It should stop at the breakpoint.</p>"},{"location":"setup-cpp-development-environment-ubuntu/","title":"Setup C++ development environment on Ubuntu","text":"<p>These steps were tested on Ubuntu 22.04.3 LTS. Scripts are <code>bash</code>.</p>"},{"location":"setup-cpp-development-environment-ubuntu/#compilers","title":"Compilers","text":"<pre><code>sudo apt install build-essential\n</code></pre>"},{"location":"setup-cpp-development-environment-ubuntu/#cmake","title":"CMake","text":"<pre><code>sudo apt install cmake\n</code></pre>"},{"location":"setup-cpp-development-environment-ubuntu/#ninja","title":"ninja","text":"<pre><code>sudo apt install ninja-build\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-ubuntu/","title":"Getting Started with C++ and Visual Studio Code on Ubuntu","text":"<p>Before going through these steps make sure you have done Setup C++ development environment on Ubuntu</p>"},{"location":"getting-started-cpp-visual-studio-code-ubuntu/#visual-studio-code","title":"Visual Studio Code","text":"<p>Download and install from Visual Studio Code site.</p> <p>Open Visual Studio Code and press <code>Cmd + Shift + P</code>. Select <code>Shell Command: Install 'code' command in PATH</code>. </p>"},{"location":"getting-started-cpp-visual-studio-code-ubuntu/#c-project","title":"C++ Project","text":"<p>Create a directory called simple in <code>~/cpp/simple</code></p> <pre><code>mkdir -p ~/cpp/simple\n</code></pre> <p>Open the directory in Visual Studio Code:</p> <pre><code>cd ~/cpp/simple\ncode .\n</code></pre> <p>Install the C/C++ Extension Pack.</p>"},{"location":"getting-started-cpp-visual-studio-code-ubuntu/#project-files","title":"Project Files","text":"<p>Add the following files:</p>"},{"location":"getting-started-cpp-visual-studio-code-ubuntu/#srcmaincpp","title":"<code>src/main.cpp</code>","text":"<pre><code>#include &lt;iostream&gt;\n\nint main() {\n  std::cout &lt;&lt; \"Hello CMake!\\n\";\n}\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-ubuntu/#cmakeliststxt","title":"<code>CMakeLists.txt</code>","text":"<pre><code>cmake_minimum_required(VERSION 3.20)\n\nproject(simple)\n\nadd_executable(simple src/main.cpp)\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-ubuntu/#buildsh","title":"<code>build.sh</code>","text":"<pre><code>#!/usr/bin/env bash\n\nmkdir -p ./build/debug\npushd ./build/debug\n    cmake -G 'Ninja' -DCMAKE_BUILD_TYPE=Debug  ../.. &amp;&amp; \\\n    ninja\n    ret=$?\npopd  \n</code></pre> <p>Make it executable:</p> <pre><code>chmod +x build.sh\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-ubuntu/#gitignore","title":"<code>.gitignore</code>","text":"<pre><code>.cache/\nbuild/\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-ubuntu/#test-the-build","title":"Test the build","text":"<p>Open Terminal in Visual Studio Code and test the build from command line:</p> <pre><code>./build.sh\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-ubuntu/#automate-the-build","title":"Automate the build","text":"<p>Add the following Visual Studio Code specific files to the <code>.vscode</code> subdir:</p>"},{"location":"getting-started-cpp-visual-studio-code-ubuntu/#vscodetasksjson","title":"<code>.vscode/tasks.json</code>","text":"<pre><code>{\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"label\": \"Build\",\n            \"type\": \"shell\",\n            \"linux\": {\n                \"command\": \"${workspaceFolder}/build.sh\",\n            },\n            \"group\": {\n                \"kind\": \"build\",\n                \"isDefault\": true\n            }\n        }\n    ]\n}\n</code></pre> <p>Test the build by pressing <code>Ctrl + B</code>. Visual Studio Code should execute the <code>build.sh</code> script automatically.</p>"},{"location":"getting-started-cpp-visual-studio-code-ubuntu/#setup-debugging","title":"Setup Debugging","text":"<p>Add the following Visual Studio Code specific files to the <code>.vscode</code> subdir:</p>"},{"location":"getting-started-cpp-visual-studio-code-ubuntu/#vscodelaunchjson","title":"<code>.vscode/launch.json</code>","text":"<pre><code>{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Launch (gdb)\",\n            \"type\": \"cppdbg\",\n            \"request\": \"launch\",\n            \"cwd\": \"${workspaceFolder}\",\n            \"linux\": {\n                \"program\": \"${workspaceFolder}/build/debug/simple\",\n                \"MIMode\": \"gdb\"\n            }\n        }    \n    ]\n}\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-ubuntu/#test-the-debugging","title":"Test the debugging","text":"<p>Set a breakpoint on the first line of <code>int main()</code> inside <code>src/main.cpp</code>. Press <code>F5</code> to launch the debugger. It should stop at the breakpoint.</p>"},{"location":"setup-net-development-environment-ubuntu/","title":"Setup .NET development environment on Ubuntu","text":""},{"location":"setup-net-development-environment-ubuntu/#setup-for-ubuntu","title":"Setup for Ubuntu","text":"<p>Download the <code>dotnet-install.sh</code> script</p> <pre><code>cd\ncurl -sSL https://dot.net/v1/dotnet-install.sh &gt; dotnet-install.sh\nchmod +x dotnet-install.sh\n</code></pre>"},{"location":"setup-net-development-environment-ubuntu/#net-runtime","title":".NET Runtime","text":""},{"location":"setup-net-development-environment-ubuntu/#net-runtime-60-lts","title":".NET Runtime 6.0 (LTS)","text":"<pre><code>./dotnet-install.sh --runtime dotnet --channel 6.0 --version latest\n</code></pre>"},{"location":"setup-net-development-environment-ubuntu/#net-runtime-70","title":".NET Runtime 7.0","text":"<pre><code>./dotnet-install.sh --runtime dotnet --channel 7.0 --version latest\n</code></pre>"},{"location":"setup-net-development-environment-ubuntu/#net-runtime-80-lts","title":".NET Runtime 8.0 (LTS)","text":"<pre><code>./dotnet-install.sh --runtime dotnet --channel 8.0 --version latest\n</code></pre>"},{"location":"setup-net-development-environment-ubuntu/#net-sdk","title":".NET SDK","text":""},{"location":"setup-net-development-environment-ubuntu/#net-sdk-60","title":".NET SDK 6.0","text":"<p>This is needed by the Visual Studio Code C# extension. Install with <code>dotnet-install.sh</code> script:</p> <pre><code>./dotnet-install.sh --channel 6.0\n</code></pre>"},{"location":"setup-net-development-environment-ubuntu/#net-sdk-70","title":".NET SDK 7.0","text":"<p>This is needed by the Visual Studio Code C# extension. Install with <code>dotnet-install.sh</code> script:</p> <pre><code>./dotnet-install.sh --channel 7.0\n</code></pre>"},{"location":"setup-net-development-environment-ubuntu/#net-sdk-80","title":".NET SDK 8.0","text":"<p>Install with <code>dotnet-install.sh</code> script:</p> <pre><code>./dotnet-install.sh --channel 8.0\n</code></pre>"},{"location":"setup-net-development-environment-ubuntu/#test","title":"Test","text":"<p>Test that you can run the <code>dotnet</code> CLI (command line interface)</p> <pre><code>~/.dotnet/dotnet --version\n~/.dotnet/dotnet new console --help\n</code></pre>"},{"location":"getting-started-net-visual-studio-code-ubuntu/","title":"Getting Started with .NET and Visual Studio Code on Ubuntu","text":"<p>Before going through these steps make sure you have done Setup .NET development environment on Ubuntu</p>"},{"location":"getting-started-net-visual-studio-code-ubuntu/#visual-studio-code","title":"Visual Studio Code","text":"<p>Download and install from Visual Studio Code site.   </p> <p>Open Visual Studio Code and press <code>Ctrl + Shift + P</code>. Select <code>Shell Command: Install 'code' command in PATH</code>.   </p> <p>Close Visual Studio Code.</p>"},{"location":"getting-started-net-visual-studio-code-ubuntu/#project-directory","title":"Project Directory","text":"<p>Create a directory called <code>simple</code> in <code>~/net/simple</code></p> <pre><code>mkdir -p ~/net/simple\n</code></pre>"},{"location":"getting-started-net-visual-studio-code-ubuntu/#net-project-files","title":".NET Project Files","text":"<p>Create the project files:</p> <pre><code>export PATH=\"$HOME/.dotnet:$PATH\"\n\ncd ~/net/simple\n\n# Switch to use .NET SDK 6.0, 7.0 or 8.0. We do 8.0 here but give the commands for other versions \n# dotnet new globaljson --sdk-version 6.0.417 --roll-forward latestPatch\n# dotnet new globaljson --sdk-version 7.0.404 --roll-forward latestPatch\ndotnet new globaljson --sdk-version 8.0.100 --roll-forward latestPatch\n\n# create new console application and project\ndotnet new console --framework net6.0\n\n# create new solution and add the project to it\ndotnet new sln\ndotnet sln add simple.csproj\n\n# add .gitignore\ndotnet new gitignore\n</code></pre> <p>Open the directory in Visual Studio Code:</p> <pre><code>export PATH=\"$HOME/.dotnet:$PATH\"\n\ncd ~/net/simple\ncode .\n</code></pre> <p>Install the C# Dev Kit extension for Visual Studio Code.</p>"},{"location":"getting-started-net-visual-studio-code-ubuntu/#automate-the-build","title":"Automate the build","text":"<p>Add the following Visual Studio Code specific files to the <code>.vscode</code> subdir:</p>"},{"location":"getting-started-net-visual-studio-code-ubuntu/#vscodetasksjson","title":"<code>.vscode/tasks.json</code>","text":"<pre><code>{\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"type\": \"dotnet\",\n            \"task\": \"build\",\n            \"group\": \"build\",\n            \"problemMatcher\": [],\n            \"label\": \"dotnet: build\"\n        }\n    ]\n}\n</code></pre> <p>Test the build by pressing <code>Ctrl + Shift + B</code>. Visual Studio Code should execute the <code>build.sh</code> script automatically.</p>"},{"location":"getting-started-net-visual-studio-code-ubuntu/#setup-debugging","title":"Setup Debugging","text":"<p>Add the following Visual Studio Code specific files to the <code>.vscode</code> subdir:</p>"},{"location":"getting-started-net-visual-studio-code-ubuntu/#vscodelaunchjson","title":"<code>.vscode/launch.json</code>","text":"<pre><code>{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \".NET Core Launch (console)\",\n            \"type\": \"coreclr\",\n            \"request\": \"launch\",\n            \"preLaunchTask\": \"dotnet: build\",\n            \"program\": \"${workspaceFolder}/bin/Debug/net6.0/simple.dll\",\n            \"args\": [],\n            \"cwd\": \"${workspaceFolder}\",\n            \"console\": \"internalConsole\",\n            \"stopAtEntry\": false\n        }\n    ]\n}\n</code></pre>"},{"location":"getting-started-net-visual-studio-code-ubuntu/#test-the-debugging","title":"Test the debugging","text":"<p>Set a breakpoint at the <code>Console.WriteLine(\"Hello, World!\");</code> line in <code>Programs.cs</code>: </p> <pre><code>// See https://aka.ms/new-console-template for more information\nConsole.WriteLine(\"Hello, World!\");\n</code></pre> <p>Press <code>F5</code> to launch the debugger. It should stop at the breakpoint.</p>"},{"location":"setup-cpp-development-environment-windows/","title":"Setup C++ development environment on Windows","text":"<p>These steps were tested on Windows 11, 23H2. Scripts are <code>PowerShell</code>.</p>"},{"location":"setup-cpp-development-environment-windows/#visual-studio-2022","title":"Visual Studio 2022","text":"<p>This is needed for the C++ compiler. Install Visual Studio 2022 Community Edition.  </p> <p>During installation select C++ desktop development and latest Windows 10 and Windows 11 SDKs. </p> <p>After installation open Visual Studio and check for updates. Install the latest 2022 version that is available. </p>"},{"location":"setup-cpp-development-environment-windows/#cmake","title":"CMake","text":"<p>Install via Windows Package Manager:</p> <pre><code>winget install kitware.cmake\n</code></pre>"},{"location":"setup-cpp-development-environment-windows/#ninja","title":"ninja","text":"<p>Install via Windows Package Manager:</p> <pre><code>winget install Ninja-build.Ninja\n</code></pre>"},{"location":"setup-cpp-development-environment-windows/#powershell-configuration","title":"PowerShell Configuration","text":"<p>This will allow you to execute PowerShell scripts locally on your machine. In PowerShell as Administrator:</p> <pre><code>Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope LocalMachine\n</code></pre>"},{"location":"setup-cpp-development-environment-windows/#environment","title":"Environment","text":"<p>Update <code>$env:PSModulePath</code>  so that you can use PowerShell modules. In PowerShell as Administrator:</p> <pre><code>[Environment]::SetEnvironmentVariable(\"PSModulePath\", \"$HOME/Documents/WindowsPowerShell/Modules;\" + $env:PSModulePath, \"Machine\")\n</code></pre>"},{"location":"setup-cpp-development-environment-windows/#vssetup-module","title":"VSSetup Module","text":"<p>In PowerShell as Administrator:</p> <p><pre><code>Install-Module VSSetup -Scope CurrentUser\n</code></pre> Close and reopen PowerShell. Now you can use the VSSetup commands.</p> <p>List the Visual Studio installations: </p> <pre><code>Get-VSSetupInstance\n</code></pre> <p>This finds the installation path for Visual Studio 2022:</p> <pre><code>Get-VSSetupInstance `\n| Select-VSSetupInstance -Version '[17.0,]' `\n| Select-Object -ExpandProperty InstallationPath\n</code></pre> <p>See Selecting an Instance</p>"},{"location":"getting-started-cpp-visual-studio-code-windows/","title":"Getting Started with C++ and Visual Studio Code on Windows","text":"<p>Before going through these steps make sure you have done Setup C++ development environment on Windows</p>"},{"location":"getting-started-cpp-visual-studio-code-windows/#visual-studio-code","title":"Visual Studio Code","text":"<p>Download and install from Visual Studio Code site.</p> <p>Open Visual Studio Code and press <code>Cmd + Shift + P</code>. Select <code>Shell Command: Install 'code' command in PATH</code>. </p>"},{"location":"getting-started-cpp-visual-studio-code-windows/#c-project","title":"C++ Project","text":"<p>Create a directory called simple in <code>~/cpp/simple</code></p> <pre><code>mkdir -p ~/cpp/simple\n</code></pre> <p>Add a configuration script <code>configure.ps1</code>:</p> <pre><code>$temp_file = [IO.Path]::GetTempFileName()\n\n# find where Visual Studio 2022 is installed\n$vs_install_dir = $(Get-VSSetupInstance | Select-VSSetupInstance -Version '[17.0,18.0]' | Select-Object -ExpandProperty InstallationPath)\n$vs_common_tools = \"${vs_install_dir}/Common7/Tools/\"\n\n# run `VsDevCmd.bat -arch=amd64 -host_arch=amd64` and save environment to $temp_file\ncmd /c \" `\"$vs_common_tools/VsDevCmd.bat`\" -arch=amd64 -host_arch=amd64 &amp;&amp; set &gt; `\"$temp_file`\"\"\n\n# copy the environment variables into PowerShell\nGet-Content $temp_file | Foreach-Object {\n    if($_ -match \"^(.*?)=(.*)$\") {\n        Set-Content \"env:\\$($matches[1])\" $matches[2]\n    }\n}\n\nRemove-Item $temp_file\n</code></pre> <p>Open the directory in Visual Studio Code. It is important to source the <code>configure.ps1</code> script before running <code>code .</code> in order to setup the correct C++ environment:</p> <pre><code>cd ~/cpp/simple\n\n. .\\configure.ps1\n\ncode .\n</code></pre> <p>Install the C/C++ Extension Pack.</p>"},{"location":"getting-started-cpp-visual-studio-code-windows/#project-files","title":"Project Files","text":"<p>Add the following files:</p>"},{"location":"getting-started-cpp-visual-studio-code-windows/#srcmaincpp","title":"<code>src/main.cpp</code>","text":"<pre><code>#include &lt;iostream&gt;\n\nint main() {\n  std::cout &lt;&lt; \"Hello CMake!\\n\";\n}\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-windows/#cmakeliststxt","title":"<code>CMakeLists.txt</code>","text":"<pre><code>cmake_minimum_required(VERSION 3.20)\n\nproject(simple)\n\nadd_executable(simple src/main.cpp)\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-windows/#buildps1","title":"<code>build.ps1</code>","text":"<pre><code>New-Item -Force -Path ./build/debug -ItemType Directory \nPush-Location ./build/debug\n    cmake -G 'Ninja' -DCMAKE_BUILD_TYPE=debug ../..\n    ninja\nPop-Location\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-windows/#gitignore","title":"<code>.gitignore</code>","text":"<pre><code>build/\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-windows/#test-the-build","title":"Test the build","text":"<p>Open Terminal in Visual Studio Code and test the build from command line:</p> <pre><code>./build.ps1\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-windows/#automate-the-build","title":"Automate the build","text":"<p>Add the following Visual Studio Code specific files to the <code>.vscode</code> subdir:</p>"},{"location":"getting-started-cpp-visual-studio-code-windows/#vscodetasksjson","title":"<code>.vscode/tasks.json</code>","text":"<pre><code>{\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"label\": \"Build\",\n            \"type\": \"shell\",\n            \"windows\": {\n                \"command\": \"${workspaceFolder}/build.ps1\",\n            },\n            \"group\": {\n                \"kind\": \"build\",\n                \"isDefault\": true\n            }\n        }\n    ]\n}\n</code></pre> <p>Test the build by pressing <code>Ctrl + Shift + B</code>. Visual Studio Code should execute the <code>build.ps1</code> script automatically.</p>"},{"location":"getting-started-cpp-visual-studio-code-windows/#setup-debugging","title":"Setup Debugging","text":"<p>Add the following Visual Studio Code specific files to the <code>.vscode</code> subdir:</p>"},{"location":"getting-started-cpp-visual-studio-code-windows/#vscodelaunchjson","title":"<code>.vscode/launch.json</code>","text":"<pre><code>{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Debug (cppvsdbg)\",\n            \"type\": \"cppdbg\",\n            \"request\": \"launch\",\n            \"cwd\": \"${workspaceFolder}\",\n            \"windows\": {\n                \"type\": \"cppvsdbg\",\n                \"program\": \"${workspaceFolder}/build/debug/simple.exe\"\n            },\n            \"preLaunchTask\": \"Build\"\n        }        \n   ]\n}\n</code></pre>"},{"location":"getting-started-cpp-visual-studio-code-windows/#test-the-debugging","title":"Test the debugging","text":"<p>Set a breakpoint on the first line of <code>int main()</code> inside <code>src/main.cpp</code>. Press <code>F5</code> to launch the debugger. It should stop at the breakpoint.</p>"},{"location":"ubuntu-virtual-machine-apple-silicon/","title":"Install Ubuntu 22.04 ARM Virtual Machine on Apple Silicon","text":""},{"location":"ubuntu-virtual-machine-apple-silicon/#install-multipass","title":"Install Multipass","text":"<p>Canonical Multipass is a lightweight VM manager for Linux, Windows and macOS. It's designed for developers who want a fresh Ubuntu environment with a single command. </p> <p>Install via Homebrew:</p> <pre><code>brew install multipass\n</code></pre> <p>Test:</p> <pre><code>multipass version\n</code></pre> <pre><code>multipass   1.13.0+mac\nmultipassd  1.13.0+mac\n</code></pre> <p>List supported Images and Blueprints:</p> <pre><code>multipass find\n</code></pre> <pre><code>Image                       Aliases           Version          Description\n20.04                       focal             20240118         Ubuntu 20.04 LTS\n22.04                       jammy,lts         20231211         Ubuntu 22.04 LTS\n23.10                       mantic            20231220         Ubuntu 23.10\n\nBlueprint                   Aliases           Version          Description\nanbox-cloud-appliance                         latest           Anbox Cloud Appliance\ncharm-dev                                     latest           A development and testing environment for charmers\ndocker                                        0.4              A Docker environment with Portainer and related tools\njellyfin                                      latest           Jellyfin is a Free Software Media System that puts you in control of managing and streaming your media.\nminikube                                      latest           minikube is local Kubernetes\nros-noetic                                    0.1              A development and testing environment for ROS Noetic.\nros2-humble                                   0.1              A development and testing environment for ROS 2 Humble.\n</code></pre>"},{"location":"ubuntu-virtual-machine-apple-silicon/#install-ubuntu","title":"Install Ubuntu","text":"<p>Launch Ubuntu 22.04 VM named <code>ubuntu-arm64</code> with 4 CPUs, 4 GB of RAM and 200 GB of disk space. This will install the official server version from https://ubuntu.com </p> <pre><code>multipass launch 22.04 --name ubuntu-arm64 --cpus 4 --memory 4G --disk 200G\n</code></pre> <p>Connect to the machine:</p> <pre><code>multipass shell ubuntu-arm64\n</code></pre> <p>You should see output similar to this:</p> <pre><code>Welcome to Ubuntu 22.04.3 LTS (GNU/Linux 5.15.0-91-generic aarch64)\n\n * Documentation:  https://help.ubuntu.com\n * Management:     https://landscape.canonical.com\n * Support:        https://ubuntu.com/advantage\n\n  System information as of Sun Jan 21 15:08:51 UTC 2024\n\n  System load:             0.2275390625\n  Usage of /:              0.7% of 193.63GB\n  Memory usage:            5%\n  Swap usage:              0%\n  Processes:               130\n  Users logged in:         0\n  IPv4 address for enp0s1: 192.168.64.5\n  IPv6 address for enp0s1: fde4:91fb:918:4bfe:5054:ff:fe94:e6a8\n</code></pre>"},{"location":"ubuntu-virtual-machine-apple-silicon/#install-ubuntu-desktop","title":"Install Ubuntu Desktop","text":"<p>Login into the VM:</p> <pre><code>multipass shell ubuntu-arm64\n</code></pre> <p>Install Ubuntu Desktop and X Remote Desktop Protocol (xrdp). This takes a few minutes to install all the required packages:</p> <pre><code>sudo apt update \nsudo apt install -y ubuntu-desktop xrdp \n</code></pre>"},{"location":"ubuntu-virtual-machine-apple-silicon/#create-a-new-user","title":"Create a new user","text":"<p>Create a new user for connecting in graphical mode. Replace <code>&lt;username&gt;</code> with your user:</p> <pre><code># create user\nsudo adduser &lt;username&gt;\n\n# add to the sudo group\nsudo usermod -aG sudo &lt;username&gt;\n</code></pre>"},{"location":"ubuntu-virtual-machine-apple-silicon/#connect-with-remote-desktop","title":"Connect with Remote Desktop","text":"<p>Install Microsoft Remote Desktop from the Apple App Store.</p> <p>Get VM IP Address:</p> <pre><code>multipass list\n\nName                    State             IPv4             Image\nubuntu-arm64            Running           192.168.64.5     Ubuntu 22.04 LTS\n</code></pre> <p>Connect to Ubuntu:</p> <p></p> <p>When asked, enter your password. You should see:</p> <p></p>"},{"location":"ubuntu-virtual-machine-apple-silicon/#ubuntu-desktop-look-and-feel","title":"Ubuntu Desktop Look and Feel","text":"<p>To have the same look and feel as the original Ubuntu Desktop GUI, in the home directory of the user you use to connect to with Remote Desktop, create a file called <code>.xsessionrc</code> with this info: </p> <pre><code>export GNOME_SHELL_SESSION_MODE=ubuntu\nexport XDG_CURRENT_DESKTOP=ubuntu:GNOME\nexport XDG_CONFIG_DIRS=/etc/xdg/xdg-ubuntu:/etc/xdg\n</code></pre> <p>You need to restart the machine for the changes to take effect</p>"},{"location":"ubuntu-virtual-machine-apple-silicon/#clean-up","title":"Clean up","text":"<p>Delete the machine. This will stop the machine without deleting the VM files:</p> <pre><code>multipass delete ubuntu-arm64\n</code></pre> <p>Purge all files for deleted machines. Make sure you don't have any data that you need on the VM. There is no coming back after you run this:</p> <pre><code>multipass purge\n</code></pre>"},{"location":"simple-regression-tensorflow-keras/","title":"Creating a simple regression model using Tensorflow and Keras","text":""},{"location":"simple-regression-tensorflow-keras/#introduction","title":"Introduction","text":"<p>A typical setting where <code>y</code> is a measurement and <code>X</code> is an input can be found in many fields such as science, engineering, economics, and machine learning. </p> <p>The relationship between <code>X</code> and <code>y</code> can be modeled as <code>y = F(X) + \u03b5</code>, where <code>F(X)</code> is a function that maps <code>X</code> to <code>y</code>, and <code>\u03b5</code> is the error term that accounts for the randomness or uncertainty in the predictions. </p> \\[ y = F(X) + \\epsilon \\] <p>The goal is to learn the function <code>F</code> that best maps <code>X</code> to <code>y</code> with the smallest error <code>\u03b5</code>. This is typically done by minimizing the difference between the predicted <code>y</code> values and the actual <code>y</code> values (i.e., minimizing the error term <code>\u03b5</code>).</p>"},{"location":"simple-regression-tensorflow-keras/#import-packages","title":"Import packages","text":"<p>The main packages that we use are Tensorflow and Keras. We also need a few supporting packages like <code>math</code>, <code>numpy</code>, and <code>sklearn</code>.</p> <pre><code>import math \nimport numpy as np \nimport matplotlib.pyplot as plt \n\nimport tensorflow as tf \nfrom tensorflow import keras\n\nfrom sklearn.metrics import r2_score\n</code></pre> <pre><code>2024-02-11 11:12:46.080901: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n</code></pre>"},{"location":"simple-regression-tensorflow-keras/#simulate-inputs-and-outputs","title":"Simulate inputs and outputs","text":"<p>We will simulate the function:</p> \\[ y = sin(X) + \\epsilon  \\] <p>for a random number of X samples.</p> <p>First, start by generating the X inputs - a few random samples between 0 and 2\u03c0. This will serve as our input: </p> <pre><code>nsamples = 1000\n\nnp.random.seed(16) \nX = np.random.uniform(low=0, high=(2 * math.pi), size=nsamples) \n\nplt.plot(X)\n</code></pre> <pre><code>[&lt;matplotlib.lines.Line2D at 0x135ccd110&gt;]\n</code></pre> <p>\u200b    \u200b    </p> <p>Next, create a noisy sine wave from the X input. This will serve as our output, a.k.a. measurements or observations: </p> <pre><code>y = np.sin(X) + (0.1 * np.random.randn(X.shape[0])) \nplt.plot(X, y, '.')\n</code></pre> <pre><code>[&lt;matplotlib.lines.Line2D at 0x148754550&gt;]\n</code></pre> <p>\u200b    \u200b    </p>"},{"location":"simple-regression-tensorflow-keras/#create-training-validation-and-test-datasets","title":"Create Training, Validation, and Test datasets","text":"<p>Split the dataset into training, validation, and test sets:</p> <pre><code># Percentage of samples that should be held for validation set \nval_ratio = 0.2 \n\n# Percentage of samples that should be held for test\ntest_ratio = 0.2 \n\n# Split the dataset into training, validation, and test sets \nval_split = int(val_ratio * nsamples) \ntest_split = int(val_split + (test_ratio * nsamples)) \nX_val, X_test, X_train = np.split(X, [val_split, test_split]) \ny_val, y_test, y_train = np.split(y, [val_split, test_split]) \n\n# Check that our splits add up correctly \nassert(X_train.size + X_val.size + X_test.size) == nsamples \n\n# Plot the data in each partition in different colors: \nplt.plot(X_train, y_train, '.', label=\"Train\") \nplt.plot(X_val, y_val, '.', label=\"Validate\") \nplt.plot(X_test, y_test, '.', label=\"Test\") \nplt.legend() \nplt.show()\n</code></pre> <p>\u200b    \u200b    </p> <p>Create a Deep Neural Network regression model with two hidden layers:</p> <pre><code># create model\nmodel = keras.Sequential() \nmodel.add(keras.layers.InputLayer(input_shape=(1,)))\nmodel.add(keras.layers.Dense(16, activation='relu')) \nmodel.add(keras.layers.Dense(16, activation='relu')) \nmodel.add(keras.layers.Dense(1))\n\n# view model summary\nmodel.summary()\n</code></pre> <pre><code>Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 16)                32\n\n dense_1 (Dense)             (None, 16)                272\n\n dense_2 (Dense)             (None, 1)                 17\n\n=================================================================\nTotal params: 321 (1.25 KB)\nTrainable params: 321 (1.25 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n</code></pre> <p>Add optimizer, loss function, and metrics to the model and compile it. The optimizer's job is to adjust the weights of the network to minimize the loss function. </p> <pre><code>model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n</code></pre>"},{"location":"simple-regression-tensorflow-keras/#train-the-model","title":"Train the model","text":"<p>Train the model using the training and the validation datasets:  </p> <pre><code>history = model.fit(X_train, y_train, epochs=500, batch_size=10, validation_data=(X_val, y_val), verbose=0)\n</code></pre> <p>Plot the training and validation history to visualize the training process: </p> <pre><code>loss = history.history['loss'] \nval_loss = history.history['val_loss'] \nepochs = range(1, len(loss) + 1) \n\nplt.plot(epochs, loss, label='Training loss') \nplt.plot(epochs, val_loss, label='Validation loss') \n\nplt.title('Training and validation loss') \nplt.legend() \nplt.show()\n</code></pre> <p>\u200b    \u200b    </p>"},{"location":"simple-regression-tensorflow-keras/#test-the-model","title":"Test the model","text":"<p>Predict the <code>test</code> output from the <code>test</code> input:</p> <pre><code>y_pred = model.predict(X_test) \n</code></pre> <pre><code>7/7 [==============================] - 0s 1ms/step\n</code></pre> <p>Compare the <code>predicted</code> observations to the <code>true</code> observations:  </p> <pre><code>plt.plot(X_test, y_test, '.', label='True') \nplt.plot(X_test, y_pred, '.', label='Predicted') \n\nplt.title('Predicted vs True') \nplt.legend() \nplt.show()\n</code></pre> <p>\u200b    \u200b    </p> <p>The R-squared statistic, often denoted as R\u00b2, is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. </p> <p>It provides a measure of how well the observed outcomes are replicated by the model, based on the proportion of total variation of outcomes explained by the model. </p> <p>R\u00b2 values range from 0 to 1. An R\u00b2 of 1 indicates that the regression predictions perfectly fit the data. </p> <pre><code>r2 = r2_score(y_test, y_pred)\n\n# plot the true vs predicted values\nplt.scatter(y_test, y_pred)\n\n# add a diagonal line\nplt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')\n\nplt.title(f'$R^2$: {r2:.2f}')\nplt.xlabel('True')\nplt.ylabel('Predicted')\n\nplt.show()\n</code></pre> <p>\u200b    \u200b    </p>"},{"location":"simple-regression-tensorflow-keras/#appendix-a","title":"Appendix A.","text":""},{"location":"simple-regression-tensorflow-keras/#deep-neural-networks-dnns","title":"Deep Neural Networks (DNNs)","text":"<p>Deep Neural Networks (DNNs) are often referred to as universal approximators. This term originates from the Universal Approximation Theorem, which states that a neural network with a single hidden layer containing a finite number of neurons can approximate any continuous function to a desired level of accuracy, given that the function is defined on a specific compact subset of real numbers. </p> <p>However, in practice, DNNs with multiple layers are used because they can represent complex functions more efficiently, requiring fewer neurons than a single-layer network. The depth of these networks allows for the abstraction of high-level features from raw input data in hierarchical layers. Each layer in the network extracts and synthesizes features, becoming progressively more abstract at each level. </p> <p>This makes DNNs extremely versatile and powerful in learning and approximating a wide variety of functions, contributing to their success in diverse fields such as image recognition, natural language processing, and reinforcement learning.</p>"},{"location":"simple-regression-tensorflow-keras/#determining-the-number-of-neurons-and-layers-to-use-in-a-deep-neural-network-dnn","title":"Determining the number of neurons and layers to use in a Deep Neural Network (DNN)","text":"<p>Determining the number of neurons and layers to use in a Deep Neural Network (DNN) is more of an art than a science, and it often involves a lot of experimentation. However, here are some general guidelines:</p> <ol> <li> <p>Number of Hidden Layers: Start with a single hidden layer for simple problems. If performance is not satisfactory, you can start adding more. In practice, most of the DNNs have between 1 and 5 hidden layers. Deep learning (with many hidden layers) is usually beneficial for complex problems like image recognition, natural language processing, etc.</p> </li> <li> <p>Number of Neurons per Hidden Layer: A common practice is to size them to form a funnel, with fewer and fewer neurons at each layer\u2014the so-called \"funnel\" architecture. Another approach is to choose a layer size that is somewhere between the number of input and output neurons. </p> </li> <li> <p>Validation Set Performance: The most reliable way to configure your neural network architecture is to use a validation set. You train multiple networks with various layers and neurons, then compare their performance on the validation set, and choose the architecture that performs best.</p> </li> <li> <p>Early Stopping: Another approach is to use a large number of layers and neurons and then rely on early stopping to prevent overfitting.</p> </li> <li> <p>Grid Search or Random Search: These are systematic methods to explore many different configurations and then pick the best one.</p> </li> <li> <p>Use Pretrained Networks: For many tasks, you can use a pretrained network that was trained on a similar task. This is called transfer learning.</p> </li> </ol> <p>Remember, these are just starting points. The optimal network architecture is highly dependent on the specific task and the data. It's often a good idea to experiment with different architectures, or use techniques like cross-validation to choose the best structure.</p>"},{"location":"simple-regression-tensorflow-keras/#optimizer","title":"Optimizer","text":"<p>Adam, which stands for Adaptive Moment Estimation, is a popular optimization algorithm used in deep learning models. It's often used instead of the classical stochastic gradient descent procedure to update network weights iterative based on training data.</p> <p>Adam combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems. </p> <p>Adam is relatively easy to configure where the default configuration parameters do well on most problems. The main advantages of Adam are:</p> <ol> <li>Straightforward to implement.</li> <li>Computationally efficient.</li> <li>Little memory requirements.</li> <li>Invariant to diagonal rescale of the gradients.</li> <li>Well suited for problems that are large in terms of data and/or parameters.</li> <li>Appropriate for non-stationary objectives.</li> <li>Works well with very little tuning of hyperparameters.</li> </ol>"},{"location":"simple-regression-tensorflow-keras/#loss-function-and-metrics","title":"Loss Function and Metrics","text":"<p>Mean Absolute Error (MAE) is a loss function used in regression problems. It's calculated as the average of the absolute differences between the true and predicted values. </p> <p>Mathematically, it's expressed as:</p> \\[ MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| \\] <p>Where: - \\(n\\) is the total number of data points - \\(y_i\\) is the actual value - \\(\\hat{y}_i\\) is the predicted value  </p> <p>MAE is a popular loss function for regression problems because it's easy to understand and calculate. It represents the average error in the same units as the original values, which makes it easy to interpret. </p> <p>However, one limitation of MAE is that it doesn't account for the direction of the error and treats all errors equally, regardless of whether they are positive or negative. This means that MAE could be the same for two models that overestimate and underestimate the target variable, respectively. </p> <p>In the context of neural networks, the network would aim to adjust its weights to minimize the MAE during the training process.</p> <p>Convert the Jupyter notebook to Markdown</p> <pre><code>!jupyter nbconvert simple-regression-tesnorflow-keras.ipynb --to markdown --output simple-regression-tesnorflow-keras.md\n</code></pre> <pre><code>[NbConvertApp] Converting notebook simple-regression-tesnorflow-keras.ipynb to markdown\n[NbConvertApp] Support files will be in simple-regression-tesnorflow-keras_files/\n[NbConvertApp] Writing 12697 bytes to simple-regression-tesnorflow-keras.md\n</code></pre>"},{"location":"local-kubernetes-cluster-ubuntu-multipass-k3s-macos/","title":"Local Kubernetes cluster on macOS with Ubuntu Multipass and K3s","text":""},{"location":"local-kubernetes-cluster-ubuntu-multipass-k3s-macos/#install-multipass","title":"Install Multipass","text":"<p>Install via Homebrew:</p> <pre><code>brew install multipass\n</code></pre>"},{"location":"local-kubernetes-cluster-ubuntu-multipass-k3s-macos/#launch-ubuntu-nodes","title":"Launch Ubuntu Nodes","text":"<p>Launch 3 virtual nodes running Ubuntu 22.04 LTS:</p> <pre><code>multipass launch 22.04 --name ubuntu-k3s-01 --cpus 1 --memory 2G --disk 8G\nmultipass launch 22.04 --name ubuntu-k3s-02 --cpus 1 --memory 2G --disk 8G\nmultipass launch 22.04 --name ubuntu-k3s-03 --cpus 1 --memory 2G --disk 8G\n</code></pre> <p>Verify that the nodes are running:</p> <p><pre><code>multipass list\n</code></pre> You should see output similar to this:</p> <pre><code>Name                    State             IPv4             Image\nubuntu-k3s-01           Running           192.168.64.2     Ubuntu 22.04 LTS\nubuntu-k3s-02           Running           192.168.64.3     Ubuntu 22.04 LTS\nubuntu-k3s-03           Running           192.168.64.4     Ubuntu 22.04 LTS\n</code></pre> <p>Verify that you can connect to each node:</p> <pre><code>multipass shell ubuntu-k3s-01\nmultipass shell ubuntu-k3s-02\nmultipass shell ubuntu-k3s-03\n</code></pre>"},{"location":"local-kubernetes-cluster-ubuntu-multipass-k3s-macos/#install-k3s","title":"Install K3s","text":""},{"location":"local-kubernetes-cluster-ubuntu-multipass-k3s-macos/#k3s-server-node","title":"K3s Server Node","text":"<pre><code>multipass exec ubuntu-k3s-01 -- bash -c \"curl -sfL https://get.k3s.io | sh -\"\n</code></pre> <p>After running this installation:</p> <ul> <li>The K3s service will be configured to automatically restart after node reboots or if the process crashes or is killed</li> <li>Additional utilities will be installed, including <code>kubectl</code>, <code>crictl</code>, <code>ctr</code>, <code>k3s-killall.sh</code>, and <code>k3s-uninstall.sh</code></li> <li>A kubeconfig file will be written to <code>/etc/rancher/k3s/k3s.yaml</code> and the <code>kubectl</code> installed by K3s will automatically use it.</li> </ul> <p>Verify that the server node is running:</p> <pre><code>multipass exec ubuntu-k3s-01 -- sudo kubectl get nodes -o wide\n</code></pre> <p>List the running pods:</p> <pre><code>multipass exec ubuntu-k3s-01 -- sudo kubectl get pods --all-namespaces -o wide\n</code></pre>"},{"location":"local-kubernetes-cluster-ubuntu-multipass-k3s-macos/#k3s-agent-nodes","title":"K3s Agent Nodes","text":"<p>A single-node server installation is a fully-functional Kubernetes cluster, including all the datastore, control-plane, kubelet, and container runtime components necessary to host workload pods. It is not necessary to add additional server or agents nodes, but you may want to do so to add additional capacity or redundancy to your cluster.</p> <p>To install additional agent nodes and add them to the cluster, run the installation script with the <code>K3S_URL</code> and <code>K3S_TOKEN</code> environment variables.</p> <p>First get the server IP address:</p> <pre><code>K3S_SERVER=$(multipass info ubuntu-k3s-01 | grep IPv4 | awk '{print $2}')\n</code></pre> <p>Next get the join token for the agents:</p> <pre><code>K3S_TOKEN=$(multipass exec ubuntu-k3s-01 sudo cat /var/lib/rancher/k3s/server/node-token)\n</code></pre> <p>Quick Checkpoint:</p> <pre><code>echo $K3S_SERVER\necho $K3S_TOKEN\n</code></pre> <p>Next add the rest of the Ubuntu nodes to the cluster:</p> <pre><code># add ubuntu-k3s-02\nmultipass exec ubuntu-k3s-02 -- \\\nbash -c \"curl -sfL https://get.k3s.io | K3S_URL=https://$K3S_SERVER:6443 K3S_TOKEN=$K3S_TOKEN sh -\"\n\n# add ubuntu-k3s-03\nmultipass exec ubuntu-k3s-03 -- \\\nbash -c \"curl -sfL https://get.k3s.io | K3S_URL=https://$K3S_SERVER:6443 K3S_TOKEN=$K3S_TOKEN sh -\"\n</code></pre> <p>Verify that the nodes have joined the cluster:</p> <pre><code>multipass exec ubuntu-k3s-01 -- sudo kubectl get nodes -o wide\n</code></pre> <p>You should see output similar to this:</p> <pre><code>NAME            STATUS   ROLES                  AGE   VERSION        INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION       CONTAINER-RUNTIME\nubuntu-k3s-01   Ready    control-plane,master   40m   v1.29.6+k3s2   192.168.64.2   &lt;none&gt;        Ubuntu 22.04.4 LTS   5.15.0-117-generic   containerd://1.7.17-k3s1\nubuntu-k3s-02   Ready    &lt;none&gt;                 29m   v1.29.6+k3s2   192.168.64.3   &lt;none&gt;        Ubuntu 22.04.4 LTS   5.15.0-117-generic   containerd://1.7.17-k3s1\nubuntu-k3s-03   Ready    &lt;none&gt;                 10s   v1.29.6+k3s2   192.168.64.4   &lt;none&gt;        Ubuntu 22.04.4 LTS   5.15.0-117-generic   containerd://1.7.17-k3s1\n</code></pre>"},{"location":"local-kubernetes-cluster-ubuntu-multipass-k3s-macos/#cleanup","title":"Cleanup","text":"<p>Stop the Ubuntu instances:</p> <pre><code>multipass stop ubuntu-k3s-03\nmultipass stop ubuntu-k3s-02\nmultipass stop ubuntu-k3s-01\n</code></pre> <p>Delete the Ubuntu instances:</p> <pre><code>multipass delete ubuntu-k3s-03\nmultipass delete ubuntu-k3s-02\nmultipass delete ubuntu-k3s-01\n</code></pre> <p>To purge all unused <code>multipass</code> images:</p> <pre><code>multipass purge\n</code></pre>"},{"location":"archive/2024/","title":"2024","text":""},{"location":"archive/2023/","title":"2023","text":""},{"location":"archive/2021/","title":"2021","text":""},{"location":"archive/2020/","title":"2020","text":""},{"location":"archive/2018/","title":"2018","text":""},{"location":"archive/2017/","title":"2017","text":""},{"location":"archive/2016/","title":"2016","text":""},{"location":"archive/2015/","title":"2015","text":""},{"location":"archive/2014/","title":"2014","text":""},{"location":"archive/2013/","title":"2013","text":""},{"location":"archive/2012/","title":"2012","text":""},{"location":"archive/2011/","title":"2011","text":""},{"location":"kubernetes/","title":"kubernetes","text":""},{"location":"k3s/","title":"k3s","text":""},{"location":"ubuntu/","title":"ubuntu","text":""},{"location":"macos/","title":"macos","text":""},{"location":"machine-learning/","title":"machine-learning","text":""},{"location":"deep-neural-networks/","title":"deep-neural-networks","text":""},{"location":"keras/","title":"keras","text":""},{"location":"tensorflow/","title":"tensorflow","text":""},{"location":"virtual-box/","title":"virtual-box","text":""},{"location":"arm64/","title":"arm64","text":""},{"location":"vscode/","title":"vscode","text":""},{"location":"cpp/","title":"cpp","text":""},{"location":"windows/","title":"windows","text":""},{"location":"csharp/","title":"csharp","text":""},{"location":"dotnet/","title":"dotnet","text":""},{"location":"linux/","title":"linux","text":""},{"location":"ruby/","title":"ruby","text":""},{"location":"podman/","title":"podman","text":""},{"location":"mongodb/","title":"mongodb","text":""},{"location":"cloud/","title":"cloud","text":""},{"location":"aws/","title":"aws","text":""},{"location":"ec2/","title":"ec2","text":""},{"location":"cloud-formation/","title":"cloud-formation","text":""},{"location":"docker/","title":"docker","text":""},{"location":"docker-swarm/","title":"docker-swarm","text":""},{"location":"ecs/","title":"ecs","text":""},{"location":"page/2/","title":"Blog","text":""},{"location":"page/3/","title":"Blog","text":""},{"location":"page/4/","title":"Blog","text":""},{"location":"page/5/","title":"Blog","text":""},{"location":"page/6/","title":"Blog","text":""},{"location":"page/7/","title":"Blog","text":""},{"location":"page/8/","title":"Blog","text":""},{"location":"page/9/","title":"Blog","text":""},{"location":"page/10/","title":"Blog","text":""},{"location":"page/11/","title":"Blog","text":""},{"location":"page/12/","title":"Blog","text":""},{"location":"page/13/","title":"Blog","text":""},{"location":"page/14/","title":"Blog","text":""},{"location":"page/15/","title":"Blog","text":""},{"location":"page/16/","title":"Blog","text":""},{"location":"page/17/","title":"Blog","text":""},{"location":"page/18/","title":"Blog","text":""},{"location":"page/19/","title":"Blog","text":""},{"location":"archive/2023/page/2/","title":"2023","text":""},{"location":"archive/2023/page/3/","title":"2023","text":""},{"location":"archive/2021/page/2/","title":"2021","text":""},{"location":"archive/2021/page/3/","title":"2021","text":""},{"location":"archive/2015/page/2/","title":"2015","text":""},{"location":"archive/2013/page/2/","title":"2013","text":""},{"location":"archive/2013/page/3/","title":"2013","text":""},{"location":"archive/2013/page/4/","title":"2013","text":""},{"location":"archive/2013/page/5/","title":"2013","text":""},{"location":"archive/2012/page/2/","title":"2012","text":""},{"location":"archive/2011/page/2/","title":"2011","text":""},{"location":"archive/2011/page/3/","title":"2011","text":""},{"location":"aws/page/2/","title":"aws","text":""},{"location":"aws/page/3/","title":"aws","text":""},{"location":"aws/page/4/","title":"aws","text":""},{"location":"cloud/page/2/","title":"cloud","text":""},{"location":"cloud/page/3/","title":"cloud","text":""},{"location":"cloud/page/4/","title":"cloud","text":""},{"location":"cloud-formation/page/2/","title":"cloud-formation","text":""},{"location":"cpp/page/2/","title":"cpp","text":""},{"location":"docker/page/2/","title":"docker","text":""},{"location":"docker-swarm/page/2/","title":"docker-swarm","text":""},{"location":"ec2/page/2/","title":"ec2","text":""},{"location":"ecs/page/2/","title":"ecs","text":""},{"location":"macos/page/2/","title":"macos","text":""},{"location":"ubuntu/page/2/","title":"ubuntu","text":""}]}